{
  "sources": [
    {
      "title": "BookingSync.com news",
      "feedUrl": "https://changelog.bookingsync.com/rss",
      "siteUrl": "https://changelog.bookingsync.com",
      "articles": [
        {
          "id": "281231",
          "author": "Maud , Partnership Manager",
          "description": "New!\n¬†¬†\nExciting news! \nIntroducing Host Review Automation on Smily ‚Äì a game-changer for hosts like you! üöÄ\nNow, with just a few clicks, you can automate the process of posting reviews about your guests on Airbnb.\n\nüíô Why you'll love it:\nSave Time: Say goodbye to the hassle of manually posting reviews. Our automation feature streamlines the process, allowing you to focus on what matters most ‚Äì creating unforgettable guest experiences.\n‚Äã\nConsistency: Don‚Äôt miss any opportunity to provide a 5-star review. It encourages positive behavior from your guests, enhances your guest experience, and fosters a sense of appreciation and satisfaction.\n‚Äã\nEnhanced Communication: Strengthen your host profile, posting a review encourages your guest to review their experience with you. Timely feedback benefits future guests and contributes to building a trustworthy host reputation.\n‚Äã\nBoost your visibility: Help your property shine bright in search results! Airbnb loves hosts with high review rates ‚Äì the more, the merrier. Your listing gets pushed to the top, ensuring more eyes on your amazing space.\n\n\n\nüåü Activate the Host Review Automation feature today through your Smily account by navigating to Reviews ‚è© Host Reviews ‚è© Automation\n\n\n\nüí° For more detailed information, simply click here and follow the easy setup instructions.\nWe can't wait to hear your thoughts on this fantastic new feature!",
          "link": "https://changelog.bookingsync.com/automate-your-host-reviews-on-airbnb!-281231",
          "publishedOn": "2023-12-11T16:53:50.000Z",
          "wordCount": 449,
          "title": "Automate your host reviews on Airbnb! ‚≠êÔ∏è",
          "imageUrl": "https://cloud.headwayapp.co/changelogs_images/images/big/000/119/555-41008a0437367eeaa201bd339ee80fc95fc35f74.gif"
        }
      ]
    },
    {
      "title": "Security Bulletins on Tailscale",
      "feedUrl": "https://tailscale.com/security-bulletins/index.xml",
      "siteUrl": "https://tailscale.com/security-bulletins/",
      "articles": [
        {
          "id": "https://tailscale.com/security-bulletins/#ts-2023-009",
          "author": null,
          "description": "Description: The OAuth implementation of Google Workspace allows for the creation of Google accounts associated with a given Workspace domain that are not actually controlled by that workspace, e.g. alice+foo@example.com. As a result, these accounts may be used to retain access to systems that use Google Workspace SSO login even after the original account has been deactivated or removed.\nWhat happened?\nTailscale uses Google as one of the possible identity providers for creating and joining a tailnet. Users who have emails with the same domain name can automatically sign in using SSO and be added to the corresponding tailnet (unless user approval is turned on for the tailnet)‚Äã‚Äã. The OAuth vulnerability reported by Truffle Security means that it is possible for an attacker to create a new pe‚Ä¶",
          "link": "https://tailscale.com/security-bulletins/#ts-2023-009",
          "publishedOn": "2023-12-22T00:00:00.000Z",
          "wordCount": 9564,
          "title": "TS-2023-009",
          "imageUrl": "https://cdn.sanity.io/images/w77i7m8x/production/8e0455b2d9b33c6151016afdf2ea81d7623c2f04-1200x628.png"
        }
      ]
    },
    {
      "title": "Airbnb API Status - Incident History",
      "feedUrl": "https://airbnbapi.statuspage.io/history.rss",
      "siteUrl": "https://airbnbapi.statuspage.io",
      "articles": []
    },
    {
      "title": "Twilio Status - Incident History",
      "feedUrl": "https://status.twilio.com/history.rss",
      "siteUrl": "https://status.twilio.com",
      "articles": [
        {
          "id": "https://status.twilio.com/incidents/52dn4j2rnk4k",
          "author": null,
          "description": "Jan  2, 03:43 PST\nResolved - This incident has been resolved.\nJan  2, 03:40 PST\nUpdate - We are no longer experiencing SMS delivery delays when sending messages to Celcom Network in Malaysia. This incident has been resolved.\nJan  2, 01:56 PST\nMonitoring - We are observing recovery in SMS delivery delays when sending messages to Celcom Network in Malaysia. We will continue monitoring the service to ensure a full recovery. We will provide another update in 2 hours or as soon as more information becomes available.\nJan  1, 22:07 PST\nUpdate - We continue to experience SMS delivery delays when sending messages to Celcom Network in Malaysia. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 4 hours or as soon as more information becomes available.\nJan  1, 20:07 PST\nUpdate - We continue to experience SMS delivery delays when sending messages to Celcom Network in Malaysia. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 2 hours or as soon as more information becomes available.\nJan  1, 19:07 PST\nInvestigating - We are experiencing SMS delivery delays when sending messages to Celcom Network in Malaysia. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 1 hour or as soon as more information becomes available.",
          "link": "https://status.twilio.com/incidents/52dn4j2rnk4k",
          "publishedOn": "2024-01-02T11:43:11.000Z",
          "wordCount": 7435,
          "title": "SMS Delivery Delays to Celcom Network in Malaysia",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/w7sl2wsb776h",
          "author": null,
          "description": "Jan  1, 11:10 PST\nResolved - We are no longer experiencing SMS delivery delays when sending messages to MTN Network in Sudan. This incident has been resolved.\nJan  1, 09:21 PST\nUpdate - We are continuing to observing recovery in MMS/SMS delivery delays when sending messages to MTN Network in Sudan. We will continue monitoring the service to ensure a full recovery. We will provide another update in 2 hours or as soon as more information becomes available.\nJan  1, 07:21 PST\nMonitoring - We are observing recovery in SMS delivery delays when sending messages to MTN Network in Sudan. We will continue monitoring the service to ensure a full recovery. We will provide another update in 2 hours or as soon as more information becomes available.\nJan  1, 03:55 PST\nUpdate - We are still experiencing SM‚Ä¶",
          "link": "https://status.twilio.com/incidents/w7sl2wsb776h",
          "publishedOn": "2024-01-01T19:10:51.000Z",
          "wordCount": 7580,
          "title": "SMS Delivery Delays to MTN Network in Sudan",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/yfvf2c09m393",
          "author": null,
          "description": "Jan  1, 10:46 PST\nResolved - We are no longer experiencing SMS delivery delays when sending messages to America Net Network in Brazil. This incident has been resolved.\nJan  1, 09:00 PST\nMonitoring - We are observing recovery in SMS delivery delays when sending messages to America Net Network in Brazil. We will continue monitoring the service to ensure a full recovery. We will provide another update in 2 hours or as soon as more information becomes available.\nJan  1, 01:00 PST\nUpdate - We are continuing to experience SMS delivery delays when sending messages America Net Network in Brazil. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 8 hours or as soon as more information becomes available.\nDec 31, 21:02 PST\nUpdate - We are continuing to experience SMS delivery delays when sending messages America Net Network in Brazil. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 4 hours or as soon as more information becomes available.\nDec 31, 19:02 PST\nUpdate - We are continuing to experience SMS delivery delays when sending messages America Net Network in Brazil. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 2 hours or as soon as more information becomes available.\nDec 31, 18:02 PST\nInvestigating - We are experiencing SMS delivery delays when sending messages America Net Network in Brazil. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 1 hour or as soon as more information becomes available.",
          "link": "https://status.twilio.com/incidents/yfvf2c09m393",
          "publishedOn": "2024-01-01T18:46:25.000Z",
          "wordCount": 7482,
          "title": "SMS Delivery Delays to America Net Network in Brazil",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/yh67v36pt7wk",
          "author": null,
          "description": "Jan  1, 04:08 PST\nResolved - We are no longer experiencing SMS delivery failures sending to Etisalat Network In Egypt. This incident has been resolved.\nJan  1, 02:10 PST\nMonitoring - We are observing recovery in SMS delivery failures sending to Etisalat Network In Egypt. We will continue monitoring the service to ensure a full recovery. We will provide another update in 2 hours or as soon as more information becomes available.\nDec 31, 22:13 PST\nUpdate - We are continuing to experience SMS delivery failures sending to Etisalat Network In Egypt. Our engineers are working with our carrier partner to resolve the issue. We expect to provide another update in 4 hours or as soon as more information becomes available.\nDec 31, 20:13 PST\nUpdate - We are continuing to experience SMS delivery failures sending to Etisalat Network In Egypt. Our engineers are working with our carrier partner to resolve the issue. We expect to provide another update in 2 hours or as soon as more information becomes available.\nDec 31, 19:13 PST\nInvestigating - We are experiencing SMS delivery failures sending to Etisalat Network In Egypt. Our engineers are working with our carrier partner to resolve the issue. We expect to provide another update in 1 hour or as soon as more information becomes available.",
          "link": "https://status.twilio.com/incidents/yh67v36pt7wk",
          "publishedOn": "2024-01-01T12:08:18.000Z",
          "wordCount": 7420,
          "title": "SMS Delivery Failure To Etisalat Network In Egypt",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/n5b1k3xtr2sp",
          "author": null,
          "description": "Dec 31, 14:06 PST\nResolved - Twilio Recordings were degraded for 60 minutes between 11:30 and 12:30 Pacific Time on 31/12/2023. During this period of time customers may have experienced 500 errors when using the API. The issue has now been resolved.",
          "link": "https://status.twilio.com/incidents/n5b1k3xtr2sp",
          "publishedOn": "2023-12-31T22:06:24.000Z",
          "wordCount": 7212,
          "title": "Twilio Recordings Affected",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/0c5rdtj4nz4m",
          "author": null,
          "description": "Dec 31, 07:28 PST\nResolved - We are no longer experiencing SMS Delivery Delay To Twilio Phone Numbers In US Over A Subset Of Shortcode. This incident has been resolved.\nDec 31, 05:51 PST\nMonitoring - We are observing recovery in SMS delivery delays to Twilio Phone Numbers in US over a subset of short codes. We will continue monitoring the service to ensure a full recovery. We will provide another update in 2 hours or as soon as more information becomes available.\nDec 30, 22:23 PST\nUpdate - We continue to experience SMS delivery delays to Twilio Phone Numbers in US over a subset of short codes. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 16 hours or as soon as more information becomes available.\nDec 30, 14:29 PST\nInvestigating -‚Ä¶",
          "link": "https://status.twilio.com/incidents/0c5rdtj4nz4m",
          "publishedOn": "2023-12-31T15:28:52.000Z",
          "wordCount": 7743,
          "title": "SMS Delivery Delay to Twilio Phone Numbers in the US Over a Subset of Shortcode",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/t0ss3njxjvkq",
          "author": null,
          "description": "Dec 30, 18:48 PST\nResolved - We are no longer experiencing SMS delivery delays when sending messages to IAM network in Morocco. This incident has been resolved.\nDec 30, 16:53 PST\nUpdate - We are observing recovery in SMS delivery delays when sending messages to IAM in Morocco. We will continue monitoring the service to ensure a full recovery. We will provide another update in 2 hours or as soon as more information becomes available.\nDec 30, 16:34 PST\nMonitoring - We are observing recovery in SMS delivery delays when sending messages to IAM in Morocco. We will continue monitoring the service to ensure a full recovery. We will provide another update in 30 minutes or as soon as more information becomes available.\nDec 30, 15:48 PST\nInvestigating - We are experiencing SMS delivery delays when sending messages to IAM network in Morocco. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 1 hour or as soon as more information becomes available.",
          "link": "https://status.twilio.com/incidents/t0ss3njxjvkq",
          "publishedOn": "2023-12-31T02:48:14.000Z",
          "wordCount": 7371,
          "title": "SMS Delivery Receipt Delays to IAM Network in Morocco",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/ccq3gmg0009g",
          "author": null,
          "description": "Dec 30, 17:00 PST\nResolved - We are no longer experiencing SMS delivery delays when sending messages to Tigo Network in Senegal. This incident has been resolved.\nDec 30, 15:32 PST\nUpdate - We are observing recovery in SMS delivery delays when sending messages to Tigo Network in Senegal. We will continue monitoring the service to ensure a full recovery. We will provide another update in 2 hours or as soon as more information becomes available.\nDec 30, 15:07 PST\nMonitoring - We are observing recovery in SMS delivery delays when sending messages to Tigo Network in Senegal. We will continue monitoring the service to ensure a full recovery. We will provide another update in 30 minutes or as soon as more information becomes available.\nDec 30, 12:16 PST\nUpdate - We continue experiencing SMS delivery delays when sending messages to Tigo Network in Senegal. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 8 hours or as soon as more information becomes available.\nDec 30, 08:16 PST\nUpdate - We continue experiencing SMS delivery delays when sending messages to Tigo Network in Senegal. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 4 hours or as soon as more information becomes available.\nDec 30, 06:20 PST\nUpdate - We are still experiencing SMS delivery delays when sending messages to Tigo Network in Senegal. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 2 hours or as soon as more information becomes available.\nDec 30, 05:24 PST\nInvestigating - We are experiencing SMS delivery delays when sending messages to Tigo Network in Senegal. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 1 hour or as soon as more information becomes available.",
          "link": "https://status.twilio.com/incidents/ccq3gmg0009g",
          "publishedOn": "2023-12-31T01:00:53.000Z",
          "wordCount": 7525,
          "title": "SMS Delivery Delays to Tigo Network in Senegal",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/1z7fqgqhymry",
          "author": null,
          "description": "Dec 30, 12:43 PST\nResolved - We are no longer experiencing SMS delivery failures to MTN Network in Sudan. This incident has been resolved.\nDec 30, 10:54 PST\nMonitoring - We are observing recovery in SMS delivery failures sending to MTN Network in Sudan. We will continue monitoring the service to ensure a full recovery. We will provide another update in 2 hours or as soon as more information becomes available.\nDec 30, 04:13 PST\nUpdate - We are still experiencing SMS delivery failures sending to MTN Network in Sudan. Our engineers are working with our carrier partner to resolve the issue. We expect to provide another update in 16 hours or as soon as more information becomes available.\nDec 29, 20:53 PST\nUpdate - We are still experiencing SMS delivery failures sending to MTN Network in Sudan. Our engineers are working with our carrier partner to resolve the issue. We expect to provide another update in 8 hours or as soon as more information becomes available.\nDec 29, 16:36 PST\nUpdate - We are still experiencing SMS delivery failures sending to MTN Network in Sudan. Our engineers are working with our carrier partner to resolve the issue. We expect to provide another update in 4 hours or as soon as more information becomes available.\nDec 29, 14:30 PST\nUpdate - We continue experiencing SMS delivery failures sending to MTN Network in Sudan. Our engineers are working with our carrier partner to resolve the issue. We expect to provide another update in 2 hours or as soon as more information becomes available.\nDec 29, 13:30 PST\nInvestigating - We are experiencing SMS delivery failures sending to MTN Network in Sudan. Our engineers are working with our carrier partner to resolve the issue. We expect to provide another update in 1 hour or as soon as more information becomes available.",
          "link": "https://status.twilio.com/incidents/1z7fqgqhymry",
          "publishedOn": "2023-12-30T20:43:36.000Z",
          "wordCount": 7516,
          "title": "SMS Delivery Failures on MTN Network in Sudan",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/bw202h6rbw1f",
          "author": null,
          "description": "Dec 30, 06:16 PST\nResolved - We are no longer experiencing SMS delivery delays when sending messages to Movistar Network in Mexico. This incident has been resolved.\nDec 30, 04:13 PST\nMonitoring - We are observing recovery in SMS delivery delays when sending messages to Movistar Network in Mexico. We will continue monitoring the service to ensure a full recovery. We will provide another update in 2 hours or as soon as more information becomes available.\nDec 30, 03:04 PST\nUpdate - We continue experiencing SMS delivery delays when sending messages to Movistar Network in Mexico. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 4 hours or as soon as more information becomes available.\nDec 30, 01:13 PST\nUpdate - We continue experiencing S‚Ä¶",
          "link": "https://status.twilio.com/incidents/bw202h6rbw1f",
          "publishedOn": "2023-12-30T14:16:55.000Z",
          "wordCount": 7623,
          "title": "SMS Delivery Delays to Movistar Network in Mexico",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/wdbw6wj2j45v",
          "author": null,
          "description": "Dec 29, 23:57 PST\nResolved - We are no longer experiencing SMS delivery delays when sending messages to Maroc Telecom Network in Morocco. This incident has been resolved.\nDec 29, 21:44 PST\nUpdate - We continue observing recovery in SMS delivery delays when sending messages to Maroc Telecom Network in Morocco. We will continue monitoring the service to ensure a full recovery. We will provide another update in 2 hours or as soon as more information becomes available.\nDec 29, 19:45 PST\nMonitoring - We are observing recovery in SMS delivery delays when sending messages to Maroc Telecom Network in Morocco. We will continue monitoring the service to ensure a full recovery. We will provide another update in 2 hours or as soon as more information becomes available.\nDec 29, 15:57 PST\nUpdate - We continue experiencing SMS delivery delays when sending messages to Maroc Telecom Network in Morocco. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 4 hours or as soon as more information becomes available.\nDec 29, 13:57 PST\nUpdate - We are still experiencing SMS delivery delays when sending messages to Maroc Telecom Network in Morocco. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 2 hours or as soon as more information becomes available.\nDec 29, 12:57 PST\nInvestigating - We are experiencing SMS delivery delays when sending messages to Maroc Telecom Network in Morocco. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 1 hour or as soon as more information becomes available.",
          "link": "https://status.twilio.com/incidents/wdbw6wj2j45v",
          "publishedOn": "2023-12-30T07:57:27.000Z",
          "wordCount": 7484,
          "title": "SMS Delivery Delays to Maroc Telecom Network in Morocco",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/lpspfc2ngrnv",
          "author": null,
          "description": "Dec 29, 04:45 PST\nResolved - We are no longer experiencing SMS delivery delays when sending messages to Mobilis Network in Algeria. This incident has been resolved.\nDec 29, 02:45 PST\nMonitoring - We are observing recovery in SMS delivery delays when sending messages to Mobilis Network in Algeria. We will continue monitoring the service to ensure a full recovery. We will provide another update in 2 hours or as soon as more information becomes available.\nDec 29, 02:44 PST\nUpdate - We continue to experience SMS delivery delays when sending messages to Mobilis Network in Algeria. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 2 hours or as soon as more information becomes available.\nDec 29, 01:36 PST\nInvestigating - We are experiencing SMS delivery delays when sending messages to Mobilis Network in Algeria. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 1 hour or as soon as more information becomes available.",
          "link": "https://status.twilio.com/incidents/lpspfc2ngrnv",
          "publishedOn": "2023-12-29T12:45:32.000Z",
          "wordCount": 7374,
          "title": "SMS Delivery Delays to Mobilis Network in Algeria",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/6243cpbqt873",
          "author": null,
          "description": "Dec 28, 21:22 PST\nResolved - We are no longer experiencing SMS delivery delays when sending messages to Claro Network In Brazil. This incident has been resolved.\nDec 28, 19:22 PST\nMonitoring - We are observing recovery in SMS delivery delays when sending messages to Claro Network In Brazil. We will continue monitoring the service to ensure a full recovery. We will provide another update in 2 hours or as soon as more information becomes available.\nDec 28, 18:22 PST\nInvestigating - We are experiencing SMS delivery delays when sending messages to Claro Network In Brazil. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 1 hour or as soon as more information becomes available.",
          "link": "https://status.twilio.com/incidents/6243cpbqt873",
          "publishedOn": "2023-12-29T05:22:10.000Z",
          "wordCount": 7321,
          "title": "SMS Delivery Delay To Claro Network In Brazil",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/j9shf2twqdwf",
          "author": null,
          "description": "Dec 28, 15:43 PST\nResolved - We are no longer experiencing SMS Delivery Delays to Altan Redes Network in Mexico. This incident has been resolved.\nDec 28, 13:49 PST\nMonitoring - We are observing recovery in SMS Delivery Delays to Altan Redes Network in Mexico. We will continue monitoring the service to ensure a full recovery. We will provide another update in 2 hours or as soon as more information becomes available.\nDec 28, 13:19 PST\nInvestigating - We are experiencing SMS Delivery Delays to Altan Redes Network in Mexico. Our engineers are working with our carrier partner to resolve the issue. We will provide an update in 1 hour or as soon as more information becomes available.",
          "link": "https://status.twilio.com/incidents/j9shf2twqdwf",
          "publishedOn": "2023-12-28T23:43:52.000Z",
          "wordCount": 7318,
          "title": "SMS Delivery Delays to Altan Redes Network in Mexico",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    },
    {
      "title": "DigitalOcean Status - Incident History",
      "feedUrl": "https://status.digitalocean.com/history.rss",
      "siteUrl": "http://status.digitalocean.com",
      "articles": [
        {
          "id": "https://status.digitalocean.com/incidents/p6j21rldnxtl",
          "author": null,
          "description": "Dec 30, 12:23 UTC\nResolved - Our Engineering team has resolved the issue impacting Spaces Object Storage in our SGP1 region. From approximately 09:20 UTC - 11:31 UTC, users may have experienced an increased error rate and low performance while using the Spaces system. Spaces should now be operating normally. \nIf you continue to experience problems, please open a ticket with our Support team. Thank you for your patience and we apologize for any inconvenience.\nDec 30, 11:53 UTC\nMonitoring - From 09:20 UTC, our Engineering team observed an issue with Spaces Object Storage availability in the SGP1 region. \nDuring this time you may have experienced an increased error rate and low performance while using the Spaces system.¬†\nThe impact has now subsided and users should no longer be experiencing issues with accessing the Spaces Object Storage.\nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/p6j21rldnxtl",
          "publishedOn": "2023-12-30T12:23:06.000Z",
          "wordCount": 6069,
          "title": "Spaces Availability in SGP1",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/vvypqsr1n2vf",
          "author": null,
          "description": "Dec 21, 21:04 UTC\nResolved - Our engineering team has identified the root cause of the issue impacting Spaces in our SGP1 region and is continuing long-term mitigation work. From approximately 05:10 UTC - 08:00 UTC, users may have encountered errors with API or object requests, experienced difficulties in creating new buckets in SGP1, or faced issues with loading Spaces in the Cloud Control Panel. Spaces should now be operating normally.\nIf you continue to experience problems, please open a ticket with our support team. Thank you for your patience and we apologize for any inconvenience.\nDec 21, 08:27 UTC\nMonitoring - Our Engineering team has implemented a fix to resolve the issue impacting Spaces in our SGP1 region and is monitoring the situation closely. Users should no longer experience slowness or timeouts when trying to create or access their Spaces resources in the SGP1 region. We will post an update as soon as the issue is fully resolved.\nDec 21, 07:56 UTC\nIdentified - Our Engineering team has identified the cause of the issue impacting Object Storage in our SGP1 region and is actively working on a fix. During this time, users may encounter difficulties accessing Spaces, creating new buckets, deleting Spaces, and uploading files to and from Spaces buckets.\nWe will post an update as soon as additional information is available.\nDec 21, 05:34 UTC\nInvestigating - As of 05:10 UTC, our Engineering team is investigating an issue with Object Storage in our SGP1 region. During this time, users may encounter difficulties accessing Spaces, creating new buckets, deleting Spaces, and uploading files to and from Spaces buckets.\nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/vvypqsr1n2vf",
          "publishedOn": "2023-12-21T21:04:56.000Z",
          "wordCount": 6203,
          "title": "Spaces Availability in SGP1",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/1hv33vh6sf2l",
          "author": null,
          "description": "Dec  8, 18:00 UTC\nResolved - From 17:53 - 18:22 UTC, we experienced an issue impacting networking in our BLR1 region, with an impact to internal DigitalOcean services.\nDuring that time, public networking for customer services like Droplets and Droplet-based products was not impacted. However, users experienced issues with CRUD (create, read, update, delete) operations for services in BLR1, such as creating Droplets, managing Spaces Buckets, etc. Additionally, Cloud Firewalls were unable to be applied to services in BLR1 during that timeframe.\nOur Engineering team has resolved the issue and all services should be functioning normally.\nWe apologize for the inconvenience. If you have any questions or continue to experience issues, please reach out via a Support ticket on your account.",
          "link": "https://status.digitalocean.com/incidents/1hv33vh6sf2l",
          "publishedOn": "2023-12-08T18:00:00.000Z",
          "wordCount": 6029,
          "title": "Network Connectivity in BLR1",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/y557k86bkdts",
          "author": null,
          "description": "Dec  8, 14:33 UTC\nResolved - As of 09:18 UTC, our Engineering team has confirmed the resolution of the issue impacting Spaces CDN in our SGP1 region. Users should no longer experience issues when accessing their Spaces resources over the CDN endpoint in the SGP1 region. \nIf you continue to experience problems, please open a ticket with our support team. We apologize for any inconvenience.\nDec  8, 09:47 UTC\nIdentified - As of 07:45 UTC, our Engineering team has been made aware of an issue with the Spaces CDN in the SGP1 region. During this time, users may experience errors for objects served over the CDN. \nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/y557k86bkdts",
          "publishedOn": "2023-12-08T14:33:52.000Z",
          "wordCount": 6040,
          "title": "Spaces CDN in SGP1",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/8gycz6w7qj30",
          "author": null,
          "description": "Dec  4, 20:32 UTC\nResolved - Our Engineering team has confirmed full resolution of the issue with contact form submissions. From 14:59 - 19:27 UTC, submissions from https://www.digitalocean.com/company/contact were not being routed to our Support teams. All submissions have been routed to our teams and are being addressed.\nIf you continue to experience problems, please reach out to our support team. Thank you for your patience throughout this incident!\nDec  4, 20:21 UTC\nMonitoring - Our Engineering team has completed the fix to resolve the issue with submissions from our Support Contact form and at this time, services should be functioning as expected. \nOur Support team is addressing all submissions as quickly as possible. We're monitoring the fix and will post an update as soon as we conf‚Ä¶",
          "link": "https://status.digitalocean.com/incidents/8gycz6w7qj30",
          "publishedOn": "2023-12-04T20:32:18.000Z",
          "wordCount": 6256,
          "title": "Support Contact Form",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    },
    {
      "title": "Notion Status - Incident History",
      "feedUrl": "https://status.notion.so/history.rss",
      "siteUrl": "https://status.notion.so",
      "articles": [
        {
          "id": "https://status.notion.so/incidents/mdxnttqpv9z2",
          "author": null,
          "description": "Dec 27, 08:41 PST\nResolved - The issue was resolved.\nDec 27, 07:20 PST\nIdentified - We have identified the issue & are implementing a fix.\nDec 27, 05:30 PST\nInvestigating - Some users are receiving an error when trying to re-enter the Notion App on an iOS mobile device after having opened a different App in the meantime. We are actively looking into this.",
          "link": "https://status.notion.so/incidents/mdxnttqpv9z2",
          "publishedOn": "2023-12-27T16:41:14.000Z",
          "wordCount": 3377,
          "title": "Degenerated iOS mobile App Performance",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/r1ppwpszz0bv",
          "author": null,
          "description": "Dec  9, 19:56 PST\nResolved - Between 6:45 PST - 7:30 PST, users may have encountered errors while saving their changes. This issue has now been resolved.",
          "link": "https://status.notion.so/incidents/r1ppwpszz0bv",
          "publishedOn": "2023-12-10T03:56:56.000Z",
          "wordCount": 3324,
          "title": "High Latency Errors",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/9jymy8sknh0f",
          "author": null,
          "description": "Dec  5, 13:22 PST\nResolved - The team will be investigating this incident as bug.\nDec  5, 12:16 PST\nMonitoring - The incident has been identified as a bug and the team is actively monitoring reports and the issue\nDec  5, 11:08 PST\nInvestigating - We are currently investigating an issue where Notion users are unable to log-in via SSO on the Windows Desktop App",
          "link": "https://status.notion.so/incidents/9jymy8sknh0f",
          "publishedOn": "2023-12-05T21:22:51.000Z",
          "wordCount": 3377,
          "title": "SSO Log-In Issues for Windows",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    },
    {
      "title": "Rippling Status - Incident History",
      "feedUrl": "https://status.rippling.com/history.rss",
      "siteUrl": "https://status.rippling.com",
      "articles": [
        {
          "id": "https://status.rippling.com/incidents/mppy0hf49wk0",
          "author": null,
          "description": "Dec 16, 00:30 UTC\nResolved - This incident has been resolved.\nDec 15, 22:45 UTC\nMonitoring - A fix from the third party has been implemented and we‚Äôre monitoring the results\nDec 15, 22:41 UTC\nInvestigating - Our third-party network provider has been encountering intermittent issues since December 15th, 02:01 PM PST, leading to errors on the rippling.com domain. We are investigating this issue with the third-party provider.",
          "link": "https://status.rippling.com/incidents/mppy0hf49wk0",
          "publishedOn": "2023-12-16T00:30:06.000Z",
          "wordCount": 5048,
          "title": "Intermittent errors while accessing Rippling",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/248858/rippling_favicoon.png"
        }
      ]
    },
    {
      "title": "Google Workspace Status Dashboard Updates",
      "feedUrl": "https://www.google.com/appsstatus/dashboard/en/feed.atom",
      "siteUrl": "https://www.google.com/appsstatus/dashboard/",
      "articles": [
        {
          "id": "https://www.google.com/appsstatus/dashboard/incidents/jPWZ4p7bTSq65P1b9Gfn",
          "author": null,
          "description": "<p> Incident began at <strong>2023-12-07 18:00</strong> and ended at <strong>2023-12-07 20:32</strong> <span>(times are in <strong>Coordinated Universal Time (UTC)</strong>).</span></p><div class=\"cBIRi14aVDP__status-update-text\"><h1>Incident Report</h1>\n<h2>Summary</h2>\n<p>On 07 December 2023, various Google Workspace and Google Cloud customers experienced intermittent authentication issues when routed to one of our data centers in the US East region. As a result, a limited number of users could not sign-up, login, or re-authenticate for a duration of 1 hour and 32 minutes.</p>\n<p>To our Google Workspace and Google Cloud customers who were impacted during this issue, we sincerely apologize ‚Äì this is not the level of quality and reliability we strive to offer you.</p>\n<h2>Root Cause</h2>\n<p>Google‚Äôs authentication stack is broad and deep, running across every region and zone to provide functionality globally across all Google products. This particular issue was scoped to a single microservice&#39;s serving jobs within a single data center; this microservice handles serving some of the user-facing pages involved in sign-up, login, and re-authentication flows.</p>\n<p>To improve resource usage efficiency, engineers had been implementing more advanced autoscaling algorithms across these serving jobs globally. These changes were rolled out gradually over a period of several weeks without any issues.</p>\n<p>On 7 December, the rollout kicked off rolling restarts across the individual tasks within the serving jobs in a single data center in the US East region. Due to internal network routing at the time, this data center was serving traffic from the US East area as well as South America. These factors placed additional demand on each task&#39;s thread pool, both overloading some tasks and affecting those tasks&#39; ability to report metrics back to load-balancers. This caused requests to be intermittently dropped between the load-balancer and the individual serving tasks; these dropped requests led to user-facing 500 error pages.</p>\n<h2>Remediation and Prevention</h2>\n<p>Google engineers were alerted by our internal monitoring system on 07 December at 11:16 US/Pacific and immediately started investigating the issue. Once the nature and scope of the issue became clear, Google engineers worked to confirm that traffic could be safely re-routed away from the impacted serving jobs as a mitigation strategy. Traffic was rerouted to other data centers, and the customer impact was mitigated by 12:32 US/Pacific. Our engineers then reviewed and tuned the stability and performance of both this and related serving jobs globally before declaring the incident fully resolved.</p>\n<p>Google is committed to quickly and continually improving our technology and operations to prevent service disruptions. We appreciate your patience and apologize again for the impact to your organization. We thank you for your business. We are committed to preventing a repeat of this issue in the future and are completing the following actions:</p>\n<ul>\n<li>Enhance metrics and dashboards to make these complex load-balancing dynamics more legible to engineers, reducing the time to mitigate similar future issues.</li>\n<li>Improve performance-testing of resource-allocation profiles for each individual serving job</li>\n</ul>\n<h2>Detailed Description of Impact</h2>\n<p><strong>Google Workspace:</strong></p>\n<ul>\n<li>During the issue, a limited number Google Workspace users served from this data center had issues with log-in and sign-up for part of unauthenticated traffic, including some users going through &quot;Sign in with Google &#39;&#39; interactive flows using their Google Workspace account</li>\n<li>Multiple Google Workspace product log-in attempts, reauthentication attempts, and some new account creation requests from users routed to this data center failed with error 502s.</li>\n<li>Users that were already logged in were not affected by the issue.</li>\n</ul>\n<p><strong>Google OAuth:</strong></p>\n<ul>\n<li>Some users served from this data center intermittently experienced error 502s when attempting to &quot;Sign in with Google&quot; and encountering interactive sign-in or re-authentication flows.</li>\n</ul>\n<p><strong>Google Cloud Console:</strong></p>\n<ul>\n<li>A limited number of  users served from this data center experienced error 502s intermittently when attempting to log-in to the Cloud Console.</li>\n</ul>\n<hr>\n</div><hr><p>Affected products: Classroom</p>",
          "link": "https://www.google.com/appsstatus/dashboard/incidents/jPWZ4p7bTSq65P1b9Gfn",
          "publishedOn": "2023-12-14T00:45:03.000Z",
          "wordCount": 1136,
          "title": "RESOLVED: We're investigating reports of an issue with Classroom. We will provide more information shortly.",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "GitHub Status - Incident History",
      "feedUrl": "https://www.githubstatus.com/history.rss",
      "siteUrl": "https://www.githubstatus.com",
      "articles": [
        {
          "id": "https://www.githubstatus.com/incidents/1ksntt4bk3bq",
          "author": null,
          "description": "Dec 29, 21:21 UTC\nResolved - This incident has been resolved.\nDec 29, 21:09 UTC\nUpdate - We are in the process of reverting a change that introduced these failures.\nDec 29, 20:05 UTC\nUpdate - We‚Äôre investigating reports of increased failure rates for migrations with GitHub Enterprise Importer and exports using the Organization Migrations REST API.\nDec 29, 20:05 UTC\nInvestigating - We are currently investigating this issue.",
          "link": "https://www.githubstatus.com/incidents/1ksntt4bk3bq",
          "publishedOn": "2023-12-29T21:21:38.000Z",
          "wordCount": 5059,
          "title": "We are investigating reports of degraded performance.",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/464b7g25n77j",
          "author": null,
          "description": "Dec 29, 18:33 UTC\nResolved - This incident has been resolved.\nDec 29, 18:31 UTC\nUpdate - With a mitigation deploying, we see recovery in most API requests and are continuing to monitor full rollout and mitigation.\nDec 29, 18:21 UTC\nUpdate - Secret Scanning and potentially other APIs are returning 500 error responses.  We're working on a mitigation.\nDec 29, 18:17 UTC\nInvestigating - We are investigating reports of degraded performance for API Requests",
          "link": "https://www.githubstatus.com/incidents/464b7g25n77j",
          "publishedOn": "2023-12-29T18:33:52.000Z",
          "wordCount": 5061,
          "title": "Incident with API Requests",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/1h37j1mb9xnx",
          "author": null,
          "description": "Dec 29, 02:04 UTC\nResolved - This incident has been resolved.\nDec 29, 01:41 UTC\nUpdate - Users without an existing valid session are unable to login and will see an error page.  We are working on a mitigation.\nDec 29, 01:41 UTC\nInvestigating - We are currently investigating this issue.",
          "link": "https://www.githubstatus.com/incidents/1h37j1mb9xnx",
          "publishedOn": "2023-12-29T02:04:44.000Z",
          "wordCount": 5039,
          "title": "We are investigating reports of degraded performance.",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/lt4kyp4tgx45",
          "author": null,
          "description": "Dec 28, 06:57 UTC\nResolved - This incident has been resolved.\nDec 28, 06:49 UTC\nUpdate - We have deployed a fix and email service should be restored shortly.\nDec 28, 06:48 UTC\nUpdate - We are experiencing issues sending some pull request, actions and other notification emails. Some emails may not be received as the result of activity on GitHub. Web and mobile push notifications are not affected.\nDec 28, 06:43 UTC\nInvestigating - We are currently investigating this issue.",
          "link": "https://www.githubstatus.com/incidents/lt4kyp4tgx45",
          "publishedOn": "2023-12-28T06:57:42.000Z",
          "wordCount": 5071,
          "title": "We are investigating reports of degraded performance.",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/hzd6d6xhjpl6",
          "author": null,
          "description": "Dec 27, 19:25 UTC\nResolved - This incident has been resolved.\nDec 27, 19:25 UTC\nUpdate - A recent update to an Action that GitHub Pages deployer service relies on impacted that service, and was corrected and redeployed.\nDec 27, 19:12 UTC\nUpdate - We've identified the cause of some Pages errors and are deploying a mitigating fix now.\nDec 27, 19:01 UTC\nUpdate - We continue to investigate issues with Pages, and will continue to keep users updated on progress towards mitigation.\nDec 27, 18:29 UTC\nUpdate - Pages workflow builds which use the actions actions/upload-pages-artifact@v3 and actions/deploy-pages@v4 are currently failing.\nDec 27, 18:29 UTC\nInvestigating - We are investigating reports of degraded performance for Pages",
          "link": "https://www.githubstatus.com/incidents/hzd6d6xhjpl6",
          "publishedOn": "2023-12-27T19:25:23.000Z",
          "wordCount": 5103,
          "title": "Incident with Pages",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/rp7669f45fjw",
          "author": null,
          "description": "Dec 27, 04:00 UTC\nResolved - This incident has been resolved.\nDec 27, 03:57 UTC\nUpdate - We have applied a fix and most customers should now be seeing recovery.\nDec 27, 03:14 UTC\nUpdate - Customers using Codespaces will be unable to connect to existing codespaces, create new ones, or export. We have identified the issue and are working on a remediation.\nDec 27, 03:09 UTC\nUpdate - Codespaces is experiencing degraded availability. We are continuing to investigate.\nDec 27, 02:53 UTC\nUpdate - Codespace services are experiencing connection issues\nDec 27, 02:53 UTC\nInvestigating - We are investigating reports of degraded availability for Codespaces",
          "link": "https://www.githubstatus.com/incidents/rp7669f45fjw",
          "publishedOn": "2023-12-27T04:00:57.000Z",
          "wordCount": 5092,
          "title": "Incident with Codespaces",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/xlm9bd5xq5bk",
          "author": null,
          "description": "Dec 27, 03:06 UTC\nResolved - This incident has been resolved.\nDec 27, 03:06 UTC\nUpdate - Codespaces is operating normally.\nDec 27, 02:51 UTC\nInvestigating - We are investigating reports of degraded performance for Codespaces and API Requests",
          "link": "https://www.githubstatus.com/incidents/xlm9bd5xq5bk",
          "publishedOn": "2023-12-27T03:06:56.000Z",
          "wordCount": 5031,
          "title": "Incident with Codespaces and API Requests",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/d3mfyt4nqnv5",
          "author": null,
          "description": "Dec 19, 22:50 UTC\nResolved - This incident has been resolved.\nDec 19, 22:25 UTC\nUpdate - Webhooks is operating normally.\nDec 19, 22:20 UTC\nUpdate - Issues is operating normally.\nDec 19, 22:14 UTC\nUpdate - Pull Requests is operating normally.\nDec 19, 22:12 UTC\nUpdate - We applied a configuration change to our database, and we are seeing a recovery.\nDec 19, 22:10 UTC\nUpdate - Packages is operating normally.\nDec 19, 21:58 UTC\nUpdate - Webhooks is experiencing degraded performance. We are continuing to investigate.\nDec 19, 21:45 UTC\nUpdate - We are seeing database connection issues among our applications. We are investigating the root cause.\nDec 19, 21:42 UTC\nUpdate - Pull Requests is experiencing degraded performance. We are continuing to investigate.\nDec 19, 21:42 UTC\nUpdate - Issues is experiencing degraded performance. We are continuing to investigate.\nDec 19, 21:12 UTC\nInvestigating - We are investigating reports of degraded performance for Packages",
          "link": "https://www.githubstatus.com/incidents/d3mfyt4nqnv5",
          "publishedOn": "2023-12-19T22:50:31.000Z",
          "wordCount": 5173,
          "title": "Incident with Packages, Issues, Pull Requests and Webhooks",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/476y2pqmb3hc",
          "author": null,
          "description": "Dec 18, 21:26 UTC\nResolved - At 2023-12-18 20:03 UTC, our monitoring flagged an increase in GitRPC response errors that resulted from a change that was made that caused backend replicas to temporarily become out of sync while the change was deployed. During this time, approximately 2,500 users across 8,200 repos would have seen the merge button disabled or received failures from the merge API endpoint.\nUpon discovering the failures, our engineers assessed that the shortest path to resolution was to roll forward and manually deploy to the remaining hosts, which resolved the issue at 2023-12-18 21:26.\nDec 18, 21:26 UTC\nUpdate - Git Operations is operating normally.\nDec 18, 21:19 UTC\nUpdate - We're seeing issues related to Pull Requests impacting a small number of users. We are aware deploying a fix and expect to resolve within the next 60 minutes.\nDec 18, 21:17 UTC\nInvestigating - We are investigating reports of degraded performance for Git Operations and Pull Requests",
          "link": "https://www.githubstatus.com/incidents/476y2pqmb3hc",
          "publishedOn": "2023-12-18T21:26:18.000Z",
          "wordCount": 5158,
          "title": "Incident with Git Operations and Pull Requests",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        }
      ]
    },
    {
      "title": "Slack System Status",
      "feedUrl": "https://status.slack.com/feed/rss",
      "siteUrl": "https://status.slack.com/",
      "articles": [
        {
          "id": "https://status.slack.com//2023-12/7f05f584fa98cf7c",
          "author": null,
          "description": "Issue summary:\n\r\nFrom 1:43 PM PST on December 19, 2023 to 10:25 AM PST on December 20, 2023, a small number of users experienced seeing blurred file previews. We discovered that this affected users with international data residency enabled in their workspace.\n\r\n\r\nA change was made to our file storage, resulting in unexpected behaviour with file previews. We promptly identified the problematic code and reverted back the change in an effort to prevent file previews from becoming blurred. \n\r\nWe later ran a script to fix affected files to display with clear previews, resolving the issue for all affected users.",
          "link": "https://status.slack.com//2023-12/7f05f584fa98cf7c",
          "publishedOn": "2023-12-21T02:01:15.000Z",
          "wordCount": 521,
          "title": "Incident: Users seeing blurred file unfurls",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-12/b0072b040087e20b",
          "author": null,
          "description": "Issue summary:\n\r\nOn December 3, 2023 from 4:35 PM PST to around 5:29 PM PST, a small number of customers experienced trouble loading parts of Slack such as threads, channels, and direct messages. Affected customers may have also had trouble sending messages and running some workflows.\n\r\n\r\nOne of our databases experienced a minor hardware issue. This triggered an automatic intervention from our redundancy systems, and a new database was brought into service. However, the new database entered a state where it could not successfully respond to incoming queries.\n\r\n\r\nAs an immediate mitigation step, we performed a manual replacement and redirected the incoming queries to a third database. This resolved the issue for all impacted customers.",
          "link": "https://status.slack.com//2023-12/b0072b040087e20b",
          "publishedOn": "2023-12-05T04:20:17.000Z",
          "wordCount": 286,
          "title": "Incident: Trouble loading some parts of Slack",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        }
      ]
    },
    {
      "title": "Make Status - Incident History",
      "feedUrl": "https://status.make.com/history.rss",
      "siteUrl": "https://status.make.com",
      "articles": [
        {
          "id": "https://status.make.com/incidents/y8fk51rrxg9q",
          "author": null,
          "description": "Dec 20, 17:44 CET\nResolved - This incident has been resolved.\nDec 20, 14:40 CET\nUpdate - We are continuing to monitor for any further issues.\nDec 20, 14:32 CET\nMonitoring - The queue of messages has been fully processed and the system has returned back to normal operation. Shared hooks are now delivered without delays. We will now continue to monitor the systems and ensure that there is no regression.\nDec 20, 13:09 CET\nUpdate - We have implemented and validated a solution to the underlying problem. The queue of hooks is now being processed at an accelerated pace and we expect to return to normal operation in the following 90 minutes. The average hook processing delay is approximately 3 hours.\nDec 20, 12:31 CET\nIdentified - We have taken the necessary steps to stabilize the situation and started processing the queue of hooks at a faster pace. The main issue still persists and shared hooks are currently being processed with a significant delay.\nDec 20, 11:08 CET\nUpdate - Our engineers are currently pursuing two hypotheses with the goal to remediate the issue. We will post another update latest in an hour.\nDec 20, 09:40 CET\nInvestigating - The issue still persists and shared hooks are being processed with a delay. The team is working towards addressing the root cause of the issue.\nDec 20, 07:15 CET\nMonitoring - We have identified the issue and applied a fix. Currently shared hooks are responding but might be delayed.\nDec 20, 06:21 CET\nInvestigating - We are currently experiencing issues with some of our services responsible for shared hooks on our clusters.\nShared hooks might currently be unresponsive. We are actively investigating the issue.",
          "link": "https://status.make.com/incidents/y8fk51rrxg9q",
          "publishedOn": "2023-12-20T16:44:01.000Z",
          "wordCount": 4113,
          "title": "Unresponsive shared hooks",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.make.com/incidents/671c34fz9z5z",
          "author": null,
          "description": "Dec 13, 14:18 CET\nResolved - The platform remains stable. The root cause has been identified, and we will actively work on the matter to prevent future reoccurrences.\nDec 12, 15:12 CET\nMonitoring - We have identified delays in scenario executions due to intermittent network issues affecting communication between our platform and one of our third-party services. We are actively working with the provider to investigate this and will share more information as soon as it becomes available.\nDec 12, 14:15 CET\nUpdate - The zone is currently stable. Scenario execution duration times are back to normal. We are still investigating the culprit.\nDec 12, 13:45 CET\nInvestigating - We are currently experiencing issues with increased scenario execution and webhook response times. We are actively investigating the issue and we will provide an update within the next 15 minutes.",
          "link": "https://status.make.com/incidents/671c34fz9z5z",
          "publishedOn": "2023-12-13T13:18:17.000Z",
          "wordCount": 3960,
          "title": "Delay in scenario executions on eu1.make.celonis.com",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.make.com/incidents/hfzsmxh14lmh",
          "author": null,
          "description": "Dec 12, 13:02 CET\nCompleted - The scheduled maintenance has been completed.\nDec 12, 10:22 CET\nVerifying - Verification is currently underway for the maintenance items.\nDec  5, 09:57 CET\nScheduled - Hello,\nPlease note that there is a scheduled Make Statuspage maintenance on 12.12.2023, 9-10 AM CET, during which the Make Statuspage will not be available.\nThank you very much for your understanding.\nKind regards,\nMake team",
          "link": "https://status.make.com/incidents/hfzsmxh14lmh",
          "publishedOn": "2023-12-12T12:02:50.000Z",
          "wordCount": 3879,
          "title": "Planned maintenance on status.make.com",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    }
  ],
  "cliVersion": "1.15.1"
}