{
  "sources": [
    {
      "title": "BookingSync.com news",
      "feedUrl": "https://changelog.bookingsync.com/rss",
      "siteUrl": "https://changelog.bookingsync.com",
      "articles": []
    },
    {
      "title": "Security Bulletins on Tailscale",
      "feedUrl": "https://tailscale.com/security-bulletins/index.xml",
      "siteUrl": "https://tailscale.com/security-bulletins/",
      "articles": []
    },
    {
      "title": "Airbnb API Status - Incident History",
      "feedUrl": "https://airbnbapi.statuspage.io/history.rss",
      "siteUrl": "https://airbnbapi.statuspage.io",
      "articles": [
        {
          "id": "https://airbnbapi.statuspage.io/incidents/tx6z0zm2rfmg",
          "author": null,
          "description": "Jun 22, 15:09 PDT\nResolved - This incident has been mitigated. Please apply any failed requests that were made during the incident time.\nJun 22, 13:26 PDT\nInvestigating - We are actively investigating an increased number of 500 errors across multiple endpoints. These errors started today (June 22, 2023) around 12:30 PM PDT. Our engineering teams are working to get everything up and running again and we will update you with the latest information as soon as possible.",
          "link": "https://airbnbapi.statuspage.io/incidents/tx6z0zm2rfmg",
          "publishedOn": "2023-06-22T22:09:15.000Z",
          "wordCount": 3336,
          "title": "500 Errors Across Multiple Endpoints",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://airbnbapi.statuspage.io/incidents/620bns7c4y3p",
          "author": null,
          "description": "Jun 20, 14:10 PDT\nResolved - This incident has been resolved. We have restored the correct bedroom, bathroom and bed count on the Listings API.\nJun 15, 20:37 PDT\nUpdate - We have implemented a fix to restore the correct bedrooms, bathrooms and bed values on the Listings API and will continue to monitor this incident.\nWe apologize for any inconvenience this may cause and appreciate your understanding as we resolve this issue.\nJun 15, 14:38 PDT\nMonitoring - We are currently addressing a bug that affects the bedroom, bathroom, and bed count on our Listings API. Due to a change in behavior of how bedrooms, bathrooms and beds interact with the Listing Rooms API, you might come across the following issues:\n* On the Listings API, some listings might have the fields `bedrooms`,`bathrooms` and/or `beds` set to 0.\n* On the Listings Rooms API, some rooms might have been created/deleted.\nAs of today, we have reverted the problematic behavior and are working diligently to restore the correct bedrooms, bathrooms, and beds values on the Listings API. To ensure that your Listing Rooms are accurately set, we kindly ask you to re-sync your data.\nWe apologize for any inconvenience this may cause and appreciate your understanding as we resolve this issue.",
          "link": "https://airbnbapi.statuspage.io/incidents/620bns7c4y3p",
          "publishedOn": "2023-06-20T21:10:48.000Z",
          "wordCount": 3472,
          "title": "Issue affecting listings bedrooms, bathrooms and beds",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://airbnbapi.statuspage.io/incidents/qn4kgtck381x",
          "author": null,
          "description": "Jun 19, 07:46 PDT\nResolved - This incident has been resolved. However, there remains a minor possibility that reservation acceptance confirmation webhooks may be sent without the guest's last name due to an Airbnb race condition. In case you encounter this issue, please  you can retrieve the missing information with the GET Reservations API.\nWe apologize for the inconvenience this may have caused and don't hesitate to reach out if you have any questions, or require further assistance.\nJun 14, 16:46 PDT\nIdentified - Unfortunately, the mitigation did not resolve the issue and we are still seeing reservation acceptance confirmation webhooks missing the guest last name. Please know our engineering teams are working to get this issue resolved, and we will update you with the latest information as soon as possible. Meanwhile, please use the GET reservations API for any reservations that did not include the guest last name within the webhooks. We apologize for the inconvenience.\nJun 12, 08:41 PDT\nMonitoring - We have implemented a fix for this issue and are monitoring the results. Apologies for the inconvenience caused.\nJun  9, 00:12 PDT\nIdentified - The issue has been identified and we are working on a fix.\nMeanwhile, please attempt GET reservations requests for any reservations that did not include the guest names in full within the webhooks.\nJun  8, 19:36 PDT\nInvestigating - We are currently investigating an issue where guest names are not returned in full within webhooks - namely the reservation acceptance confirmation webhooks. This is not a widespread issue and is only affecting a small percentage of webhooks.\nAlternatively, you may be able to retrieve the details with GET reservations requests.\nWe will post updates as soon as we know more.\nApologies for the inconvenience caused and thank you for your understanding.",
          "link": "https://airbnbapi.statuspage.io/incidents/qn4kgtck381x",
          "publishedOn": "2023-06-19T14:46:01.000Z",
          "wordCount": 3563,
          "title": "Issues Affecting Guest Name Parameters in Webhooks",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://airbnbapi.statuspage.io/incidents/vl5ppdvchsjb",
          "author": null,
          "description": "Jun 19, 00:00 PDT\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nJun 16, 14:55 PDT\nScheduled - The deprecation date for API Webhook Version 2021.12.31 was May 31, 2023. Any applications that have not fully migrated webhooks will be automatically migrated to a newer version, which can result in application breakage.\nAutomatic webhook migration will occur in phases as detailed in https://developer.airbnb.com/docs/versioning-enforcement\nPhase 2 will occur during the week of June 19th, 2023 and will automatically migrate all Messaging, Reviews, and Reservations webhooks.",
          "link": "https://airbnbapi.statuspage.io/incidents/vl5ppdvchsjb",
          "publishedOn": "2023-06-19T07:00:37.000Z",
          "wordCount": 3358,
          "title": "v2021.12.31 Webhook Migration Enforcement - Phase 2",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://airbnbapi.statuspage.io/incidents/bf02v30139sd",
          "author": null,
          "description": "Jun 17, 00:00 PDT\nCompleted - The scheduled maintenance has been completed.\nJun 13, 00:00 PDT\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nJun 12, 11:00 PDT\nScheduled - The deprecation date for API Webhook Version 2021.12.31 was May 31, 2023. Any applications that have not fully migrated webhooks will be automatically migrated to a newer version, which can result in application breakage.\nAutomatic webhook migration will occur in phases as detailed in https://developer.airbnb.com/docs/versioning-enforcement\nPhase 1 will occur during the week of June 12th, 2023 and will automatically migrate all async webhooks (except Messaging, Reviews and Reservations).",
          "link": "https://airbnbapi.statuspage.io/incidents/bf02v30139sd",
          "publishedOn": "2023-06-17T07:00:20.000Z",
          "wordCount": 3370,
          "title": "v2021.12.31 Webhook Migration Enforcement - Phase 1",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://airbnbapi.statuspage.io/incidents/l4t3crp7lr61",
          "author": null,
          "description": "Jun 16, 18:52 PDT\nResolved - This incident has now been resolved.\nJun 16, 16:38 PDT\nMonitoring - An issue has been deployed and we are monitoring the results - the 500 error rate has significantly dropped.\nJun 16, 15:44 PDT\nIdentified - We are actively investigating an increased number of 500 errors and an increase in latency across multiple endpoints. These errors started today (June 16, 2023) around 14:20 PDT. If your API requests fail with a 500, please retry them. Our engineering teams are working to get everything up and running again and we will update you with the latest information as soon as possible.",
          "link": "https://airbnbapi.statuspage.io/incidents/l4t3crp7lr61",
          "publishedOn": "2023-06-17T01:52:37.000Z",
          "wordCount": 3367,
          "title": "500 Errors Across Multiple Endpoints",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://airbnbapi.statuspage.io/incidents/xccq5r4gm6c5",
          "author": null,
          "description": "Jun  2, 08:35 PDT\nResolved - This issue is now resolved. The incident that occurred yesterday (June 1, 2023) resulted in an elevated amount of 500 errors across multiple endpoints, for approximately 1 hour. If you are still encountering a high volume of 500 errors, please reach out to us through the Support Portal so we can assist you further.\nWe apologize for any inconvenience this may have caused.\nJun  1, 13:34 PDT\nMonitoring - We have implemented a fix for the issue, and the error rate has dropped significantly. We will continue to monitor the results\nJun  1, 12:51 PDT\nIdentified - We are actively investigating an increased number of 500 errors across multiple endpoints. These errors started today (June 1, 2023) around 12:20 PM PDT. Please know our engineering and operations teams are working hard to get everything up and running again, and we will update you with the latest information as soon as possible",
          "link": "https://airbnbapi.statuspage.io/incidents/xccq5r4gm6c5",
          "publishedOn": "2023-06-02T15:35:47.000Z",
          "wordCount": 3416,
          "title": "500 Errors Across Multiple Endpoints",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    },
    {
      "title": "Twilio Status - Incident History",
      "feedUrl": "https://status.twilio.com/history.rss",
      "siteUrl": "https://status.twilio.com",
      "articles": [
        {
          "id": "https://status.twilio.com/incidents/vn2c1vhp9t19",
          "author": null,
          "description": "THIS IS A SCHEDULED EVENT Jun 22, 23:00 PDT  -  Jun 23, 05:00 PDT\nJun 21, 01:15 PDT\nScheduled - The AT&T network in Mexico is conducting a planned maintenance from 22 June 2023 at 23:00 PDT until 23 June 2023 at 05:00 PDT. During the maintenance window, there could be intermittent delays delivering SMS to and from AT&T Mexico handsets.",
          "link": "https://status.twilio.com/incidents/vn2c1vhp9t19",
          "publishedOn": "2023-06-23T06:00:00.000Z",
          "wordCount": 6254,
          "title": "Mexico SMS Carrier Maintenance - AT&T Mexico",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/6y0bbhfqbwhq",
          "author": null,
          "description": "THIS IS A SCHEDULED EVENT Jun 22, 21:00 - 23:00 PDT\nJun 19, 11:02 PDT\nScheduled - The Telcel network in Mexico is conducting a planned maintenance from 22 June 2023 at 21:00 PDT until 22 June 2023 at 23:00 PDT. During the maintenance window, there could be intermittent delays delivering SMS to and from Telcel Mexico handsets",
          "link": "https://status.twilio.com/incidents/6y0bbhfqbwhq",
          "publishedOn": "2023-06-23T04:00:00.000Z",
          "wordCount": 6255,
          "title": "Mexico SMS Carrier Maintenance - Telcel",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/8jjrzrx3dqv2",
          "author": null,
          "description": "THIS IS A SCHEDULED EVENT Jun 22, 19:00 - 23:00 PDT\nJun 22, 08:05 PDT\nScheduled - Our Carrier Partner Verizon Wireless US is conducting an emergency maintenance from 22 June 2023 at 19:00 PDT until 22 June 2023 at 23:00 PDT. During the maintenance window, there could be intermittent API request failures for Verizon Wireless US customers.\nImpacted Products: SNA, Lookup SIM Swap and Identity Match.",
          "link": "https://status.twilio.com/incidents/8jjrzrx3dqv2",
          "publishedOn": "2023-06-23T02:00:00.000Z",
          "wordCount": 6266,
          "title": "United States Account Security Carrier Partner Maintenance",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/snxz0bj2fw50",
          "author": null,
          "description": "Jun 22, 17:12 PDT\nIdentified - Our engineers have identified the issue causing the Flex Queue Stats to not refresh properly, and have deployed a fix. New task queues will now report correct statistics. However, task queues that were already affected may continue to show incorrect statistics. Our engineering team is actively working to fix the corrupted data. We expect to provide another update in 4 hours or as soon as more information becomes available.\nJun 22, 14:34 PDT\nUpdate - We are still investigating an issue with Flex Queue Stats. The Waiting Task counter is not refreshing properly, therefore, customers may experience piling up with tasks that are no longer waiting. We expect to provide another update in 4 hours or as soon as more information becomes available.\nJun 22, 12:37 PDT\nUpdate - We continue investigating an issue with Flex Queue Stats. The Waiting Task counter is not refreshing properly, therefore, customers may experience piling up with tasks that are no longer waiting. We expect to provide another update in 2 hours or as soon as more information becomes available.\nJun 22, 11:32 PDT\nUpdate - We are investigating an issue with Flex Queue Stats. The Waiting Task counter is not refreshing properly, therefore, customers may experience piling up with tasks that are no longer waiting. We expect to provide another update in 1 hour or as soon as more information becomes available.\nJun 22, 11:18 PDT\nInvestigating - Our monitoring systems have detected a potential issue with Flex Insights. Our engineering team has been alerted and is actively investigating. We will update as soon as we have more information.",
          "link": "https://status.twilio.com/incidents/snxz0bj2fw50",
          "publishedOn": "2023-06-23T00:12:00.000Z",
          "wordCount": 6474,
          "title": "Flex Queue Stats Not Refreshing Properly",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/d5r39t3hlx0t",
          "author": null,
          "description": "Jun 22, 16:42 PDT\nResolved - We are no longer experiencing SMS delivery delays when sending messages to Glo Mobile Network in Nigeria. This incident has been resolved.\nJun 22, 14:42 PDT\nMonitoring - We are observing recovery in SMS delivery delays when sending messages to Glo Mobile Network in Nigeria. We will continue monitoring the service to ensure a full recovery. We will provide another update in 2 hours or as soon as more information becomes available.\nJun 22, 11:14 PDT\nUpdate - We continue experiencing SMS delivery delays when sending messages to Glo Mobile Network in Nigeria. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 4 hours or as soon as more information becomes available.\nJun 22, 09:17 PDT\nUpdate - We are still experiencing SMS delivery delays when sending messages to Glo Mobile Network in Nigeria. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 2 hours or as soon as more information becomes available.\nJun 22, 08:17 PDT\nInvestigating - We are experiencing SMS delivery delays when sending messages to Glo Mobile Network in Nigeria. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 1 hour or as soon as more information becomes available.",
          "link": "https://status.twilio.com/incidents/d5r39t3hlx0t",
          "publishedOn": "2023-06-22T23:42:03.000Z",
          "wordCount": 6431,
          "title": "SMS Delivery Delays to Glo Mobile Network",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/rrdnqybl0ryn",
          "author": null,
          "description": "Jun 22, 16:06 PDT\nResolved - The issue causing devices using Super SIM to experience missing OTA updates has been resolved, and it is operating normally at this time.\nJun 22, 15:06 PDT\nUpdate - We are now seeing recovery of the issue causing devices using Super SIM to experience missing OTA updates. We are continuing to monitor for service stability. We will provide another update in 1 hour or as soon as more information becomes available.\nJun 22, 12:58 PDT\nMonitoring - We are now seeing recovery of the issue causing devices using Super SIM to experience missing OTA updates. We are continuing to monitor for service stability. We will provide another update in 2 hours or as soon as more information becomes available.\nJun 22, 12:42 PDT\nUpdate - The issue causing devices using Super SIM to experience missing OTA updates has been identified. The affected service on the partner’s side has been restarted. We are checking if the missing events could be replayed. We will provide another update in 2 hours or sooner once more information becomes available.\nJun 22, 10:56 PDT\nIdentified - The issue causing a small set of devices (less than 1%) using Super SIM has been identified. We are working with our partners to investigate the root cause. We will provide another update in 2 hours or as soon as more information becomes available.\nJun 22, 09:52 PDT\nUpdate - We have identified that since 13th of June there could be an issue where a small set of devices using Super SIM won’t receive any OTA updates. We are actively working to identify and resolve the issue. Likewise, we will provide another update in 1 hour or sooner once more information becomes available.\nJun 22, 09:45 PDT\nInvestigating - Our monitoring systems have detected a potential issue with Super SIM. Our engineering team has been alerted and is actively investigating. We will update as soon as we have more information.",
          "link": "https://status.twilio.com/incidents/rrdnqybl0ryn",
          "publishedOn": "2023-06-22T23:06:32.000Z",
          "wordCount": 6543,
          "title": "Devices Using Super SIM May Experience Issues Receiving OTA Updates",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/f4g44v8ktf3z",
          "author": null,
          "description": "Jun 22, 16:02 PDT\nResolved - Programmable Messaging Link Shortening was degraded for 10 hours between 12:00 AM and 10:00 AM Pacific Time. During this period of time, customers may have experienced issues with shortening links as part of sending messages. The issue has now been resolved.\nJun 22, 15:19 PDT\nInvestigating - Our monitoring systems have detected a potential issue with Link Shortener. Our engineering team has been alerted and is actively investigating. We will update as soon as we have more information.",
          "link": "https://status.twilio.com/incidents/f4g44v8ktf3z",
          "publishedOn": "2023-06-22T23:02:04.000Z",
          "wordCount": 6279,
          "title": "Links in a Subset of Messages Were not Shortened",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/ndk65s38fy3q",
          "author": null,
          "description": "Jun 22, 13:37 PDT\nUpdate - We still continue experiencing SMS delivery delays when sending messages to Airtel network in India. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 4 hours or as soon as more information becomes available.\nJun 22, 11:44 PDT\nUpdate - We continue experiencing SMS delivery delays when sending messages to Airtel network in India. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 2 hours or as soon as more information becomes available.\nJun 22, 10:45 PDT\nInvestigating - We are experiencing SMS delivery delays when sending messages to Airtel network in India. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 1 hour or as soon as more information becomes available.",
          "link": "https://status.twilio.com/incidents/ndk65s38fy3q",
          "publishedOn": "2023-06-22T20:37:45.000Z",
          "wordCount": 6350,
          "title": "SMS Delivery Delays to Airtel Network in India",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/sm2bpxs38k37",
          "author": null,
          "description": "Jun 22, 11:47 PDT\nMonitoring - We are observing successful SMS delivery to Etisalat and DU networks in the United Arab Emirates, using Domestic Sender ID’s. We will continue to monitor to ensure full service recovery. We expect to provide another update in 12 hours or as soon as more information becomes available.\nJun 22, 11:01 PDT\nUpdate - We are still experiencing SMS delivery failures when sending messages to Etisalat and DU networks in the United Arab Emirates, using Domestic Sender ID’s. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 1 hour or as soon as more information becomes available.\nJun 22, 09:03 PDT\nUpdate - We are experiencing SMS delivery failures when sending messages to Etisalat and DU networks in the United Arab …",
          "link": "https://status.twilio.com/incidents/sm2bpxs38k37",
          "publishedOn": "2023-06-22T18:47:11.000Z",
          "wordCount": 6634,
          "title": "Delivery Failures to Etisalat and DU Networks in United Arab Emirates Using Domestic Sender ID's",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/n7wbrxftxkfj",
          "author": null,
          "description": "Jun 22, 09:27 PDT\nResolved - The issue with undelivered SMS traffic towards Etisalat UAE with Authy/Verify has been resolved, and the service is functioning normally at this time.\nJun 22, 08:56 PDT\nMonitoring - We have started seeing recovery for undelivered SMS traffic towards Etisalat UAE with Authy/Verify. We will continue to monitor to ensure a full recovery. We expect to provide another update in 30 minutes or as soon as more information becomes available.\nJun 22, 04:50 PDT\nUpdate - We are currently investigating an issue with undelivered SMS traffic towards Etisalat UAE with Authy/Verify. We expect to provide another update in 4 hours or as soon as more information becomes available.\nJun 22, 02:51 PDT\nUpdate - We are investigating an issue with undelivered SMS traffic towards Etisalat UAE with Authy/Verify. We expect to provide another update in 2 hours or as soon as more information becomes available.\nJun 22, 02:04 PDT\nInvestigating - We are investigating an issue with undelivered SMS traffic towards Etisalat UAE with Authy/Verify. We expect to provide another update in 1 hour or as soon as more information becomes available",
          "link": "https://status.twilio.com/incidents/n7wbrxftxkfj",
          "publishedOn": "2023-06-22T16:27:58.000Z",
          "wordCount": 6402,
          "title": "Undelivered SMS Traffic Towards Etisalat UAE With Authy/Verify",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/wx0mbs6yd2rg",
          "author": null,
          "description": "Jun 22, 04:00 PDT\nCompleted - The scheduled maintenance has been completed.\nJun 21, 21:00 PDT\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nJun 16, 16:04 PDT\nScheduled - The AT&T network in the US is conducting a planned maintenance from 21 June 2023 at 21:00 PDT until 22 June 2023 at 04:00 PDT. During the maintenance window, there could be intermittent delays delivering SMS and MMS to and from AT&T US handsets.",
          "link": "https://status.twilio.com/incidents/wx0mbs6yd2rg",
          "publishedOn": "2023-06-22T11:00:10.000Z",
          "wordCount": 6296,
          "title": "US SMS/MMS Carrier Maintenance - AT&T",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/dfxqcdrpylwn",
          "author": null,
          "description": "Jun 21, 23:00 PDT\nCompleted - The scheduled maintenance has been completed.\nJun 21, 22:00 PDT\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nJun 16, 09:37 PDT\nScheduled - Our Global Carrier Partner Three UK is conducting a planned maintenance from 21 June 2023 at 22:00 PDT until 21 June 2023 at 23:00 PDT. During the maintenance window, there could be intermittent API request failures for the following destinations: Austria, Indonesia, Italy, UK\nImpacted Products - Carrier\nSilent Network Authentication (SNA) - 3 Indonesia, Wind (Tre) Italy, Three UK\nLookup SIM Swap - 3 Austria, Wind (Tre) Italy, Three UK\nIdentity Match - Wind (Tre) Italy, Three UK",
          "link": "https://status.twilio.com/incidents/dfxqcdrpylwn",
          "publishedOn": "2023-06-22T06:00:20.000Z",
          "wordCount": 6323,
          "title": "Global Account Security Carrier Partner Maintenance -Three UK",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/s5zy5qgllk7w",
          "author": null,
          "description": "Jun 21, 22:00 PDT\nCompleted - The scheduled maintenance has been completed.\nJun 21, 14:00 PDT\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nJun 21, 13:05 PDT\nScheduled - Our SMS carrier partner in Ireland is conducting an emergency maintenance from 21 June 2023 at 14:00 PDT until 21 June 2023 at 22:00 PDT. During the maintenance window, there could be intermittent delays delivering SMS to and from Ireland handsets via short codes.",
          "link": "https://status.twilio.com/incidents/s5zy5qgllk7w",
          "publishedOn": "2023-06-22T05:00:43.000Z",
          "wordCount": 6275,
          "title": "Ireland SMS Carrier Partner Maintenance",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    },
    {
      "title": "DigitalOcean Status - Incident History",
      "feedUrl": "https://status.digitalocean.com/history.rss",
      "siteUrl": "http://status.digitalocean.com",
      "articles": [
        {
          "id": "https://status.digitalocean.com/incidents/9hwth0p75c6y",
          "author": null,
          "description": "Jun 21, 18:05 UTC\nResolved - Our Engineering team has confirmed that the issue impacting our Functions service has been fully resolved. If you continue to experience any issues in relation to this incident please open a ticket with our support team. Thank you for your patience.\nJun 21, 17:11 UTC\nMonitoring - Functions in BLR1 region are now restored to normal service. As of 17:00 UTC, all impact has been mitigated and users should no longer experience any issues with the Functions. We are monitoring the situation and will post an update once the incident is completely resolved.\nThank you for your patience and we apologize for the inconvenience.\nJun 21, 16:50 UTC\nUpdate - Functions in FRA1 and LON1 are now restored to normal service. We continue work to remediate BLR1.\nOur Engineering team has discovered that some Function invocations were duplicated, so a subset of users may have experienced that during the course of this incident.\nWe will post an update once the last region has returned to normal service.\nJun 21, 16:01 UTC\nIdentified - Our Engineering team has been working in order to restore the Functions service. At this time, normal service has been restored in most of the regions including AMS3, SGP1, TOR1, and SYD1.\nWe’re now working to fully remediate the remaining regions: BLR1, FRA1, and LON1. We will post an update as soon as that has completed. Thank you for your patience!\nJun 21, 15:43 UTC\nInvestigating - Beginning 14:37 UTC, our Engineering team has identified an issue impacting Functions in AMS3, BLR1, FRA1, LON1, SGP1, SYD1, and TOR1. During this time, users with standalone Functions or Functions deployed through Apps may experience performance degradation, leading to delays in Functions invocations and/or Functions working more slowly than normal.\nOur team is working to mitigate the issue and we will provide an update as soon as possible.",
          "link": "https://status.digitalocean.com/incidents/9hwth0p75c6y",
          "publishedOn": "2023-06-21T18:05:27.000Z",
          "wordCount": 5280,
          "title": "Degraded Functions Service",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/bclmy32d12p0",
          "author": null,
          "description": "Jun 21, 14:31 UTC\nResolved - From 12:00 - 13:40 UTC our Engineering team observed an issue with network connectivity to US-EAST-1 and US-EAST-2 (AWS) from European datacenter regions including DigitalOcean's AMS, FRA & LON datatancers. During this time, a subset of users might have experienced high latency or errors while connecting to  services, including Droplets and Droplet-based products. We also received reports of issues in pushing/pulling images to and from DigitalOcean Container Registries. \nAs of 13:40 UTC the impact has been subsided and users should no longer be facing network connectivity issues. We apologize for the inconcenience and if you are still experiencing issues or have any additional questions then please open a support ticket from within your account.",
          "link": "https://status.digitalocean.com/incidents/bclmy32d12p0",
          "publishedOn": "2023-06-21T14:31:05.000Z",
          "wordCount": 5078,
          "title": "Network Connectivity in European Regions",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/7dgq9yz9ch1n",
          "author": null,
          "description": "Jun 16, 19:00 UTC\nResolved - From 19:12 - 19:40 UTC, we experienced an issue with Volumes and Snapshots endpoints. During that time, we saw elevated 500 errors and a subset of users experienced latency or errors while loading the Volumes or Images tab in the Cloud Control Panel. A subset of users also experienced errors in both the Cloud Control Panel and the API for CRUD (create, read, update, and delete) operations on Volumes and Snapshots. \nOur Engineering team was able to identify the root cause and quickly deployed a configuration fix to resolve the situation.  \nWe apologize for the inconvenience. If you are still experiencing any problems or have additional questions, please open a support ticket within your account.",
          "link": "https://status.digitalocean.com/incidents/7dgq9yz9ch1n",
          "publishedOn": "2023-06-16T19:00:00.000Z",
          "wordCount": 5085,
          "title": "Elevated Error Rate for Volumes and Snapshots",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/1d5qv6pmsv6b",
          "author": null,
          "description": "Jun 15, 03:37 UTC\nResolved - Our Engineering team has confirmed the full resolution of the issue impacting networking in our European regions.\nFrom 16:40 UTC to 02:10 UTC, Users may have experienced network timeouts, packet loss, and/or increased latency interacting with the resources in these regions (AMS2/3, FRA1 & LON1).\nIf you continue to experience problems, please open a ticket with our Support team. Thank you for your patience and we apologize for the inconvenience.\nJun 15, 02:40 UTC\nMonitoring - The network issues affecting our European regions have been mitigated. Users should no longer experience packet loss/latency, timeouts, and related issues with Droplet-based services in those regions, including Droplets, Managed Kubernetes, and Managed Database.\nWe will continue to monitor network conditions for a period of time to establish a return to pre-incident conditions.\nJun 15, 01:26 UTC\nUpdate - Our engineering team continues to investigate the ongoing issues impacting the networking in our European data centres including AMS2/3, FRA1 & LON1 regions. During this time, you may experience intermittent packet loss or increased latency while interacting with the resources in these regions. We apologize for the inconvenience and will share an update once we have more information.\nJun 14, 20:06 UTC\nInvestigating - From 16:40 UTC our Engineering team is investigating an issue impacting the networking in our European data centers including AMS2/3, FRA1 & LON1 regions. During this time, you may experience intermittent packet loss or increased latency while interacting with the resources in these regions.\nAt the moment, all the droplet-based services appear to be impacted and the users can expect to see brief connectivity issues and interrupted traffic flows. This will also be impacting services including Spaces and Managed Databases. \nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/1d5qv6pmsv6b",
          "publishedOn": "2023-06-15T03:37:51.000Z",
          "wordCount": 5274,
          "title": "Networking in Europe Datacenters (AMS, FRA, LON)",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/rptq6jh8ljd7",
          "author": null,
          "description": "Jun 12, 17:44 UTC\nResolved - From 04:30 to 09:30 UTC, our Engineering team observed issues with DigitalOcean Container Registry in SGP1 and FRA1 regions. During this time, users might have experienced errors while interacting with their registries in SGP1 and FRA1 regions. Users might also have experienced latency in pushing/pulling images to/from registries.\nOur Engineering team has observed that the impact has been mitigated. As of 17:20 UTC, users should no longer experience any issues with pushing/pulling images to/from their registries in SGP1 and FRA1 regions. We apologize for the inconvenience. If you are still experiencing any problems or have additional questions, please open a support ticket within your account.",
          "link": "https://status.digitalocean.com/incidents/rptq6jh8ljd7",
          "publishedOn": "2023-06-12T17:44:00.000Z",
          "wordCount": 5071,
          "title": "Container Registry in FRA1 and SGP1",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/5jvv4xltnbk7",
          "author": null,
          "description": "Jun  8, 22:53 UTC\nResolved - Our Engineering team has confirmed that the issue impacting the modification of the DNS records for the existing domains via the Cloud Control Panel is fully resolved. \nIf you continue to experience problems please open a ticket with our support team. Thank you for your patience and we apologize for the inconvenience.\nJun  8, 22:31 UTC\nMonitoring - Our engineering team has implemented a fix to resolve the issue that affected the modification of the DNS records for the existing domains via the Cloud Control Panel. Users should now be able to modify or create new DNS records for the domains within their Cloud Control Panel.\nWe are monitoring the situation and will post another update once we confirm it is fully resolved.\nJun  8, 21:56 UTC\nInvestigating - Our Engineering team is investigating an issue with modifying or creating new DNS records in our Cloud Control Panel for the existing domains. \nDuring this time, some users may experience issues editing the DNS records from within the Cloud Control Panel and also when navigating through the tabs available in the domain section. Users should be able to modify or add new DNS records to the existing domains using the API.\nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/5jvv4xltnbk7",
          "publishedOn": "2023-06-08T22:53:00.000Z",
          "wordCount": 5193,
          "title": "Modifying DNS records via Cloud Control Panel",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/tw85s4rhwpqm",
          "author": null,
          "description": "Jun  8, 08:00 UTC\nCompleted - The scheduled maintenance has been completed.\nJun  8, 04:00 UTC\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nJun  8, 03:08 UTC\nScheduled - Start time: 2023-06-08 04:00 UTC\nEnd time: 2023-06-08 08:00 UTC\nDuring the above window, our Networking team will be performing maintenance on core switches in our NYC3 datacenter as a part of network upgrades.\nExpected Impact:\nThese upgrades are designed and tested to be seamless and we do not expect any impact to customer traffic due to this maintenance. If an unexpected issue arises, affected Droplets and Droplet-based services may experience a temporary loss of connectivity. We will endeavor to keep any such impact to a minimum.\nIf you have any questions or concerns regarding this maintenance, please reach out to us by opening up a ticket on your account via https://cloudsupport.digitalocean.com/s/createticket .",
          "link": "https://status.digitalocean.com/incidents/tw85s4rhwpqm",
          "publishedOn": "2023-06-08T08:00:22.000Z",
          "wordCount": 5117,
          "title": "NYC3 Network Maintenance 2023-06-08 04:00 UTC",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/r8yz7801sh9w",
          "author": null,
          "description": "Jun  1, 03:01 UTC\nCompleted - The scheduled maintenance has been completed.\nJun  1, 01:00 UTC\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nMay 31, 23:11 UTC\nScheduled - Start: 2023-06-01 01:00 UTC\nEnd: 2023-06-01 05:00 UTC\nDuring the above window, our Networking team will be making changes to our core networking infrastructure to improve performance and scalability in the SFO2 region. This will be the second of the two maintenance activities performed by our team in the region on consecutive days.\nExpected Impact:\nThese upgrades are designed and tested to be seamless and we do not expect any impact to customer traffic due to this maintenance. If an unexpected issue arises, affected Droplets and Droplet-based services may experience a temporary loss of private connectivity between VPCs. We will endeavor to keep any such impact to a minimum.\nIf you have any questions or concerns regarding this maintenance, please reach out to us by opening up a ticket on your account via https://cloudsupport.digitalocean.com/s/createticket .",
          "link": "https://status.digitalocean.com/incidents/r8yz7801sh9w",
          "publishedOn": "2023-06-01T03:01:07.000Z",
          "wordCount": 5145,
          "title": "SFO2 Network Maintenance 2023-06-01 01:00 UTC Phase 2",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/4rf2j2dmc382",
          "author": null,
          "description": "May 31, 04:04 UTC\nCompleted - The scheduled maintenance has been completed.\nMay 31, 01:30 UTC\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nMay 31, 01:26 UTC\nScheduled - Start: 2023-05-31 01:00 UTC\nEnd: 2023-05-31 05:00 UTC\n\nDuring the above window, our Networking team will be making changes to our core networking infrastructure to improve performance and scalability in the SFO2 region. This maintenance will occur in two parts on consecutive days and we will send another maintenance notice for the second phase. \nExpected Impact:\nThese upgrades are designed and tested to be seamless and we do not expect any impact to customer traffic due to this maintenance. If an unexpected issue arises, affected Droplets and Droplet-based services may experience a temporary loss of private connectivity between VPCs. We will endeavor to keep any such impact to a minimum.\nIf you have any questions or concerns regarding this maintenance, please reach out to us by opening up a ticket on your account via https://cloudsupport.digitalocean.com/s/createticket .",
          "link": "https://status.digitalocean.com/incidents/4rf2j2dmc382",
          "publishedOn": "2023-05-31T04:04:49.000Z",
          "wordCount": 5132,
          "title": "SFO2 Network Maintenance",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/vmxnj2vv4k9k",
          "author": null,
          "description": "May 31, 02:25 UTC\nResolved - Our Engineering team has confirmed the full resolution of the issue impacting Spaces performance and availability in our NYC3 region.\nFrom 00:20 to 00:57 UTC, users may have experienced slowness or timeouts when trying to access or manage their Spaces resources in NYC3, static site assets in NYC, or App Platform bandwidth insights.\nSpaces should now be operating normally. If you continue to experience problems, please open a ticket with our support team from within your Cloud Control Panel. We apologize for any inconvenience.\nMay 31, 01:47 UTC\nMonitoring - Our Engineering team has observed recovery of availability for Spaces in our NYC3 region. \nAvailability returned to 100% at 00:57 UTC and since then, users should not be experiencing any issues with Spaces or App Platform. \nWe'll now monitor the situation for a period of time and post a final update once we confirm the incident is resolved.\nMay 31, 01:05 UTC\nInvestigating - Our Engineering team is investigating a drop in availability for Spaces in our NYC region. During this time, some users may experience errors with API or object requests, be unable to create new buckets in NYC3, and/or see issues with loading Spaces in the Cloud Control Panel. \nAdditionally, users of App Platform will be unable to see bandwidth insights in their dashboards and static site users may notice errors fetching assets from Spaces buckets in NYC3. \nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/vmxnj2vv4k9k",
          "publishedOn": "2023-05-31T02:25:35.000Z",
          "wordCount": 5218,
          "title": "Spaces API Availability in NYC3",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/qbszx5q5dd19",
          "author": null,
          "description": "May 28, 19:16 UTC\nResolved - Our Engineering team has continued to actively monitor the situation resulting from multiple subsea fiber faults in the APAC region. Over the last few days, our team has continued to make routing changes where possible. \nCrews have been able to complete some cable repairs and we expect to see our network routing stabilize once the repair of a few more cables are completed in the coming weeks. Until then, we expect to see intermittent periods of packet loss and latency on network routes between Singapore and New York City, as well as Singapore and Toronto. These are normally short-lived and happen during Singapore business hours when traffic is heavy. \nGiven the relative stability of routes, we will now close out this incident and provide any needed updates sepa…",
          "link": "https://status.digitalocean.com/incidents/qbszx5q5dd19",
          "publishedOn": "2023-05-28T19:16:27.000Z",
          "wordCount": 5524,
          "title": "Subsea Fiber Faults in the APAC region",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/93nbbqq83slf",
          "author": null,
          "description": "May 26, 02:38 UTC\nResolved - As of 02:10 UTC, Our Engineering team has confirmed that the issue with our Container Registry services in the SFO3 region has been fully resolved. \nAll operations should now be operating normally with our Container Registry services. If you continue to experience any trouble with these services please open a ticket with our support team. \nThank you for your patience and we apologize for the inconvenience.\nMay 25, 23:31 UTC\nMonitoring - As of 22:10 UTC, Our engineering team has implemented a fix to resolve the issue with our Container Registry services in the SFO3 region and is monitoring the situation closely. \nUsers should no longer see 500-type errors when uploading/pushing/deleting images, slow cleanup operations, creation failures for new registries, or other errors when interacting with registries in the SFO3 region. \nWe are going to continue to monitor the situation and will post an update once we are confident this issue will not recur.\nMay 25, 16:20 UTC\nInvestigating - We are observing some customer reports for issues with DigitalOcean Container Registries in the SFO3 region. Our Engineering team is investigating any potential issues that are causing these reports. This seems to be a reoccurrence of the incident mentioned in the below link:\nhttps://status.digitalocean.com/incidents/mmngtxzmm6gs  \nAt this time, users may see 500 type errors when uploading/pushing/deleting images, slow cleanup operations, creation failures for new registries, or other errors when interacting with registries in SFO3. \nWe will post an update as soon as we have further information. Thank you for your patience.",
          "link": "https://status.digitalocean.com/incidents/93nbbqq83slf",
          "publishedOn": "2023-05-26T02:38:56.000Z",
          "wordCount": 5220,
          "title": "Container Registry in SFO3",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/kg0b7wl8mshl",
          "author": null,
          "description": "May 25, 09:45 UTC\nResolved - Our Engineering team has confirmed the full resolution of this incident.\nFrom 06:00 - 08:00 UTC, users were unable to create and deploy new Apps and experienced errors when updating, and deploying existing Apps. The App deployments should now be operating normally.\nIf you continue to experience problems, please open a ticket with our support team from within your Cloud Control Panel.\nMay 25, 09:20 UTC\nMonitoring - Our Engineering team has implemented a fix to resolve the issue with App deployments in the SFO region and is monitoring the situation. We will post an update as soon as the issue is fully resolved.\nMay 25, 08:47 UTC\nIdentified - Our Engineering team has identified the cause of the issue with network latency that is impacting the management and creation of Apps in the SFO region and is actively working on a fix. During this time, a subset of users might see errors when updating and deploying new/existing Apps. We will post an update as soon as additional information is available.\nMay 25, 08:30 UTC\nInvestigating - Our Engineering team is investigating an issue with network latency that is impacting the management and creation of Apps in the SFO region. As of 06:00 UTC, users are unable to create and deploy new Apps and may see errors when updating, and deploying existing Apps. At this time, previously deployed running Apps are not impacted. We apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/kg0b7wl8mshl",
          "publishedOn": "2023-05-25T09:45:27.000Z",
          "wordCount": 5226,
          "title": "App Platform Deployments in SFO region",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/mmngtxzmm6gs",
          "author": null,
          "description": "May 25, 02:49 UTC\nResolved - Our Engineering team has identified the root cause of the incident to be multiple DB calls causing DB contention. During this time, users might have experienced issues interacting and authenticating with the DigitalOcean Container Registry, creating new container registries, and pushing/deleting images to/from registries.\nAs of 00:10 UTC, we have confirmed the full resolution of the issue affecting the DigitalOcean Container Registry in the SFO3 region. We appreciate your patience throughout the process and if you continue to experience problems, please open a ticket with our support team for further review.\nMay 24, 22:53 UTC\nUpdate - Our Engineering team continues to investigate the root cause of this incident but has observed a reduction in the error rate with DigitalOcean Container Registry in the SFO3 region.\nAt this time, users should no longer experience errors while interacting and authenticating with the DigitalOcean Container Registry, creating new container registries, and pushing/deleting images to/from registries.\nWe will post an update as soon as we have further information. Thank you for your patience.\nMay 24, 19:28 UTC\nInvestigating - Following an uptick in customer reports of issues with DigitalOcean Container Registries in SFO3, our Engineering team is investigating any potential issues that are causing these reports. \nAt this time, users may see 500 type errors when uploading/pushing/deleting images, slow cleanup operations, creation failures for new registries, or other errors when interacting with  registries in SFO3. \nWe will post an update as soon as we have further information. Thank you for your patience.",
          "link": "https://status.digitalocean.com/incidents/mmngtxzmm6gs",
          "publishedOn": "2023-05-25T02:49:34.000Z",
          "wordCount": 5217,
          "title": "Container Registry in SFO3",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/y3033ln7n73w",
          "author": null,
          "description": "May 24, 21:30 UTC\nResolved - As of 21:15 UTC, Our Engineering team has confirmed the full resolution of this incident. We have verified that the Snapshot and Backup events in the SGP1 region are processing without any failures and we will now mark this issue as resolved. \nThank you for your patience and understanding throughout this process. If you should encounter any further issues at all, then please open a ticket with our Support team.\nMay 24, 21:05 UTC\nUpdate - We are continuing to monitor for any further issues.\nMay 24, 20:44 UTC\nMonitoring - As of 19:30 UTC, Our Engineering team was able to take action to mitigate the impact of this incident and allow Snapshot and Backup events to process normally in the SGP1 region. We will post an update as soon as the issue is fully resolved. \nPlease note that while the situation has improved, there may still be a backlog of older events that are in the process of being resolved. We kindly ask for your patience as our team works diligently to address these remaining events. \nWe apologize for any inconvenience caused and assure you that we are committed to resolving all outstanding issues.\nMay 24, 19:20 UTC\nInvestigating - As of 13:30 UTC our Engineering team is investigating an issue with intermittent Snapshot and Backup failures in our SGP1 region. Users may experience errors when performing Snapshots, but may eventually see retries succeed. \nAny Backup failures are automatically being retried within the Backup window for individual Droplets. \nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/y3033ln7n73w",
          "publishedOn": "2023-05-24T21:30:01.000Z",
          "wordCount": 5243,
          "title": "Snapshots and Backups Failure in SGP1",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/gqtn5dtkstzg",
          "author": null,
          "description": "May 24, 18:35 UTC\nCompleted - The scheduled maintenance has been completed.\nMay 24, 16:00 UTC\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nMay 24, 15:05 UTC\nScheduled - Start: 2023-05-24 16:00 UTC\nEnd:  2023-05-24 20:00 UTC\n\nDuring the above window, our Networking team will be making changes to our core networking infrastructure to improve performance and scalability in the AMS3 region. This will be the final phase of the three maintenance activities performed by our team in AMS3 on consecutive days.\nExpected Impact:\nThese upgrades are designed and tested to be seamless and we do not expect any impact to customer traffic due to this maintenance. If an unexpected issue arises, affected Droplets and Droplet-based services may experience a temporary loss of private connectivity between VPCs. We will endeavor to keep any such impact to a minimum.\nIf you have any questions or concerns regarding this maintenance, please reach out to us by opening up a ticket on your account via https://cloudsupport.digitalocean.com/s/createticket .",
          "link": "https://status.digitalocean.com/incidents/gqtn5dtkstzg",
          "publishedOn": "2023-05-24T18:35:49.000Z",
          "wordCount": 5136,
          "title": "AMS3 Network Maintenance Phase 3",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    },
    {
      "title": "Notion Status - Incident History",
      "feedUrl": "https://status.notion.so/history.rss",
      "siteUrl": "https://status.notion.so",
      "articles": [
        {
          "id": "https://status.notion.so/incidents/j5jk1f1ytyz1",
          "author": null,
          "description": "Jun  5, 10:43 PDT\nResolved - This has been resolved -- all users can access notion.so without issue again.\nJun  5, 09:53 PDT\nInvestigating - The notion.so site is down for some users, we are investigating. Users can still log in and access their workspaces at notion.so/login.",
          "link": "https://status.notion.so/incidents/j5jk1f1ytyz1",
          "publishedOn": "2023-06-05T17:43:47.000Z",
          "wordCount": 2825,
          "title": "Notion.so down",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/vpm90b50y09t",
          "author": null,
          "description": "Jun  5, 09:30 PDT\nResolved - Notion was down from around 9:25am - 9:40am Pacific time.  We are still investigating an issue that may be preventing some users from accessing notion.so while not logged in.",
          "link": "https://status.notion.so/incidents/vpm90b50y09t",
          "publishedOn": "2023-06-05T16:30:00.000Z",
          "wordCount": 2809,
          "title": "Notion production outage",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/crfw2mn48z7m",
          "author": null,
          "description": "Jun  2, 05:26 PDT\nResolved - The issue has been resolved, and notion.so is available to all users\nJun  2, 04:53 PDT\nInvestigating - The notion.so site is down for some users, we are investigating. Users can still log in and access their workspaces at notion.so/login.",
          "link": "https://status.notion.so/incidents/crfw2mn48z7m",
          "publishedOn": "2023-06-02T12:26:37.000Z",
          "wordCount": 2824,
          "title": "Notion.so down",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    },
    {
      "title": "Rippling Status - Incident History",
      "feedUrl": "https://status.rippling.com/history.rss",
      "siteUrl": "https://status.rippling.com",
      "articles": [
        {
          "id": "https://status.rippling.com/incidents/tvr7l7344y0y",
          "author": null,
          "description": "Jun  7, 13:43 UTC\nResolved - This incident has been resolved.\nJun  6, 20:27 UTC\nUpdate - We are continuing to monitor for any further issues.\nJun  6, 18:43 UTC\nMonitoring - Google has implemented a fix and we are monitoring the results. Customers should be able to add new licenses and transfer subscriptions via the Google Workspace App in Rippling.\nJun  5, 22:07 UTC\nIdentified - We are continuing to work with Google to resolve an issue that is affecting our integration.\nJun  5, 17:32 UTC\nInvestigating - Customers are currently unable to add new licenses and transfer subscriptions via the Google Workspace App in Rippling. We are currently working with Google to resolve this issue.",
          "link": "https://status.rippling.com/incidents/tvr7l7344y0y",
          "publishedOn": "2023-06-07T13:43:53.000Z",
          "wordCount": 4152,
          "title": "Issues with the Google Workspace integration",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/248858/rippling_favicoon.png"
        }
      ]
    },
    {
      "title": "Google Workspace Status Dashboard Updates",
      "feedUrl": "https://www.google.com/appsstatus/dashboard/en/feed.atom",
      "siteUrl": "https://www.google.com/appsstatus/dashboard/",
      "articles": [
        {
          "id": "https://www.google.com/appsstatus/dashboard/incidents/1jNfhkFKus49vEyaUQLm",
          "author": null,
          "description": "<p> Incident began at <strong>2023-06-02 19:25</strong> and ended at <strong>2023-06-03 11:57</strong> <span>(times are in <strong>Coordinated Universal Time (UTC)</strong>).</span></p><div class=\"cBIRi14aVDP__status-update-text\"><h1>Incident Report</h1>\n<h2>Summary</h2>\n<p>From Friday, 2 June 2023 to Saturday, 3 June 2023, some Google Workspace Administrators experienced issues performing List, Create, Update, or Delete operations for users and organizational units (OU) when using the Admin Console or Directory APIs. The total outage duration was 16 hours and 32 minutes. We have conducted an internal investigation and are taking steps to improve our service.</p>\n<h2>Root Cause</h2>\n<p>The Google Workspace Admin Console and Directory APIs use a backend service to authorize requests to create/update/delete/read user and OU resources. A workflow synchronizes user and OU resources to that backend authorization service.</p>\n<p>On Friday, 2 June 2023 at 12:25 PDT, engineers rolled out a configuration change that inadvertently caused the workflow to stop synchronizing resources to the authorization service. Because the authorization service was not aware of the new resources (those created during the outage), it was unable to authorize requests and returned a 403 Unauthorized error. The incorrect configuration went undetected before being deployed to production because the automatic pre-submit checks had been suppressed because engineers incorrectly believed the change was safe.</p>\n<h2>Remediation and Prevention</h2>\n<p>Google engineers were alerted to the outage via a support case on 2 June 2023 at 19:33 PDT and immediately started an investigation. Engineers identified that the roll out of the configuration change aligned with the start of 403 Unauthorized errors and initiated a rollback on 3 June 2023 at 00:14 PDT. The rollback completed at 00:57 PDT, mitigating the issue for new users and OU resources created after that time. Engineers performed a backfill to synchronize the impacted users and OU resources that were created after the start of the issue, fully mitigating the issue at 04:57 PDT.</p>\n<p>Google is committed preventing a repeat of this issue in the future and is completing the following actions:</p>\n<ul>\n<li>We will be updating the pre-submit checks for workflow configuration changes to better identify potential issues before rolling out to production.</li>\n<li>We will be adding a requirement to have a designated reviewer approve workflow configuration changes to ensure that automated presubmit checks are being run before rolling out to production.</li>\n</ul>\n<h2>Detailed Description of Impact</h2>\n<p>From 2 June 2023 at 12:25 PDT to 3 June 2023 at 04:57, Google Workspace Administrators may have experienced 403 Unauthorized errors when attempting to perform actions for user and OU resources via Admin Console or Directory APIs. This issue affected Create, Fetch, Update, Delete and other related operations for user and OU resources created between 2 June 2023 at 12:25 PDT and 3 June 2023 at 00:57 PDT.</p>\n</div><hr><p>Affected products: Admin Console</p>",
          "link": "https://www.google.com/appsstatus/dashboard/incidents/1jNfhkFKus49vEyaUQLm",
          "publishedOn": "2023-06-15T21:23:03.000Z",
          "wordCount": 1344,
          "title": "RESOLVED: We're aware of a problem with Admin Console affecting a subset of Google Workspace Administrators. Some Google Workspace Administrators may experience issues when performing List, Create, Update, or Delete operations for OrgUnits using the Admin Console or Directory APIs. Attempting to navigate to the admin.google.com/ac/users/",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "GitHub Status - Incident History",
      "feedUrl": "https://www.githubstatus.com/history.rss",
      "siteUrl": "https://www.githubstatus.com",
      "articles": [
        {
          "id": "https://www.githubstatus.com/incidents/22qm4j1kvn0h",
          "author": null,
          "description": "Jun 19, 23:09 UTC\nResolved - This incident has been resolved.\nJun 19, 22:47 UTC\nInvestigating - We are investigating reports of degraded performance for Actions.",
          "link": "https://www.githubstatus.com/incidents/22qm4j1kvn0h",
          "publishedOn": "2023-06-19T23:09:51.000Z",
          "wordCount": 4048,
          "title": "Incident with Actions",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/psdymfgt6p7q",
          "author": null,
          "description": "Jun 16, 23:59 UTC\nResolved - This incident has been resolved.\nJun 16, 23:46 UTC\nUpdate - Users may be unable to access org-owned resources in GitHub-owned client apps such as VS Code, GitHub Desktop, GitHub Mobile, and the CLI. We are working on reverting a change that is causing this\nJun 16, 23:46 UTC\nInvestigating - We are currently investigating this issue.",
          "link": "https://www.githubstatus.com/incidents/psdymfgt6p7q",
          "publishedOn": "2023-06-16T23:59:23.000Z",
          "wordCount": 4089,
          "title": "Investigating reports of degraded performance.",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/6tfr2b2s2073",
          "author": null,
          "description": "Jun 15, 19:36 UTC\nResolved - This incident has been resolved.\nJun 15, 19:22 UTC\nInvestigating - We are investigating reports of degraded performance for Copilot.",
          "link": "https://www.githubstatus.com/incidents/6tfr2b2s2073",
          "publishedOn": "2023-06-15T19:36:17.000Z",
          "wordCount": 4048,
          "title": "Incident with Copilot",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/h3vqt1fvp9tc",
          "author": null,
          "description": "Jun 15, 16:57 UTC\nResolved - This incident has been resolved.\nJun 15, 16:47 UTC\nUpdate - Due to an issue with Let's Encrypt, obtaining a new HTTPS certificate for Pages sites is delayed.\nJun 15, 16:34 UTC\nInvestigating - We are investigating reports of degraded performance for Pages.",
          "link": "https://www.githubstatus.com/incidents/h3vqt1fvp9tc",
          "publishedOn": "2023-06-15T16:57:15.000Z",
          "wordCount": 4073,
          "title": "Incident with Pages",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/csnbwc85chp2",
          "author": null,
          "description": "Jun 13, 00:17 UTC\nResolved - This incident has been resolved.\nJun 13, 00:09 UTC\nUpdate - We have applied a mitigation and are seeing signs of recovery. We will post another update shortly.\nJun 12, 23:39 UTC\nUpdate - We are investigating reports of degraded performance for Actions. We have identified the root cause and have begun applying a mitigation.\nJun 12, 22:48 UTC\nUpdate - Pages is experiencing degraded performance. We are still investigating and will provide an update when we have one.\nJun 12, 22:43 UTC\nInvestigating - We are investigating reports of degraded performance for Actions.",
          "link": "https://www.githubstatus.com/incidents/csnbwc85chp2",
          "publishedOn": "2023-06-13T00:17:05.000Z",
          "wordCount": 4136,
          "title": "Incident with Actions and Pages",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/0csnqhwzxp1m",
          "author": null,
          "description": "Jun  9, 23:17 UTC\nResolved - This incident has been resolved.\nJun  9, 22:46 UTC\nUpdate - We are investigating elevated error rates on Pull Requests. We will continue to keep users updated on progress towards mitigation.\nJun  9, 22:18 UTC\nInvestigating - We are investigating reports of degraded performance for Pull Requests.",
          "link": "https://www.githubstatus.com/incidents/0csnqhwzxp1m",
          "publishedOn": "2023-06-09T23:17:57.000Z",
          "wordCount": 4081,
          "title": "Incident with Pull Requests",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/17c40y7spfgl",
          "author": null,
          "description": "Jun  8, 12:55 UTC\nResolved - This incident has been resolved.\nJun  8, 12:55 UTC\nUpdate - Our team continues to mitigate the impacted search results however we are going to status to green due to impact on overall service. We will continue to post updates on the status page as we mitigate\nJun  8, 12:23 UTC\nUpdate - We are aware search results for PRs are returning incomplete results in certain scenarios. This is impacting most users. No other search results are impacted. All other PR functionality is working.\nJun  8, 11:58 UTC\nInvestigating - We are investigating reports of degraded performance for Pull Requests.",
          "link": "https://www.githubstatus.com/incidents/17c40y7spfgl",
          "publishedOn": "2023-06-08T12:55:12.000Z",
          "wordCount": 4136,
          "title": "Incident with Pull Requests",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/1g1gkh0qpyvs",
          "author": null,
          "description": "Jun  7, 18:39 UTC\nResolved - This incident has been resolved.\nJun  7, 18:32 UTC\nUpdate - Repository push workers are continuing to catch up with enqueued jobs.\nJun  7, 17:58 UTC\nUpdate - We have mitigated the problem and are waiting for our repository push workers to catch up with enqueued jobs.\nJun  7, 17:42 UTC\nUpdate - We have identified the cause of delayed processing for commits pushed to repositories and are actively working on mitigating this issue.\nJun  7, 17:31 UTC\nUpdate - Webhooks is experiencing degraded performance. We are continuing to investigate.\nJun  7, 17:29 UTC\nUpdate - Actions is experiencing degraded performance. We are still investigating and will provide an update when we have one.\nJun  7, 16:53 UTC\nUpdate - Pushes to repositories may take longer for a significant number of customers. We are actively investigating.\nJun  7, 16:45 UTC\nInvestigating - We are investigating reports of degraded availability for Pull Requests.",
          "link": "https://www.githubstatus.com/incidents/1g1gkh0qpyvs",
          "publishedOn": "2023-06-07T18:39:02.000Z",
          "wordCount": 4208,
          "title": "Incident with Actions, Pull Requests and Webhooks",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        }
      ]
    },
    {
      "title": "Slack System Status",
      "feedUrl": "https://status.slack.com/feed/rss",
      "siteUrl": "https://status.slack.com/",
      "articles": [
        {
          "id": "https://status.slack.com//2023-06/4edd40b2f4290679",
          "author": null,
          "description": "Issue summary:\n\r\nFrom June 13, 2023 at 12:30 PM PDT until June 15, 2023 at 2:30 AM PDT, some users may have experienced issues with statuses, reminders and agendas failing to sync from their Google Calendar and Outlook Calendar apps.\n\r\n\r\nThese issues were due to an outage from an upstream service provider which affected many services. The provider actively worked to remediate those issues, which then fully resolved the reported failures for impacted Slack users.",
          "link": "https://status.slack.com//2023-06/4edd40b2f4290679",
          "publishedOn": "2023-06-16T12:00:18.000Z",
          "wordCount": 184,
          "title": "Incident: Trouble with Google Calendar and Outlook Calendar App",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-06/7363f55dbcde89c1",
          "author": null,
          "description": "Issue summary:\n\r\n\r\nOn June 15, 2023 from 8:10 AM PDT to around 8:20 AM PDT, some users may have experienced slow performance and errors while loading conversations, sending messages and taking other actions in Slack.\n\r\n\r\nWe traced the issue to a recent code change which caused connection failures. We reverted this change and all affected functionality should be restored for users. Thank you for your patience while we resolved this issue.",
          "link": "https://status.slack.com//2023-06/7363f55dbcde89c1",
          "publishedOn": "2023-06-15T23:28:00.000Z",
          "wordCount": 240,
          "title": "Incident: Some users may notice slow performance throughout Slack",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-06/20df18536cc9524b",
          "author": null,
          "description": "Issue Summary:\n\r\nFrom June 14, 2023 at 3:44 PM PDT until June 15, 2023 at 4:30 AM PDT, some customers may have been unable to send messages, join Huddles, run workflows, and access Slack.\n\r\n\r\nA recent code change caused some resources on our backend web hosting service to be temporarily exhausted. Due to this, users experienced errors when joining Huddles, sending messages, and may have had their connection to Slack reset. We identified the issue and reverted the change restoring full functionality to these features.",
          "link": "https://status.slack.com//2023-06/20df18536cc9524b",
          "publishedOn": "2023-06-15T18:31:06.000Z",
          "wordCount": 397,
          "title": "Incident: Trouble with workflows, loading channels and accessing Slack",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-06/a0c185e5ad5eac55",
          "author": null,
          "description": "Issue summary: \n\r\nOn June 13, 2023 from 11:55 AM PDT to around 3:47 PM PDT, some users may have experienced failure with clips transcribing and transcoding, execution of workflows with custom functions, new deployments of apps with hosted functions, and some delay when using canvases in Slack. \n\r\n\r\nThese issues were due to an outage from an upstream service provider which affected many services. The provider actively worked to remediate those issues, which then fully resolved the reported failures for impacted Slack users.",
          "link": "https://status.slack.com//2023-06/a0c185e5ad5eac55",
          "publishedOn": "2023-06-14T03:06:22.000Z",
          "wordCount": 317,
          "title": "Incident: Trouble with workflows and clips transcripts",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-06/1bd97a73cb7874f1",
          "author": null,
          "description": "On June 11, 2023 from 10:57 AM PDT to 12:10 PM PDT, some users may have experienced difficulties when trying to access Slack due to a database issue.\n\r\n\r\nThe underlying cause has since been determined and remediation steps were applied. This resolved the above for all impacted users.",
          "link": "https://status.slack.com//2023-06/1bd97a73cb7874f1",
          "publishedOn": "2023-06-12T14:56:48.000Z",
          "wordCount": 262,
          "title": "Incident: Small number of users might be experiencing connectivity issues",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-06/6cb0bb4f227a82e8",
          "author": null,
          "description": "Thank you for your patience while our team investigated this. All new file uploads are now expected to generate thumbnails for affected users and the issue has been resolved. Please note that previous attempts won't be retried, however new files should function as normal.",
          "link": "https://status.slack.com//2023-06/6cb0bb4f227a82e8",
          "publishedOn": "2023-06-06T11:15:34.000Z",
          "wordCount": 280,
          "title": "Incident: Some files may not be unfurling as expected",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-06/f7c5d1e455e95466",
          "author": null,
          "description": "Issue summary:\n\r\n\r\nOn June 02, 2023 from 3:28 PM PDT to around 5:29 PM PDT, some customers may have experienced large empty spaces in the Workflow Builder UI and issues with publishing/adding or editing steps in a workflow. \n\r\n\r\nWe traced the issue to a recent code change which caused the channel selector to appear out of view, resulting in the inability to take certain actions while editing a workflow. \n\r\n\r\nWe reverted the change which solved the issue for all customers.",
          "link": "https://status.slack.com//2023-06/f7c5d1e455e95466",
          "publishedOn": "2023-06-05T09:01:22.000Z",
          "wordCount": 200,
          "title": "Incident: Issues with Workflow Builder",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-05/d3da25ad25333a58",
          "author": null,
          "description": "Issue summary:\n\r\n\r\nFrom May 19, 2023 at 12:00 AM PDT until May 25, 2023 at 8:00 AM PDT, some users may have experienced issues triggering shortcut workflows.\n\r\n\r\nWe carried out our investigation and determined that cached data on the back end temporarily broke legacy workflows. In the process of determining our path to a resolution the issue resolved itself. We are taking the necessary steps to prevent similar issues in the future.",
          "link": "https://status.slack.com//2023-05/d3da25ad25333a58",
          "publishedOn": "2023-06-01T18:00:28.000Z",
          "wordCount": 232,
          "title": "Incident: Some users are reporting issues triggering shortcut Workflows",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-05/223e97529097de1c",
          "author": null,
          "description": "Issue summary:\n\r\nOn May 31, 2023 from 5:15 PM PDT to 7:12 PM PDT, some customers experienced issues with using keyboard shortcuts. \n\r\n\r\nWe’ve traced that this issue was caused by a recent code change. We’ve rolled back this change, resolving the issue for all impacted customers.",
          "link": "https://status.slack.com//2023-05/223e97529097de1c",
          "publishedOn": "2023-06-01T05:57:52.000Z",
          "wordCount": 152,
          "title": "Incident: Users reporting issues with keyboard shortcuts",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-05/aa025f4aef896b16",
          "author": null,
          "description": "Issue summary:\n\r\nFrom May 30th, 2023 at 8:02 AM PDT until 11:18 AM PDT, some users experienced unexpected behavior with autocomplete suggestions, including incorrect rankings & incomplete results when conducting searches.\n\r\n\r\nWe traced the source of the issue back to an error that occurred in our autocomplete cache. A fix was rolled out to our search logic which began to show the correct results.\n\r\n\r\nUsers can refresh their Slack client (by pressing Cmd/Ctrl + Shift + R) if they are still experiencing issues. We apologize for any interruption.",
          "link": "https://status.slack.com//2023-05/aa025f4aef896b16",
          "publishedOn": "2023-05-31T23:27:14.000Z",
          "wordCount": 204,
          "title": "Incident: Autocomplete results ranking in search degraded",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-05/0848cba206ef2188",
          "author": null,
          "description": "Issue summary:\n\r\nFrom May 30th, 2023 at around 8:00 PM PDT until May 31st, 2023 at 9:20 AM PDT, users with the Reacji Channeler app installed in their workspace experienced some issues where the app would not execute.\n\r\n\r\nThe issue was traced back to a recent change that occurred for one of our app databases. This caused the app to accept new requests even though it was unable to connect to the database, resulting in timeout errors. \n\r\n\r\nWe reverted the change and restarted the backend processes which allowed the app to connect to the database again, resolving the issue for impacted users. We apologize for any disruptions to your day.",
          "link": "https://status.slack.com//2023-05/0848cba206ef2188",
          "publishedOn": "2023-05-31T23:04:00.000Z",
          "wordCount": 221,
          "title": "Incident: Reacji Channeler app is failing for some users",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-05/f1df0cac8d8d8d68",
          "author": null,
          "description": "On May 23, 2023 between 8:38 AM PDT and 9:44 AM PDT some users were unable to send and edit messages, load threads, join channels and create group DMs.\n\r\n\r\nOur investigation uncovered that a recent code change we made had caused an overwhelming impact on our databases. We rolled this change back and temporarily redirected user traffic as our databases recovered. Once we rolled back the change and our databases were in a healthier state, the issue became resolved for impacted users.\n\r\n\r\nWe will continue to implement new ways to detect issues like this early-on.\n\r\n\r\nThank you for your patience while we investigated and resolved the issue.",
          "link": "https://status.slack.com//2023-05/f1df0cac8d8d8d68",
          "publishedOn": "2023-05-24T22:29:00.000Z",
          "wordCount": 244,
          "title": "Incident: A small percentage of users are experiencing issues with Slack.",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        }
      ]
    },
    {
      "title": "Make Status - Incident History",
      "feedUrl": "https://status.make.com/history.rss",
      "siteUrl": "https://status.make.com",
      "articles": [
        {
          "id": "https://status.make.com/incidents/413nrl6rvmsx",
          "author": null,
          "description": "Jun 14, 13:00 CEST\nCompleted - The scheduled maintenance has been completed.\nJun 14, 11:00 CEST\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nJun 13, 15:02 CEST\nScheduled - We would like to inform you about a scheduled maintenance window that will be taking place on 14th June between 11:00 CEST - 13:00 CEST.\nDuring this maintenance period, there will be a short interruption resulting in the unavailability of the login page and organisations page. \nIf you experience a blank page , clearing your browser cache might resolve the issue . If not please reach out to our customer care team.\nHowever, we assure you that there will be no data loss and all scenarios will continue running properly.\nWe apologize for any inconvenience caused and appreciate your understanding.",
          "link": "https://status.make.com/incidents/413nrl6rvmsx",
          "publishedOn": "2023-06-14T11:00:40.000Z",
          "wordCount": 3390,
          "title": "Scheduled Maintenance",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.make.com/incidents/ts75knvtfm16",
          "author": null,
          "description": "Jun  8, 00:47 CEST\nResolved - This incident is now resolved.\nJun  7, 21:32 CEST\nUpdate - We have applied a permanent fix on eu1.make.celonis.com and eu1.make.com, and based on our checks there are no issues and all scenarios are running as expected.\nJun  7, 21:18 CEST\nUpdate - We are applying a fix for this issue.\nJun  7, 13:13 CEST\nUpdate - We have applied a permanent fix on us1.make.celonis.com and us1.make.com, and based on our checks there are no issues and all scenarios are running as expected.\nIn regards to eu1.make.celonis.com and eu1.make.com, we are going to roll out the fix outside of business hours. \nPlease use the workaround as needed, it was described in the previous update.\nWe will post another update once a full fix is applied.\nJun  6, 11:39 CEST\nIdentified - We're currently experiencing an issue that appears only in certain unique circumstances when a running scenario is not properly using the values of team or organization variables during executions.\nSpecific circumstances for the issue are:\n- A team or organization variable is used as a filter condition OR there is more than one team or organization variable referenced within a single mapped field, OR the variable is used inside a function.\n- AND the scenario was created / modified before March 8, 2023 \n- AND the execution occurs after May 3, 2023\nWorkaround: \nAny user encountering this issue can open the affected scenario, make any change (move a module) and hit save. This will immediately resolve the issue for that scenario.\nComplete resolution: \nThe development team is actively working on a fix that will address any scenario where the issue still persists. Will post an update once we have more information around the permanent fix.\nJun  6, 09:09 CEST\nInvestigating - We're currently experiencing issues with Scenarios that use Custom Variables. Our engineering team is investigating the root cause.",
          "link": "https://status.make.com/incidents/ts75knvtfm16",
          "publishedOn": "2023-06-07T22:47:29.000Z",
          "wordCount": 3584,
          "title": "Scenarios using Custom Variables not working properly",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.make.com/incidents/ms6hw0p562v8",
          "author": null,
          "description": "Jun  6, 10:00 CEST\nCompleted - The scheduled maintenance has been completed.\nJun  6, 08:00 CEST\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nJun  1, 15:57 CEST\nScheduled - We would like to inform you about a scheduled maintenance window that will be taking place on 6th June between 08:00 CEST - 10:00 CEST.\nDuring this maintenance period, there will be a short interruption resulting in the unavailability of the login page and organizations page. \nHowever, we assure you that there will be no data loss and all scenarios will continue running properly.\nWe apologize for any inconvenience caused and appreciate your understanding.",
          "link": "https://status.make.com/incidents/ms6hw0p562v8",
          "publishedOn": "2023-06-06T08:00:15.000Z",
          "wordCount": 3365,
          "title": "Scheduled maintenance",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.make.com/incidents/2vlc5cz18jbn",
          "author": null,
          "description": "May 31, 10:00 CEST\nCompleted - The scheduled maintenance has been completed.\nMay 31, 08:02 CEST\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nMay 29, 15:34 CEST\nScheduled - We would like to inform you about a scheduled maintenance window that will be taking place on 31st May between 08:00 CEST - 10:00 CEST.\nDuring this maintenance period, there will be a short interruption resulting in the unavailability of the login page and organizations page. \nHowever, we assure you that there will be no data loss and all scenarios will continue running properly.\nWe apologize for any inconvenience caused and appreciate your understanding.",
          "link": "https://status.make.com/incidents/2vlc5cz18jbn",
          "publishedOn": "2023-05-31T08:00:42.000Z",
          "wordCount": 3365,
          "title": "Scheduled maintenance",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.make.com/incidents/zgjx54wdw2y9",
          "author": null,
          "description": "May 25, 09:00 CEST\nCompleted - The scheduled maintenance has been completed.\nMay 25, 08:00 CEST\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nMay 23, 15:00 CEST\nScheduled - We would like to inform you about a scheduled maintenance window that will be taking place on 25th May between 08:00 CEST - 09:00 CEST.\nDuring this maintenance period, there will be a short interruption resulting in the unavailability of the login page and organizations page. \nHowever, we assure you that there will be no data loss and all scenarios will continue running properly.\nWe apologize for any inconvenience caused and appreciate your understanding.",
          "link": "https://status.make.com/incidents/zgjx54wdw2y9",
          "publishedOn": "2023-05-25T07:00:25.000Z",
          "wordCount": 3365,
          "title": "Scheduled maintenance",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    }
  ],
  "cliVersion": "1.15.1"
}