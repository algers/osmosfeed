{
  "sources": [
    {
      "title": "BookingSync.com news",
      "feedUrl": "https://changelog.bookingsync.com/rss",
      "siteUrl": "https://changelog.bookingsync.com",
      "articles": [
        {
          "id": "283940",
          "author": "Basile, Product Manager",
          "description": "Improvement\n  \nIntroducing Smily’s enhanced deposit management: seamless synchronization with booking.com\nSay goodbye to data discrepancies and hello to effortless property management!\nKey Features:\nEasier deposit handling: Our system now allows you to manage properly damage deposits directly through Smily, ensuring perfect synchronization with Booking.com.\nNo more data mismatch: We’ve revolutionized our sync logic to eliminate discrepancies between Smily and Booking.com. This means the information you see on one platform is exactly what you’ll find on the other.\nEnhanced user experience: Managing your properties has never been smoother. Our updates are tailored to make your workflow more intuitive and efficient.\nRevamped collection & return methods: Say farewell to the hassle of cash deposits and wire returns. With our update, deposit collection and returns are streamlined through credit card transactions, simplifying the process for you and your guests.\nBenefits for you:\nPeace of mind: With matched data across platforms, reduce the risk of errors and enjoy a more streamlined management experience.\nTime savings: Minimize manual work, allowing you to focus on growing your business and enhancing guest experiences.\nConsistent information: Rest assured knowing that what you set in Smily is precisely reflected on Booking.com.\n-> Update your knowledge with our revised manual. Get all the latest information and tips for maximizing the benefits of this new feature at Smily's updated manual.\nYour Smily team :)",
          "link": "https://changelog.bookingsync.com/smily-s-enhanced-deposit-management-seamless-synchronization-with-booking-com-283940",
          "publishedOn": "2024-01-22T17:40:37.000Z",
          "wordCount": 456,
          "title": "Smily’s enhanced deposit management: seamless synchronization with booking.com",
          "imageUrl": null
        },
        {
          "id": "283898",
          "author": "Yannick, Customer Care Team Leader - Pro Team",
          "description": "Action required\n  \nWe have an important update regarding your email communications with your guests via the notification app.\nTo maintain uninterrupted service, some adjustments are needed on your domain provider to keep sending notifications from your own domain name.\nIn case you are confident to do the changes yourself, please follow the instructions on our manual and let us know once it is done so we can verify, otherwise please contact our Customer Support team (Yannick or Pauline) to receive proper instructions and/or schedule a video meeting and we will be happy to help you.\nNote: Please make sure you have access to your domain provider before the call.\nYour prompt attention to this matter is appreciated to prevent any disruptions. Please note that the changes need to be done before February 13 2024.\nThank you for your cooperation.",
          "link": "https://changelog.bookingsync.com/action-required-for-continued-email-communication-from-your-own-domain-283898",
          "publishedOn": "2024-01-22T13:29:03.000Z",
          "wordCount": 380,
          "title": "Action required for continued Email communication from your own domain",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Security Bulletins on Tailscale",
      "feedUrl": "https://tailscale.com/security-bulletins/index.xml",
      "siteUrl": "https://tailscale.com/security-bulletins/",
      "articles": [
        {
          "id": "https://tailscale.com/security-bulletins/#ts-2024-002",
          "author": null,
          "description": "Description: We resolved an information disclosure vulnerability in the\nhello.ts.net service.\nWhat happened?\nOn January 15 2024, we became aware of a potential information disclosure\nvulnerability in the hello.ts.net service, which could show the identity of a\ndifferent Tailscale user when loaded. The hello.ts.net service receives\nidentity information and public keys of nodes tied to their IP address. On\nNovember 28 2023, we made a change to how IPs are assigned to\nTailscale nodes, making them globally non-unique. When the Tailscale service\nassigned the same IP to multiple nodes, hello.ts.net would receive identity\ninformation for one of the nodes at random. We confirmed on January 26 2024\nthat, if one of the other nodes with that IP loaded hello.ts.net, they would\nsee another user's name, email, and hostname.\nThe Tailscale Security Team immediately took hello.ts.net offline while the\nfix was in progress. The issue has been fixed and the hello.ts.net service\nwas restored on January 29 2024.\nWho was affected?\nThe incident was isolated to 10 users across 9 tailnets who could have had\ntheir information leaked to other Tailscale users. We notified the tailnet\nsecurity contacts directly in accordance with our obligations under applicable\ndata privacy laws. Due to the random nature of the vulnerability, we cannot\nconfirm that all of those users were indeed affected.\nRegular shared nodes always see unique node IPs and were not\nvulnerable in a manner similar to hello.ts.net.\nWhat was the impact?\nA small number of users had their name, email, and hostname potentially exposed\nto other Tailscale users that had nodes sharing the same IP.\nIn addition, the hello.ts.net service was offline between January 26-29\n2024. Several users reported being negatively impacted by this.\nWhat do I need to do?\nNo action is needed at this time.\nIf you have a dependency on hello.ts.net as a probing target for Tailscale\nconnectivity, consider using a different probing\nmechanism.",
          "link": "https://tailscale.com/security-bulletins/#ts-2024-002",
          "publishedOn": "2024-01-30T00:00:00.000Z",
          "wordCount": 10683,
          "title": "TS-2024-002",
          "imageUrl": "https://cdn.sanity.io/images/w77i7m8x/production/8e0455b2d9b33c6151016afdf2ea81d7623c2f04-1200x628.png"
        }
      ]
    },
    {
      "title": "Airbnb API Status - Incident History",
      "feedUrl": "https://airbnbapi.statuspage.io/history.rss",
      "siteUrl": "https://airbnbapi.statuspage.io",
      "articles": [
        {
          "id": "https://airbnbapi.statuspage.io/incidents/bs3vrsstwjvz",
          "author": null,
          "description": "Feb  7, 09:48 PST\nResolved - This incident has been resolved.\nFeb  7, 08:55 PST\nMonitoring - Our Async Request Processing system had an issue this morning, which resulted in increased delays between the time a request was enqueued and when it was processed, and may have resulted in an elevated processing failure rate. This began around 8:10 AM PST, and was resolved by 9:15 AM PST.\nWe are still actively monitoring, but are not expecting any ongoing issues at this time.",
          "link": "https://airbnbapi.statuspage.io/incidents/bs3vrsstwjvz",
          "publishedOn": "2024-02-07T17:48:58.000Z",
          "wordCount": 3891,
          "title": "Issues with Async Request Processing",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://airbnbapi.statuspage.io/incidents/dmybzf132ygz",
          "author": null,
          "description": "Feb  5, 16:00 PST\nResolved - We've identified spikes in errors across multiple endpoints that have occurred over the past day. The two distinct spikes were:\n- February 5th, 4:10 PM to 4:30 PM (PST)\n- February 6th, 6:30 AM to 7:30 AM (PST)\nThe issue is now resolved, and we don't expect any ongoing impact.",
          "link": "https://airbnbapi.statuspage.io/incidents/dmybzf132ygz",
          "publishedOn": "2024-02-06T00:00:00.000Z",
          "wordCount": 3861,
          "title": "500 Errors Across Multiple Endpoints",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    },
    {
      "title": "Twilio Status - Incident History",
      "feedUrl": "https://status.twilio.com/history.rss",
      "siteUrl": "https://status.twilio.com",
      "articles": [
        {
          "id": "https://status.twilio.com/incidents/cwj1rl9b7bwz",
          "author": null,
          "description": "THIS IS A SCHEDULED EVENT Feb 14, 22:00 PST  -  Feb 15, 01:00 PST\nFeb  7, 14:04 PST\nScheduled - Our carrier partner Wind Tre (3) Italy is conducting a planned maintenance from 14 February 2024 at 22:00 PST until 15 February 2024 at 01:00 PST. During the maintenance window, there could be intermittent API request failures for Wind Tre (3) Italy customers.\n\nImpacted Products: Verify Silent Network Auth, Lookup SIM Swap, Lookup Identity Match, Legacy Identity MatchAndAttributes",
          "link": "https://status.twilio.com/incidents/cwj1rl9b7bwz",
          "publishedOn": "2024-02-15T06:00:00.000Z",
          "wordCount": 7543,
          "title": "Account Security Carrier Partner Maintenance - Wind Tre (3) Italy",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/jc51lw4fvvlt",
          "author": null,
          "description": "THIS IS A SCHEDULED EVENT Feb 14, 22:00 PST  -  Feb 15, 01:00 PST\nFeb  7, 14:03 PST\nScheduled - Our carrier partner H3G Austria is conducting a planned maintenance from 14 February 2024 at 22:00 PST until 15 February 2024 at 01:00 PST. During the maintenance window, there could be intermittent API request failures for H3G Austria customers.\n\nImpacted Products: Verify Silent Network Auth, Lookup SIM Swap",
          "link": "https://status.twilio.com/incidents/jc51lw4fvvlt",
          "publishedOn": "2024-02-15T06:00:00.000Z",
          "wordCount": 7523,
          "title": "Account Security Carrier Partner Maintenance - H3G Austria",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/620pqn54sl9c",
          "author": null,
          "description": "THIS IS A SCHEDULED EVENT Feb 14, 22:00 PST  -  Feb 15, 01:00 PST\nFeb  7, 14:02 PST\nScheduled - Our carrier partner Three UK is conducting a planned maintenance from 14 February 2024 at 22:00 PST until 15 February 2024 at 01:00 PST. During the maintenance window, there could be intermittent API request failures for Three UK customers.\n\nImpacted Products: Verify Silent Network Auth, Lookup SIM Swap, Lookup Identity Match, Legacy Identity MatchAndAttributes",
          "link": "https://status.twilio.com/incidents/620pqn54sl9c",
          "publishedOn": "2024-02-15T06:00:00.000Z",
          "wordCount": 7533,
          "title": "Account Security Carrier Partner Maintenance - Three UK",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/8qlybzzwfrbz",
          "author": null,
          "description": "THIS IS A SCHEDULED EVENT Feb 14, 21:00 PST  -  Feb 15, 01:30 PST\nFeb  9, 15:56 PST\nScheduled - A subset of small US networks in the US is conducting a planned maintenance from 14 February 2024 at 21:00 PST until 15 February 2024 at 01:30 PST. During the maintenance window, there could be intermittent delays delivering SMS to and from small US carriers.",
          "link": "https://status.twilio.com/incidents/8qlybzzwfrbz",
          "publishedOn": "2024-02-15T05:00:00.000Z",
          "wordCount": 7524,
          "title": "US SMS Carrier Maintenance - Small US Carriers",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/ghhy4r5s6sb6",
          "author": null,
          "description": "Feb 14, 16:15 PST\nCompleted - The scheduled maintenance has been completed.\nFeb 14, 16:00 PST\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nFeb  7, 22:50 PST\nScheduled - Our voice carrier partner in Germany is conducting a planned maintenance from 14 February 2024 at 16:00 PST until 14 February 2024 at 16:15 PST. During the maintenance window, there could be intermittent call disconnects or call failures from and to Twilio Germany phone numbers.",
          "link": "https://status.twilio.com/incidents/ghhy4r5s6sb6",
          "publishedOn": "2024-02-15T00:15:56.000Z",
          "wordCount": 7537,
          "title": "Germany Voice Carrier Partner Maintenance",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/k273q690dps5",
          "author": null,
          "description": "Feb 14, 16:01 PST\nCompleted - The scheduled maintenance has been completed.\nFeb 14, 12:00 PST\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nFeb  9, 06:54 PST\nScheduled - The Megafon and Yota networks in Russia are conducting a planned maintenance from 14 February 2024 at 12:00 PST until 14 February 2024 at 16:00 PST. During the maintenance window, there could be intermittent delays delivering SMS to Megafon and Yota Russia handsets.",
          "link": "https://status.twilio.com/incidents/k273q690dps5",
          "publishedOn": "2024-02-15T00:01:13.000Z",
          "wordCount": 7544,
          "title": "Russia SMS Carrier Maintenance - Megafon and Yota",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/q79pjh86mbh6",
          "author": null,
          "description": "Feb 14, 15:00 PST\nUpdate - We are experiencing SMS delivery delays when sending messages to Orange Network in Burkina Faso. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 2 hours or as soon as more information becomes available.\nFeb 14, 14:09 PST\nInvestigating - We are experiencing SMS delivery delays when sending messages to Orange Network in Burkina Faso. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 1 hour or as soon as more information becomes available.",
          "link": "https://status.twilio.com/incidents/q79pjh86mbh6",
          "publishedOn": "2024-02-14T23:00:39.000Z",
          "wordCount": 7572,
          "title": "SMS Delivery Delays to Orange Network in Burkina Faso",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/dhb0hj0dm9qf",
          "author": null,
          "description": "Feb 14, 14:26 PST\nResolved - All services impacted by the issues with the Twilio Rest API have recovered and are operating as intended. This incident has been resolved.\nFeb 14, 13:55 PST\nMonitoring - We're seeing recovery in the Twilio Rest API, impacting multiple Twilio services. Please see impacted services as follows:\nTaskrouter: Customers are unable to create, update, or delete via REST API\nFlex platform: Agent Login/Inbound outbound conversation \nProgrammable Video: Unable to create and modify rooms via Rest API \nVerify: Customers may have seen errors\nProgrammable Messaging (SMS): Customers may experience 5XX errors\nWe will be monitoring all services to ensure a full recovery and provide another update in 30 minutes or as soon as more information becomes available.\nFeb 14, 13:25 PST\nUpdate - We are experiencing issues with the Twilio Rest API, impacting multiple Twilio services. We're seeing impact on Verify, Programmable Messaging (SMS), Taksrouter and Flex agent login/inbound conversations. Our engineering team is actively working to resolve the issue. We expect to provide another update in 30 mins or as soon as more information becomes available.\nFeb 14, 13:04 PST\nInvestigating - We are currently investigating errors for the Twilio Rest API, impacting multiple Twilio services. Our engineering team has been alerted and is actively investigating. We will update as soon as we have more information.",
          "link": "https://status.twilio.com/incidents/dhb0hj0dm9qf",
          "publishedOn": "2024-02-14T22:26:07.000Z",
          "wordCount": 7696,
          "title": "Twilio Rest API Errors Impacting Multiple Twilio Services",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/hn0pm8zdrnk2",
          "author": null,
          "description": "Feb 14, 14:00 PST\nCompleted - The scheduled maintenance has been completed.\nFeb 14, 12:01 PST\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nFeb 12, 15:18 PST\nScheduled - The Beeline network in Russia is conducting a planned maintenance from 14 February 2024 at 12:00 PST until 14 February 2024 at 14:00 PST. During the maintenance window, there could be intermittent delays delivering SMS to Beeline Russia handsets.",
          "link": "https://status.twilio.com/incidents/hn0pm8zdrnk2",
          "publishedOn": "2024-02-14T22:00:56.000Z",
          "wordCount": 7537,
          "title": "Russia SMS Carrier Maintenance - Beeline (VimpelCom)",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/3mm8m3r1h5n7",
          "author": null,
          "description": "Feb 14, 13:20 PST\nCompleted - The scheduled maintenance has been completed.\nFeb 14, 10:20 PST\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nFeb 12, 22:47 PST\nScheduled - The Motiv network in Russia is conducting an emergency maintenance from 14 February 2024 at 10:20 PST until 14 February 2024 at 13:20 PST. During the maintenance window, there could be intermittent delays delivering SMS to Motiv Russia handsets.",
          "link": "https://status.twilio.com/incidents/3mm8m3r1h5n7",
          "publishedOn": "2024-02-14T21:20:56.000Z",
          "wordCount": 7534,
          "title": "Russia SMS Carrier Maintenance - Motiv",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/vtvk2sws68mw",
          "author": null,
          "description": "Feb 14, 13:00 PST\nCompleted - The scheduled maintenance has been completed.\nFeb 14, 11:00 PST\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nFeb 14, 07:51 PST\nScheduled - The NUR Telecom network in Kyrgyzstan is conducting a planned maintenance from 14 February 2024 at 11:00 PST until 14 February 2024 at 13:00 PST. During the maintenance window, there could be intermittent delays delivering SMS to NUR Telecom Kyrgyzstan handsets.",
          "link": "https://status.twilio.com/incidents/vtvk2sws68mw",
          "publishedOn": "2024-02-14T21:00:58.000Z",
          "wordCount": 7539,
          "title": "Kyrgyzstan SMS Carrier Maintenance - NUR Telecom",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    },
    {
      "title": "DigitalOcean Status - Incident History",
      "feedUrl": "https://status.digitalocean.com/history.rss",
      "siteUrl": "http://status.digitalocean.com",
      "articles": [
        {
          "id": "https://status.digitalocean.com/incidents/w1sspyd728kg",
          "author": null,
          "description": "Feb  7, 20:54 UTC\nResolved - As of 19:37 UTC, our Engineering team has confirmed the full resolution of the problem impacting the Droplet resize events in all regions. All the Droplet resize events should now be succeeding normally. \nIf you continue to experience problems, please open a ticket with our Support team. \nThank you for your patience and we apologize for the inconvenience.\nFeb  7, 19:41 UTC\nMonitoring - Our Engineering team has fully deployed the fix for the issue with Droplet resizes and is now monitoring the situation. Users can now retry Droplet resizes and should see them succeed.\nWe'll post another update once we confirm the fix resolves this incident.\nFeb  7, 15:49 UTC\nIdentified - Our Engineering team has identified the root cause of the issue with failed Droplet resizes and a fix is in the process of being deployed. \nUsers attempting to resize Droplets where the image for the Droplet has been deleted or retired (e.g. a user created a Droplet from a Snapshot, but later deleted that Snapshot) will see failures. All other resizes are succeeding normally.\nWe'll post another update once the fix has completed deployment.\nFeb  7, 15:32 UTC\nInvestigating - Our Engineering team is investigating an uptick in failed Droplet resizes, beginning Feb 6, 20:57 UTC. \nDuring this time, some users may experience failures when attempting to resize Droplets, in all regions. \nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/w1sspyd728kg",
          "publishedOn": "2024-02-07T20:54:58.000Z",
          "wordCount": 6430,
          "title": "Droplet Resize Events",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/y2cm9wm1bvv7",
          "author": null,
          "description": "Feb  7, 07:21 UTC\nResolved - Our Engineering team has confirmed the resolution of the issue impacting network latency in our NYC regions.\nThe issues were a direct result of traffic congestion from our upstream providers, which has been repaired. Users should no longer experience packet loss or increased latency while interacting with their resources in the NYC regions.\nWe sincerely apologize and thank you for your patience as we worked through this issue. In case of any questions or concerns, please open a ticket with our Support team.\nFeb  7, 04:03 UTC\nInvestigating - Our Engineering team is investigating multiple reports of network latency when connecting to services in our NYC regions. During this time, users may experience intermittent packet loss or increased latency while interacting with their resources in the NYC regions.\nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/y2cm9wm1bvv7",
          "publishedOn": "2024-02-07T07:21:30.000Z",
          "wordCount": 6332,
          "title": "Networking in NYC Regions",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/1jwy0vy3hjfb",
          "author": null,
          "description": "Feb  6, 22:21 UTC\nCompleted - The scheduled maintenance has been completed.\nFeb  6, 17:00 UTC\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nFeb  2, 20:23 UTC\nScheduled - Start Time: 17:00 UTC Feb 6, 2024\nEnd Time: 00:00 UTC Feb 7, 2024\nDuring the above time, our Engineering Team will be performing maintenance to failover some internal databases from one cluster to another.\nExtensive testing has been conducted to ensure this maintenance will be successful and result in minimal impact to DigitalOcean users. The actual failover is estimated to take less than 3 seconds.\nExisting infrastructure, including Droplets and Droplet-based services, should continue running without issue. There is no network disruption to existing services expected as part of this maintenance. However, there are dependencies on multiple services. During the failover, there may be customer impacts that should be brief and transitory. The following actions may experience increased latency or failure rates during the maintenance period:\n- API calls to the DigitalOcean public API \n- Events for Droplets and Droplet-based services such as create, delete, power on/off, resize, etc \n- Control operations through the DigitalOcean Cloud Control Panel \nMultiple teams will be engaged to keep downtime to a minimum and mitigate any impact that does occur. We’ll post updates here for any unexpected changes to this scheduled maintenance, as well as progress updates during the maintenance itself.\nIf you have any questions or concerns, please reach out to the Support team from within your account.",
          "link": "https://status.digitalocean.com/incidents/1jwy0vy3hjfb",
          "publishedOn": "2024-02-06T22:21:17.000Z",
          "wordCount": 6438,
          "title": "Core Infrastructure Maintenance",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/1q1jhbr85zvv",
          "author": null,
          "description": "Feb  5, 05:54 UTC\nResolved - Our Engineering team has confirmed the resolution of the issue impacting Spaces CDN in our SGP1 region.\nFrom 03:02 UTC - 05:15 UTC, users were experiencing errors for objects served over the CDN.\nWe apologize for the inconvenience. If you have any questions or continue to experience issues, please reach out via a Support ticket on your account.\nFeb  5, 05:10 UTC\nMonitoring - Our Engineering team has applied a fix to mitigate the issue related to the Spaces CDN in the SGP1 region. Users should no longer experience errors for objects served over the CDN. \nWe apologize for the inconvenience and will post another update once we're confident that the issue is fully resolved.\nFeb  5, 04:52 UTC\nIdentified - From 03:02 UTC, our Engineering team has identified an issue with the Spaces CDN in our SGP1 region and is actively working on a fix. During this time, users may experience errors for objects served over the CDN. \nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/1q1jhbr85zvv",
          "publishedOn": "2024-02-05T05:54:58.000Z",
          "wordCount": 6365,
          "title": "Spaces CDN in SGP1",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/swc8grzsb33n",
          "author": null,
          "description": "Jan 31, 15:26 UTC\nResolved - Our team has confirmed the full resolution for the problem with our support portal at https://cloudsupport.digitalocean.com/s/ where customers were unable to create tickets with 'Billing' ticket type. \nWe sincerely apologize and thank you for your patience as we worked through this issue. \nIn case of any questions or concerns, please open a ticket with our Support team.\nJan 31, 15:12 UTC\nMonitoring - Our Engineering team has identified the cause of the issue and implemented a fix to resolve the problem with the Support Portal. Users should now be able to create the tickets in the Support portal with Billing ticket type. \nWe are monitoring the situation now and will post an update as soon as the issue is fully resolved.\nJan 31, 14:26 UTC\nInvestigating - Our Engineering team is investigating an issue with customers being unable to create the support tickets to our support portal for Ticket type \"Billing\" at https://cloudsupport.digitalocean.com. \nAs a temporary workaround, users may still contact us via the form here: https://www.digitalocean.com/company/contact/support\nWe apologize for the inconvenience and will post an update as soon as further information is available.",
          "link": "https://status.digitalocean.com/incidents/swc8grzsb33n",
          "publishedOn": "2024-01-31T15:26:00.000Z",
          "wordCount": 6375,
          "title": "Customer Support Ticket Portal",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/39r97dl3v2l0",
          "author": null,
          "description": "Jan 30, 16:42 UTC\nResolved - Our Engineering team identified and resolved an issue impacting the Snapshots page in our Cloud Control Panel. \nFrom 13:00 - 15:00 UTC, users attempting to navigate to https://cloud.digitalocean.com/images/snapshots (via Images -> Snapshots) were unable to access the page, and instead saw an error page returned. \nWe apologize for the inconvenience. If you have any questions or continue to experience issues, please reach out via a Support ticket on your account.",
          "link": "https://status.digitalocean.com/incidents/39r97dl3v2l0",
          "publishedOn": "2024-01-30T16:42:28.000Z",
          "wordCount": 6259,
          "title": "Snapshots Page - Cloud Control Panel",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/r9w0yrbyy9ls",
          "author": null,
          "description": "Jan 29, 18:36 UTC\nResolved - Our Engineering team has confirmed the workaround fix is successful and all services should now be operating normally. We will now close this incident and work with the DNS provider separately on the root cause. \nWe appreciate your patience throughout the process and if you continue to experience problems, please open a ticket with our support team for further review.\nJan 29, 18:18 UTC\nMonitoring - Our Engineering team has identified the root cause of the issue with DNS resolution. DigitalOcean resolvers in use in FRA1, AMS3, and LON1 are unable to reach an upstream DNS provider, resulting in resolution for a subset of domain names being unavailable from our resolvers. Our Engineering team is reaching out to the provider for assistance.\nIn the meantime, our Engineering team has been able to implement a workaround fix by filtering some incorrectly announced network routes. At this time, we are seeing recovery and resolution of hostnames returning to normal in the impacted regions. We'll continue to await an update from the DNS provider. We're now monitoring the workaround fix for stability and will post an update once we are confident it is successful.\nJan 29, 17:27 UTC\nInvestigating - Our Engineering team is currently investigating issues with DNS resolution in FRA1, AMS3, and LON1. During this time, customers may experience errors trying to resolve domain names from within DigitalOcean services in those regions, including Droplets and Droplet-based services, as well as App Platform. Additionally, App Platform builds may fail or experience delays. \nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/r9w0yrbyy9ls",
          "publishedOn": "2024-01-29T18:36:45.000Z",
          "wordCount": 6473,
          "title": "DNS Resolution in FRA1, AMS3 and LON1 Regions",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/2yxmsbx1r89b",
          "author": null,
          "description": "Jan 25, 02:56 UTC\nResolved - Our Engineering team has resolved the issue with snapshots taken by customers in the NYC3 and SFO3 regions. If you continue to experience problems, please open a ticket with our support team. Thank you for your patience and we apologize for any inconvenience.\nJan 25, 01:50 UTC\nMonitoring - Our Engineering team has implemented a fix to resolve the issue with snapshots taken by customers in the NYC3 and SFO3 regions and are monitoring the situation closely. \nWe will post another update once we're confident that the issue is fully resolved.\nJan 25, 00:26 UTC\nIdentified - Our Engineering team has identified an issue with snapshots taken by customers in the NYC3 and SFO3 regions and is actively working on a fix. We will post an update as soon as additional information is available.",
          "link": "https://status.digitalocean.com/incidents/2yxmsbx1r89b",
          "publishedOn": "2024-01-25T02:56:12.000Z",
          "wordCount": 6340,
          "title": "Snapshots are failing in SFO3 and NYC3",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/s4kt15q6xq19",
          "author": null,
          "description": "Jan 23, 22:50 UTC\nResolved - Our Engineering team has completed mitigation efforts for the issue impacting Managed Kubernetes in the FRA1 region and we are marking this incident as Resolved. \nAt this time, functionality to impacted clusters has been restored but customers may need to reconfigure some Kubernetes resources. Customer Support is contacting impacted customers directly with further instructions. \nIf you have any questions or concerns regarding this incident, please open a ticket with our support team.\nJan 23, 18:44 UTC\nUpdate - Our Engineering team continues to work on mitigation efforts. An additional small bug has been discovered and remediated. About 10% of clusters have had accessibility restored and restoration efforts are ongoing. \nWe will post another update as soon as we have new developments.\nThank you for your patience and we apologize for any inconvenience.\nJan 23, 15:12 UTC\nIdentified - Our Engineering team has identified the cause of the issue with Managed Kubernetes clusters in the FRA1 region. 200 clusters are impacted by the issue and remain inaccessible to users at this time. \nOur Engineering team is engaged in remediating these clusters to restore accessibility. As soon as we are able to provide an estimated time to restore, we will provide an update.\nJan 23, 13:02 UTC\nInvestigating - As of 12:18 UTC, our Engineering team is investigating an issue with Kubernetes clusters in the FRA1 region. During this time, users may experience errors while communicating with their clusters in the FRA1 region. \nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/s4kt15q6xq19",
          "publishedOn": "2024-01-23T22:50:40.000Z",
          "wordCount": 6827,
          "title": "Managed Kubernetes Cluster in FRA1",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/9y133zrfqngf",
          "author": null,
          "description": "Jan 22, 18:38 UTC\nResolved - As of 18:37 UTC, our Engineering team has confirmed the full resolution of the issue that impacted network reachability in the LON1 region. All services and resources should now be fully reachable.\nIf you continue to experience problems, please open a ticket with our support team from within your Cloud Control Panel. \nThank you for your patience and we apologize for any inconvenience.\nJan 22, 13:32 UTC\nMonitoring - The network issues affecting our LON1 region have been mitigated. Users should no longer experience packet loss/latency, timeouts, and related issues with Droplet-based services in this region, including Droplets, LBaas, Managed Kubernetes, and Managed Database. \nWe are currently monitoring the situation closely and will share an update as soon as the issue is fully resolved.\nJan 22, 12:25 UTC\nIdentified - Our Engineering team has identified the cause of the issue impacting networking in the LON1 region and is actively working on a fix.\nDuring this time, users may still experience packet loss/latency, timeouts, and related issues with Droplet-based services in this region, including Droplets, LBaaS, Managed Kubernetes, and Managed Databases.\nWe will post an update as soon as additional information is available\nJan 22, 11:36 UTC\nInvestigating - Our Engineering team is investigating a networking issue in our LON1 region. At this time, you may experience packet loss or dropped connections.\nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/9y133zrfqngf",
          "publishedOn": "2024-01-22T18:38:44.000Z",
          "wordCount": 6426,
          "title": "Network connectivity in LON1",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/299xh1cfs8s5",
          "author": null,
          "description": "Jan 22, 10:32 UTC\nResolved - Our Engineering team has resolved the issue impacting Spaces API availability in our SFO2 region. From approximately 09:00 UTC - 10:00 UTC, users may have experienced latency or timeouts when trying to access or manage their Spaces buckets. Spaces should now be operating normally.\nIf you continue to experience problems, please open a ticket with our Support team. Thank you for your patience and we apologize for any inconvenience.\nJan 22, 10:10 UTC\nMonitoring - Our Engineering team has implemented a fix to resolve the issue impacting SFO2 Spaces API availability and monitoring the situation. We will post an update as soon as the issue is fully resolved.\nJan 22, 09:59 UTC\nIdentified - As of 09:50 UTC, our Engineering team has identified the cause of the issue impacting Spaces API availability in our SFO2 region and is actively working on a fix.\nWe will post an update as soon as additional information is available\nJan 22, 09:13 UTC\nInvestigating - As of 09:00 UTC, Our Engineering team is investigating an issue impacting Spaces API availability in our SFO2 region.\nDuring this time, users may experience slowness or timeouts when trying to access or manage their Spaces resources in SFO2.\nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/299xh1cfs8s5",
          "publishedOn": "2024-01-22T10:32:23.000Z",
          "wordCount": 6405,
          "title": "Spaces availability in SFO2",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/x0f8bvr688rs",
          "author": null,
          "description": "Jan 17, 09:34 UTC\nResolved - As of 09:17 UTC, our Engineering team has confirmed the full resolution of the issue impacting the Droplet rebuild via the Cloud Control Panel.\nWe appreciate your patience throughout the process. If you continue to experience problems, please open a ticket with our support team.\nJan 17, 09:22 UTC\nMonitoring - Our Engineering team has taken actions to mitigate the issue impacting the Droplet rebuild via Cloud Control Panel and is monitoring the situation.\nThe impact has been subsided and the users should no longer experience issues when rebuilding Droplets from the Cloud Control Panel. We apologize for the inconvenience and we will post an update once we confirm this incident is fully resolved.\nJan 17, 08:26 UTC\nIdentified - Our Engineering team has identified the cause of the issue impacting the Droplet rebuild via the Cloud Control Panel and is actively working on a fix. During this time, users may get an error response when trying to rebuild the Droplet via the Cloud Control Panel. We will post an update as soon as additional information is available.\nJan 17, 07:15 UTC\nInvestigating - As of 06:50 UTC, our Engineering team is investigating an issue impacting the Droplet rebuild via the Cloud Control Panel.\nDuring this time, users may get an error response when trying to rebuild the Droplet via the Cloud Control Panel.\nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/x0f8bvr688rs",
          "publishedOn": "2024-01-17T09:34:03.000Z",
          "wordCount": 6436,
          "title": "Droplet rebuild",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/j4jwmwl3szxz",
          "author": null,
          "description": "Jan 16, 13:34 UTC\nResolved - Our Engineering team has resolved the issue impacting multiple spaces-related functionalities. From approximately 10:30 UTC - 13:30 UTC, users may have experienced issues while trying to perform multiple actions on Spaces via the Cloud Control Panel and API. Spaces-related functionalities should now be operating normally.\nIf you continue to experience problems, please open a ticket with our Support team. Thank you for your patience and we apologize for any inconvenience.\nJan 16, 12:51 UTC\nMonitoring - Our Engineering team has taken actions to mitigate the issue affecting multiple Spaces-related functionalities and is monitoring the situation.\nThe impact has been subsided and the users should no longer experience issues with Spaces-related functionalities. \nWe apologize for the inconvenience and we will post an update once we confirm this incident is fully resolved.\nJan 16, 12:03 UTC\nIdentified - Our Engineering team has identified the issue affecting multiple Spaces-related functionalities and is actively working on a fix.\nDuring this time, users may experience issues while trying to perform multiple actions on Spaces via the Cloud Control Panel and API.\nAdditionally, this may also impact Container Registry creation and issues with transferring images between regions. \nWe apologize for the inconvenience and will share an update once we have more information.\nJan 16, 10:54 UTC\nInvestigating - As of 10:30 UTC, our Engineering team is investigating an issue with multiple Spaces functionalities via the Cloud Control Panel. \nDuring this time, users may experience errors when attempting to delete objects via the Cloud Control Panel. At this moment we are investigating the exact impact and will share more information as soon as we have it.\nWe apologize for the inconvenience.",
          "link": "https://status.digitalocean.com/incidents/j4jwmwl3szxz",
          "publishedOn": "2024-01-16T13:34:24.000Z",
          "wordCount": 6481,
          "title": "Spaces Functionality",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    },
    {
      "title": "Notion Status - Incident History",
      "feedUrl": "https://status.notion.so/history.rss",
      "siteUrl": "https://status.notion.so",
      "articles": [
        {
          "id": "https://status.notion.so/incidents/2b5f3nmpht76",
          "author": null,
          "description": "Feb 12, 15:34 PST\nResolved - This incident has been resolved.",
          "link": "https://status.notion.so/incidents/2b5f3nmpht76",
          "publishedOn": "2024-02-12T23:34:06.000Z",
          "wordCount": 3349,
          "title": "Notion app experienced a brief outage due to a deployment that didn't function as expected",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/2wtslqc6bv54",
          "author": null,
          "description": "Feb  6, 09:58 PST\nResolved - This incident has been resolved.\nFeb  6, 09:16 PST\nUpdate - We are working hard to resolve the issue for you. Thank you for your continuous patience.\nFeb  6, 07:00 PST\nUpdate - We are still working on fixing the issue and appreciate your patience.\nFeb  6, 05:05 PST\nIdentified - We are experiencing an issue with the Notion's database automations service that cause automation actions to fail or experience delays. Our engineers have identified this & are working on a fix.",
          "link": "https://status.notion.so/incidents/2wtslqc6bv54",
          "publishedOn": "2024-02-06T17:58:31.000Z",
          "wordCount": 3395,
          "title": "Database Automations failing",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/f88y9tn65kl1",
          "author": null,
          "description": "Feb  5, 16:32 PST\nResolved - This incident has been resolved.\nFeb  5, 16:03 PST\nUpdate - We are continuing to investigate this issue.\nFeb  5, 16:02 PST\nInvestigating - We are currently investigating this issue.",
          "link": "https://status.notion.so/incidents/f88y9tn65kl1",
          "publishedOn": "2024-02-06T00:32:44.000Z",
          "wordCount": 3396,
          "title": "A number of South Korean users inadvertently banned from using vital APIs in Notion, potentially affecting some functionalities within the app.",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/w7ppqptykrdz",
          "author": null,
          "description": "Feb  5, 06:56 PST\nResolved - Between 3:00 UTC - 14:22 UTC, some users may have experienced database automation failures or delays in actions being triggered.\nThis is now resolved, and the affected automations have completed. Database automation services are now running as normal. \nThank you for your patience while we worked through this issue.\nFeb  5, 05:30 PST\nMonitoring - Notion's database automation service began experiencing problems at approximately 3 AM UTC today, which caused a number of automation actions to fail or experience delays. \nOur engineers have identified a fix, and are now retrying automations that failed to trigger during this period. \nWe will continue to monitor the situation and share an update when this is fully resolved.",
          "link": "https://status.notion.so/incidents/w7ppqptykrdz",
          "publishedOn": "2024-02-05T14:56:59.000Z",
          "wordCount": 3422,
          "title": "Database Automation Failures",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/q9j3jvg634lx",
          "author": null,
          "description": "Feb  2, 14:45 PST\nResolved - As of 2:44 PM PT, this incident has been resolved.\nFeb  2, 11:52 PST\nMonitoring - As of 11:44 AM PT, a fix has been implemented and we are monitoring the results.\nFeb  2, 11:42 PST\nUpdate - We are continuing to investigate this issue.\nFeb  2, 11:42 PST\nUpdate - Users cannot join and create a workspace from their sidebar. In addition, users may experience increased latency across search, viewing and editing content, and syncing content.\nWe are actively investigating these issues and will follow up here with an update.\nFeb  2, 11:36 PST\nInvestigating - Currently, the \"Join or create a workspace\" button from the workspace sidebar is broken.\nWe are actively investigating the issue and will follow up here with an update.",
          "link": "https://status.notion.so/incidents/q9j3jvg634lx",
          "publishedOn": "2024-02-02T22:45:22.000Z",
          "wordCount": 3457,
          "title": "Joining or creating a workspace from sidebar is broken",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/t93zz4ynglj2",
          "author": null,
          "description": "Jan 31, 15:01 PST\nResolved - This incident has been resolved.\nJan 31, 15:00 PST\nUpdate - We are continuing to work on a fix for this issue.\nJan 31, 13:41 PST\nIdentified - We identified the root cause and are preparing a hotfix.\nJan 31, 11:05 PST\nUpdate - We are continuing to investigate this issue.\nJan 31, 11:05 PST\nInvestigating - As of 12:35 AM PT the /search endpoint (https://api.notion.com/v1/search) has been down. \nWe are currently investigating the issue and will share an update once the issue has been identified.",
          "link": "https://status.notion.so/incidents/t93zz4ynglj2",
          "publishedOn": "2024-01-31T23:01:16.000Z",
          "wordCount": 3408,
          "title": "Search API endpoint is down",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    },
    {
      "title": "Rippling Status - Incident History",
      "feedUrl": "https://status.rippling.com/history.rss",
      "siteUrl": "https://status.rippling.com",
      "articles": []
    },
    {
      "title": "Google Workspace Status Dashboard Updates",
      "feedUrl": "https://www.google.com/appsstatus/dashboard/en/feed.atom",
      "siteUrl": "https://www.google.com/appsstatus/dashboard/",
      "articles": []
    },
    {
      "title": "GitHub Status - Incident History",
      "feedUrl": "https://www.githubstatus.com/history.rss",
      "siteUrl": "https://www.githubstatus.com",
      "articles": [
        {
          "id": "https://www.githubstatus.com/incidents/k0qjh7s64fxk",
          "author": null,
          "description": "Feb 12, 18:14 UTC\nResolved - On Monday February 12th, 2024, 03:00 UTC we deployed a code change to a component of Copilot. At 06:00 UTC we observed an increase in timeouts for code completions impacting 55% of Copilot users at peak across Asia and Europe.\nAt 12:00 UTC we restarted the nodes, and response durations returned to normal operation until 13:00 UTC when response durations degraded again. At 16:15 UTC we made a configuration change to send traffic to regions that were not exhibiting the errors, which resulted in code completions working fully although completing at a higher latency than normal for some users. At 18:00 UTC we reverted the deploy and response durations returned to normal. \nWe have added better monitoring to components that failed to decrease resolution times to inci…",
          "link": "https://www.githubstatus.com/incidents/k0qjh7s64fxk",
          "publishedOn": "2024-02-12T18:14:07.000Z",
          "wordCount": 5684,
          "title": "Incident with Copilot",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/vv6z7v5w80yr",
          "author": null,
          "description": "Feb 12, 12:39 UTC\nResolved - On Monday February 12th, 2024, 03:00 UTC we deployed a code change to a component of Copilot. At 06:00 UTC we observed an increase in timeouts for code completions impacting 55% of Copilot users at peak across Asia and Europe.\nAt 12:00 UTC we restarted the nodes, and response durations returned to normal operation until 13:00 UTC when response durations degraded again. At 16:15 UTC we made a configuration change to send traffic to regions that were not exhibiting the errors, which resulted in code completions working fully although completing at a higher latency than normal for some users. At 18:00 UTC we reverted the deploy and response durations returned to normal. \nWe have added better monitoring to components that failed to decrease resolution times to incidents like this in the future.\nFeb 12, 12:29 UTC\nUpdate - We are starting to see recovery based on the signals that the team have been monitoring, following mitigation steps being taken. When confident that recovery is complete, we will resolve this incident.\nFeb 12, 12:00 UTC\nUpdate - We are continuing to investigate increased failure rates for Copilot code completion for some users in Europe.\nFeb 12, 11:38 UTC\nUpdate - We are investigating reports that GitHub Copilot code completions are not working for some users in Europe.\nFeb 12, 11:38 UTC\nInvestigating - We are investigating reports of degraded performance for Copilot",
          "link": "https://www.githubstatus.com/incidents/vv6z7v5w80yr",
          "publishedOn": "2024-02-12T12:39:20.000Z",
          "wordCount": 5486,
          "title": "Incident with Copilot",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/my7r3l9lsqnk",
          "author": null,
          "description": "Feb  9, 11:28 UTC\nResolved - On February 9, 2024 between 10:34 UTC and 11:24 UTC, the Webhooks service was degraded and 63% of webhooks were delayed by up to 16 minutes with an average delay of 5 minutes. No webhook deliveries were lost. This was due to an issue with an overloaded backend data store that was unable to process network requests fast enough.\nWe mitigated the incident by manually failing over traffic to healthy hosts.\nWe are expanding the capacity of the backing store as well as making the Webhooks service more resilient to this kind of issue. \n\nFeb  9, 11:25 UTC\nUpdate - Webhooks is operating normally.\nFeb  9, 11:11 UTC\nUpdate - We are investigating latency in processing webhooks. Customers may see a delay of around 5 minutes at this time. We will continue to keep users updated on progress towards mitigation.\nFeb  9, 11:09 UTC\nInvestigating - We are investigating reports of degraded performance for Webhooks",
          "link": "https://www.githubstatus.com/incidents/my7r3l9lsqnk",
          "publishedOn": "2024-02-09T11:28:59.000Z",
          "wordCount": 5407,
          "title": "Incident with Webhooks",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/3k40h28fkb2r",
          "author": null,
          "description": "Feb  5, 09:53 UTC\nResolved - On 2024-02-05, from 09:26 to 13:20 UTC some GitHub customers experienced errors when trying to download raw files. An overloaded server exposed a bug, causing us to return HTTP 500 error codes.\nThe issue was mitigated by disabling the server and re-routing traffic. We are implementing improvements to our routing logic to more quickly avoid troublesome hosts in the future. \n\nFeb  5, 09:40 UTC\nInvestigating - We are investigating reports of degraded performance for Git Operations",
          "link": "https://www.githubstatus.com/incidents/3k40h28fkb2r",
          "publishedOn": "2024-02-05T09:53:13.000Z",
          "wordCount": 5329,
          "title": "Incident with Git Operations",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/7k5wl5j4f1t4",
          "author": null,
          "description": "Feb  1, 04:41 UTC\nResolved - An update to our design system caused issues loading dynamic content in the global side navigation menu and in other page-specific sidebar navigation elements. Impacted users saw continuous loading spinners in place of dynamic menu content. User impact lasted from 0:55 UTC to 4:41 UTC on February 1st.\nWe are working on a number of improvements in response to this incident. We are adding request volume monitors to sidebar navigation endpoints and making changes to our front end escalation paths to improve our time to detect and time to recovery for incidents of this nature. We have also begun work to improve both automated and manual testing for these types of changes in order to prevent recurrence.\nFeb  1, 04:41 UTC\nUpdate - This issue has been resolved. A reload of your browser window/tab may be required if you continue to experience issues with the collapsable navigation sidebars not loading.\nFeb  1, 04:21 UTC\nUpdate - We are in the process of deploying a remediation, and expect to see restoration of impacted functionality within the next hour.\nFeb  1, 03:55 UTC\nUpdate - We have identified an issue that is preventing some navigation components from loading while browsing GitHub.com, and are testing a remediation prior to deployment.\nFeb  1, 03:14 UTC\nUpdate - We are currently investigating reports of some components of the GitHub.com website not loading for some users.\nFeb  1, 03:13 UTC\nInvestigating - We are currently investigating this issue.",
          "link": "https://www.githubstatus.com/incidents/7k5wl5j4f1t4",
          "publishedOn": "2024-02-01T04:41:36.000Z",
          "wordCount": 5507,
          "title": "We are investigating reports of degraded performance.",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/5y8b8lsqbbyq",
          "author": null,
          "description": "Jan 31, 14:57 UTC\nResolved - This incident was the result of an infrastructure change that was made to our load balancers to prepare us for IPv6 enablement of GitHub.com. This change was deployed to a subset of our global edge sites.\nThe change had the unintended consequence of causing IPv4 addresses to start being passed as an IPv4-mapped IPv6-compatible address to our IP Allow List functionality.\nFor example 10.1.2.3 became ::ffff:10.1.2.3. While our IP Allow List functionality was developed with IPv6 in mind, it wasn't developed to handle these mapped addresses, and hence started blocking requests as it deemed these to be not in the defined list of allowed addresses. Request error rates peaked at 0.23% of all requests.\nWe have so far identified three remediation items here:\n- Update the IP Allow List functionality to handle IPv4-mapped addresses.\n- Audit the rest of our stack to confirm there are no further places this IPv4-mapped IPv6 addresses flaw exists.\n- Improve our testing and monitoring processes to better catch these issues in the future.\nJan 31, 14:56 UTC\nUpdate - We have resolved the issue and confirmed all regions are now operating as expected.\nJan 31, 14:49 UTC\nUpdate - The fix for ip allow lists is currently rolling out; and we are awaiting confirmation from specific geographic regions.\nJan 31, 14:33 UTC\nUpdate - We are rolling out a fix to resolve the issues with IP allow lists. This should be resolved shortly.\nJan 31, 14:14 UTC\nUpdate - Some customers are experiencing issues with IP allow lists.\nJan 31, 14:14 UTC\nInvestigating - We are currently investigating this issue.",
          "link": "https://www.githubstatus.com/incidents/5y8b8lsqbbyq",
          "publishedOn": "2024-01-31T14:57:16.000Z",
          "wordCount": 5526,
          "title": "We are investigating reports of degraded performance.",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/g6drnqm54qd4",
          "author": null,
          "description": "Jan 28, 14:42 UTC\nResolved - On January 28, 2024, between 01:00 UTC and 14:00 UTC the Avatars service was degraded and could not return all avatar images requested by users, instead it would return a default, fallback avatar image. This incident impacted, at peak time 6% of the requests for viewing Avatars. Requests that were impacted did not prevent the users from continuing to use any GitHub services. This was due to an issue with the Avatars service connecting to a database host.\n We mitigated the incident by restarting the malfunctioning hosts that were not able to return the user avatar images.\n We are working to improve alerting and monitoring of our services to reduce our time to detection and mitigation.\nJan 28, 14:27 UTC\nUpdate - We have mitigated all customer impact. We are no longer serving fallback avatar icons when loading web pages for some customers. We continue to monitor the results.\nJan 28, 13:57 UTC\nUpdate - A fix has been implemented for customers seeing the default avatar (octocat) when loading web pages and we are monitoring the results.\nJan 28, 13:20 UTC\nUpdate - Some requests for getting the Avatars are returning the fallback response instead of the asked avatar since they are having issues connecting to the Mysql host\nJan 28, 13:20 UTC\nInvestigating - We are currently investigating this issue.",
          "link": "https://www.githubstatus.com/incidents/g6drnqm54qd4",
          "publishedOn": "2024-01-28T14:42:55.000Z",
          "wordCount": 5485,
          "title": "We are investigating reports of degraded performance.",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/bsk6hmj0d7nv",
          "author": null,
          "description": "Jan 23, 18:53 UTC\nResolved - On January 23, 2024 at 14:36 UTC, our internal metrics began showing an increase in exceptions originating from our live update service. Live updates to Issues, PRs, Actions, and Projects were failing, but refreshing the page successfully updated page content. We resolved the issue by rolling back a problematic dependency update and reenabled live updates at 18:53 UTC. \nWe are working to improve alerting and monitoring of our live update service to reduce our time to detection and mitigation.\nJan 23, 18:53 UTC\nUpdate - Live updates have been restored and the system is operating normally.\nJan 23, 18:14 UTC\nUpdate - We have identified and are beginning to roll out a potential fix for issues with live updates to our Web UI that power automatic page updates such as…",
          "link": "https://www.githubstatus.com/incidents/bsk6hmj0d7nv",
          "publishedOn": "2024-01-23T18:53:29.000Z",
          "wordCount": 5695,
          "title": "We are investigating reports of degraded performance.",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/7ck5966p1073",
          "author": null,
          "description": "Jan 21, 09:34 UTC\nResolved - On 2024-01-21 at 3:38 UTC, we experienced an incident that affected customers using Codespaces. Customers encountered issues creating and resuming Codespaces in multiple regions due to operational issues with compute and storage resources.\nAround 25% of customers were impacted, primarily in East US and West Europe. We re-routed traffic for Codespace creations to less impacted regions, but existing Codespaces in these regions may have been unable to resume during the incident.\nBy 7:30 UTC, we had recovered connectivity to all regions except West Europe, which had an extended recovery time due to increased load in that particular region. The incident was resolved on 2024-01-21 at 9:34 UTC once Codespace creations and resumes were working normally in all regions.\n…",
          "link": "https://www.githubstatus.com/incidents/7ck5966p1073",
          "publishedOn": "2024-01-21T09:34:34.000Z",
          "wordCount": 5691,
          "title": "Incident with Codespaces",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/hmvr5kpgzc45",
          "author": null,
          "description": "Jan 21, 06:19 UTC\nResolved - On 2024-01-21 from 02:05 UTC to 06:19 UTC, GitHub Hosted Runners experienced increased error rates from our main cloud service provider. The errors were initially limited to a single region and we were able to route around the issue by transparently failing over to other regions. However, errors gradually expanded across all regions we deploy to and led to our available compute capacity being exhausted.\nDuring the incident, up to 35% of Actions jobs using Larger Runners and 2% of Actions jobs using GitHub Hosted Runners overall may have experienced intermittent delays in starting. Once the issue was resolved by our cloud service provider, our systems made a full recovery without intervention.\nWe’re working closely with our service provider to understand the cause of the outage and mitigations we can put in place. We’re also working to increase our resilience to outages of this nature by expanding the regions we deploy to beyond the existing set, especially for Larger Runners.\nJan 21, 05:54 UTC\nUpdate - We've applied a mitigation to fix the issues with queuing and running Actions jobs. We are seeing improvements in telemetry and are monitoring for full recovery.\nJan 21, 05:26 UTC\nUpdate - We have mitigated the issues impacting Actions Larger Runners. We are still experiencing delays starting normal jobs, and are continuing to investigate.\nJan 21, 04:53 UTC\nUpdate - The team has identified the cause of the issues with Actions Larger Runners and has begun mitigation.\nJan 21, 04:16 UTC\nUpdate - The team continues to investigate issues with some Actions jobs being queued for a long time and a percentage of jobs failing. We will continue providing updates on the progress towards mitigation.\nJan 21, 03:45 UTC\nInvestigating - We are investigating reports of degraded performance for Actions",
          "link": "https://www.githubstatus.com/incidents/hmvr5kpgzc45",
          "publishedOn": "2024-01-21T06:19:52.000Z",
          "wordCount": 5552,
          "title": "Incident with Actions",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        }
      ]
    },
    {
      "title": "Slack System Status",
      "feedUrl": "https://status.slack.com/feed/rss",
      "siteUrl": "https://status.slack.com/",
      "articles": [
        {
          "id": "https://status.slack.com//2024-02/804d3a52e234f2fa",
          "author": null,
          "description": "Issue summary:\n\r\nOn February 12, 2024 from 6:00 AM PST to 8:32 AM PST, some users experienced latency when loading canvases or errors related to editing and saving canvases.\n\r\n\r\nUpon investigation we determined that this was caused by rate limits put in place by an upstream provider. We restarted the impacted endpoints to mitigate the issue immediately, which resolved the issue for all affected users. We're continuing to partner with our upstream provider to reduce the likelihood of this occurring in the future.",
          "link": "https://status.slack.com//2024-02/804d3a52e234f2fa",
          "publishedOn": "2024-02-13T22:15:24.000Z",
          "wordCount": 176,
          "title": "Incident: Some users may be experiencing trouble with canvas.",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2024-02/16aecfd53af7219b",
          "author": null,
          "description": "The issue some users experienced with profile pictures not displaying properly has been fixed. If you're still encountering the issue, a hard refresh of your Slack client (Cmd/Ctrl + Shift + R) is recommended. For mobile users, you may need to clear your Slack app cache.\n\r\n\r\nWe appreciate your patience while we sorted this out and apologize for the inconvenience. We'll follow up with a summary of the issue once it's available to share.",
          "link": "https://status.slack.com//2024-02/16aecfd53af7219b",
          "publishedOn": "2024-02-12T16:47:00.000Z",
          "wordCount": 267,
          "title": "Incident: Profile photos aren't displaying properly",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2024-02/558e3bb8ce654659",
          "author": null,
          "description": "Issue summary:\n\r\nOn February 7, 2024 from around 9:23 AM PST to 9:51 AM PST, a small percentage of users may have experienced issues connecting to Slack or searching within Slack. \n\r\n\r\nOur automated alerting systems detected an unusual spike in traffic to one of our servers. We carried out a thorough investigation, but the load subsided naturally as we worked, resolving the issue for all affected users.\n\r\n\r\nWhile we did not take any remedial action in this case, we continued our investigation to better understand the problem and potential mitigation strategies for similar issues in future.",
          "link": "https://status.slack.com//2024-02/558e3bb8ce654659",
          "publishedOn": "2024-02-08T02:06:20.000Z",
          "wordCount": 245,
          "title": "Incident: Some users may be having trouble connecting to Slack.",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2024-02/30dfe547672802a4",
          "author": null,
          "description": "Issue Summary:\n\r\n\r\nOn February 1, 2024 between 12:57 AM PST and 3:52 AM PST, some users in Germany were having trouble receiving two-factor authentication codes via SMS.\n\r\n\r\nThis was caused by an issue with a service provider and has now been resolved.\n\r\n\r\nUsers in Germany should no longer be having trouble and may also choose to use an authentication app to receive their 2FA codes instead of SMS.\n\r\n\r\nThank you for being patient with us, we appreciate it.",
          "link": "https://status.slack.com//2024-02/30dfe547672802a4",
          "publishedOn": "2024-02-01T14:43:18.000Z",
          "wordCount": 197,
          "title": "Incident: Users in Germany having trouble receiving 2FA SMS codes",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2024-01/8e9a7cb95549d34c",
          "author": null,
          "description": "Issue Summary:\n\r\n\r\nOn January 31, 2024 between 7:43 AM PST and 8:27 AM PST, some users were unable to load threads and send messages.\n\r\n\r\nWe traced the issue to a backend failure and immediately implemented a change which fixed the issue for all affected users.\n\r\n\r\nWe apologize for any disruption to your work day and appreciate your patience while we resolved the issue.",
          "link": "https://status.slack.com//2024-01/8e9a7cb95549d34c",
          "publishedOn": "2024-01-31T18:14:04.000Z",
          "wordCount": 180,
          "title": "Incident: Users may be experiencing issues loading threads and sending mesages.",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2024-01/0a000b0ad09623a0",
          "author": null,
          "description": "Issue summary:\n\r\nFrom 11:37 AM PST to 11:48 AM PST on January 24, 2024, we experienced an unexpected amount of API calls to our servers that occurred within a short window of time. The volume of API calls resulted in some users experiencing latency loading channels and general difficulties connecting to Slack. We investigated the impact with a broad lens and began to observe signs of recovery around 12:09 PM PST.\n\r\n\r\nDuring this time, we cautiously observed our health metrics to ensure our servers were accurately recovering. As a result of our thorough monitoring, there was a delay before we could confirm the issue was fully resolved. Our teams have also put in measures to help reduce the likelihood of this occurring again in the future.",
          "link": "https://status.slack.com//2024-01/0a000b0ad09623a0",
          "publishedOn": "2024-01-30T17:58:00.000Z",
          "wordCount": 270,
          "title": "Incident: Some latency with Slack",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2024-01/8ad463b92a084387",
          "author": null,
          "description": "Issue summary: \n\r\nFrom 11:45 AM PST to around 5:20 PM PST on January 29, 2024, some customers experienced problems using keyboard shortcuts to paste text into Slack. \n\r\n\r\nA code change inadvertently introduced an issue that prevented the use of Cmd/Ctrl + V to paste text into Slack. We reverted this change, then deployed a fix to fully resolve the issue.",
          "link": "https://status.slack.com//2024-01/8ad463b92a084387",
          "publishedOn": "2024-01-30T03:44:32.000Z",
          "wordCount": 194,
          "title": "Incident: Pasting via Cmd/Ctrl + V not working",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2024-01/f39851209d6c471a",
          "author": null,
          "description": "Issue Summary:\n\r\n\r\nFrom 1:00pm PST on January 23, 2024 to 2:30pm PST on January 23, 2024, some users encountered trouble uploading, downloading, and viewing files in Slack.\n\r\n\r\nWe determined that an API call was not functioning correctly, and made a change to mitigate the issue. The upload problems were caused by a slowing down of responses due to a higher than normal volume of API calls due to the malfunction. This issue has been resolved and steps have been taken to avoid it happening in the future.",
          "link": "https://status.slack.com//2024-01/f39851209d6c471a",
          "publishedOn": "2024-01-27T00:22:52.000Z",
          "wordCount": 277,
          "title": "Incident: Some users are unable to upload, download, and view files in Slack.",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2024-01/8b623c0b5640c28f",
          "author": null,
          "description": "Issue summary:\n\r\nOn January 24, 2024 from 5:40 AM PST to around 9:00 AM PST, a small number of users experienced issues connecting to Slack and running workflows.\n\r\n\r\nA change to routing in our servers resulted in requests failing due to a lack of available resources. This change was rolled back and Slack returned to a normal state.",
          "link": "https://status.slack.com//2024-01/8b623c0b5640c28f",
          "publishedOn": "2024-01-26T14:18:08.000Z",
          "wordCount": 231,
          "title": "Incident: Service wide connection issues",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2024-01/166eb312bd134031",
          "author": null,
          "description": "Issue summary:\n\r\nFrom 12:20pm PST until 3:00pm PST on January 22, 2024, some Enterprise Grid users noticed multiple Slackbot responses being triggered unexpectedly.\n\r\n\r\nWe determined that the rollout of a fix for an older bug report pertaining to Slackbot responses not working in org-wide or multi-workspace channels, was the root cause. \n\r\n\r\nWhilst the fix for the bug was intended to improve this features behaviour, ensuring that Slackbot custom responses would work in these channel types, our wider team concluded that the fixed behaviour might not function well for organizations with potentially thousands of custom Slackbot responses.\n\r\n\r\nWe rolled back the deployment which caused this behaviour. Customers will no longer see these Slackbot custom responses being triggered unexpectedly.\n\r\n\r\nA discussion is underway about the long-term future of Slackbot custom response behaviour within large organizations.\n\r\n\r\nThank you for your patience whilst we resolved this.",
          "link": "https://status.slack.com//2024-01/166eb312bd134031",
          "publishedOn": "2024-01-23T03:06:24.000Z",
          "wordCount": 327,
          "title": "Incident: Some Enterprise Grid users may be seeing unexpected Slackbot responses",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        }
      ]
    },
    {
      "title": "Make Status - Incident History",
      "feedUrl": "https://status.make.com/history.rss",
      "siteUrl": "https://status.make.com",
      "articles": [
        {
          "id": "https://status.make.com/incidents/ldktvddm239d",
          "author": null,
          "description": "Feb  8, 17:03 CET\nResolved - This incident has been resolved.\nFeb  8, 14:41 CET\nUpdate - We are continuing to monitor for any further issues.\nFeb  8, 14:39 CET\nMonitoring - We have identified and resolved the issue associated with the recent code change. Stability has been restored to eu2.make.com since 14:20 CET. We will continue to monitor the situation for the next several hours.\nFeb  8, 14:21 CET\nInvestigating - We are currently experiencing issues with the eu2.make.com zone. Login to the webpage is unreachable, and scenario executions are affected. We are actively investigating the issue and will provide an update within the next 60 minutes.",
          "link": "https://status.make.com/incidents/ldktvddm239d",
          "publishedOn": "2024-02-08T16:03:02.000Z",
          "wordCount": 3919,
          "title": "Outage on eu2.make.com",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.make.com/incidents/wtq70l2b2g74",
          "author": null,
          "description": "Feb  8, 13:52 CET\nResolved - This incident has been resolved.\nFeb  8, 10:04 CET\nUpdate - The fix has been successfully rolled out. Webhooks and mailhooks should now be fully functional for eu1.make.com. We will continue to monitor the situation for the next few hours.\nFeb  8, 09:33 CET\nUpdate - While monitoring the issue, we observed certain problems with mailhooks and webhooks. We have identified the issue and are working on rolling out the fix. The issue pertains only to eu1.make.com, the remaining zones are functional.\nFeb  8, 01:19 CET\nMonitoring - A fix has been implemented and we are monitoring the current behavior.\nFeb  8, 00:45 CET\nInvestigating - We are currently experiencing issues with some of our services responsible for shared hooks on our clusters.\nShared hooks might currently be unresponsive. We are actively investigating the issue.",
          "link": "https://status.make.com/incidents/wtq70l2b2g74",
          "publishedOn": "2024-02-08T12:52:07.000Z",
          "wordCount": 3954,
          "title": "Unresponsive shared hooks",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    }
  ],
  "cliVersion": "1.15.1"
}