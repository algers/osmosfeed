{
  "sources": [
    {
      "title": "BookingSync.com news",
      "feedUrl": "https://changelog.bookingsync.com/rss",
      "siteUrl": "https://changelog.bookingsync.com",
      "articles": [
        {
          "id": "283940",
          "author": "Basile, Product Manager",
          "description": "Improvement\nÂ Â \nIntroducing Smilyâ€™s enhanced deposit management: seamless synchronization with booking.com\nSay goodbye to data discrepancies and hello to effortless property management!\nKey Features:\nEasier deposit handling: Our system now allows you to manage properly damage deposits directly through Smily, ensuring perfect synchronization with Booking.com.\nNo more data mismatch: Weâ€™ve revolutionized our sync logic to eliminate discrepancies between Smily and Booking.com. This means the information you see on one platform is exactly what youâ€™ll find on the other.\nEnhanced user experience: Managing your properties has never been smoother. Our updates are tailored to make your workflow more intuitive and efficient.\nRevamped collection & return methods: Say farewell to the hassle of cash deposits and wire returns. With our update, deposit collection and returns are streamlined through credit card transactions, simplifying the process for you and your guests.\nBenefits for you:\nPeace of mind: With matched data across platforms, reduce the risk of errors and enjoy a more streamlined management experience.\nTime savings: Minimize manual work, allowing you to focus on growing your business and enhancing guest experiences.\nConsistent information: Rest assured knowing that what you set in Smily is precisely reflected on Booking.com.\n-> Update your knowledge with our revised manual. Get all the latest information and tips for maximizing the benefits of this new feature at Smily's updated manual.\nYour Smily team :)",
          "link": "https://changelog.bookingsync.com/smily-s-enhanced-deposit-management-seamless-synchronization-with-booking-com-283940",
          "publishedOn": "2024-01-22T17:40:37.000Z",
          "wordCount": 456,
          "title": "Smilyâ€™s enhanced deposit management: seamless synchronization with booking.com",
          "imageUrl": null
        },
        {
          "id": "283898",
          "author": "Yannick, Customer Care Team Leader - Pro Team",
          "description": "Action required\nÂ Â \nWe have an important update regarding your email communications with your guests via the notification app.\nTo maintain uninterrupted service, some adjustments are needed on your domain provider to keep sending notifications from your own domain name.\nIn case you are confident to do the changes yourself, please follow the instructions on our manual and let us know once it is done so we can verify, otherwise please contact our Customer Support team (Yannick or Pauline) to receive proper instructions and/or schedule a video meeting and we will be happy to help you.\nNote: Please make sure you have access to your domain provider before the call.\nYour prompt attention to this matter is appreciated to prevent any disruptions. Please note that the changes need to be done before February 13 2024.\nThank you for your cooperation.",
          "link": "https://changelog.bookingsync.com/action-required-for-continued-email-communication-from-your-own-domain-283898",
          "publishedOn": "2024-01-22T13:29:03.000Z",
          "wordCount": 380,
          "title": "Action required for continued Email communication from your own domain",
          "imageUrl": null
        },
        {
          "id": "283413",
          "author": "Maud , Partnership Manager",
          "description": "New!\nÂ Â \n\n\nWe are thrilled to announce a new partnership that will revolutionise key management for vacation rental hosts and property managers like you. ðŸ”‘\n  \n\nðŸ’¡What is KeyNest Points?\nKeyNest Points is a global network of over 5,500 locations where you can securely store and exchange keys with ease. No more hassles of on-site visits or high installation costs.\nMost KeyNest Points are open 24/7, ensuring flexibility for key exchanges at your convenience. Discover your nearest Point and its opening hours on the interactive map provided.\n\n \n\n\nðŸ  KeyNest Points - Your Trusted Partners\nThese points are typically local businesses such as convenience stores, cafes, hotels, or petrol stations, conveniently situated near your properties.\nEach KeyNest Point is managed by trained staff, ensuring instant and secure key exchanges. Your peace of mind is paramount.\n\nðŸ”¤ How Does it Work?\n\nHere's a quick overview of how KeyNest Points operate:\nDrop your keys at a local KeyNest Point.\nYour keys are tagged and logged into the system for real-time tracking.\nStaff at the Point securely stores your keys.\nSend the location of the key and the code to your guests within your automated Smily messages.\nGuests or cleaners visit the Point, show their safety code, and receive the key.\nUpon return, they drop the key back at the same Point, and you are notified.\n \nðŸ‘‰ Install the Keynest app here\n \nðŸ’Œ Learn more on our dedicated manual page.\n  \nIf you have any questions, please don't hesitate to contact support@keynest.com.",
          "link": "https://changelog.bookingsync.com/new-partnership-announcement-with-keynest!-283413",
          "publishedOn": "2024-01-16T06:58:43.000Z",
          "wordCount": 474,
          "title": "ðŸ†• New partnership announcement with KeyNest!",
          "imageUrl": "https://cloud.headwayapp.co/changelogs_images/images/big/000/120/909-b0c60a35f9afa4ac910a5afc1d805a93b692e947.png"
        },
        {
          "id": "283019",
          "author": "Basile, Product Manager",
          "description": "New!\nÂ \nImprovement\nÂ Â \nWe're thrilled to share a new feature weâ€™ve just released for booking.com properties.\nWhat's New?\nThe rate rule Booking at least 'x' day ahead is now synchronised on booking.com channel;\nWhy Does This Matter?\nYou were facing the obstacle where Guests were making a booking for the same day or 'x' days (based on your settings) even though the setting to prevent that was activated;\n-> It wonâ€™t happen anymore.\nWhat's Next?\nIf you face any obstacle with this setting, reach out to us; \nWe are and will be working on more improvements to make your day-to-day easier :)\n--\nðŸ’¡ For more detailed information, simply click here;\nLet's embark on this journey together to make your vacation rental dreams a reality ðŸš€\nHave a great day,\nYour Smily team :)",
          "link": "https://changelog.bookingsync.com/new-fix-for-your-booking-com-reservations-283019",
          "publishedOn": "2024-01-10T17:36:04.000Z",
          "wordCount": 362,
          "title": "New fix for your booking.com reservations",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Security Bulletins on Tailscale",
      "feedUrl": "https://tailscale.com/security-bulletins/index.xml",
      "siteUrl": "https://tailscale.com/security-bulletins/",
      "articles": [
        {
          "id": "https://tailscale.com/security-bulletins/#ts-2024-002",
          "author": null,
          "description": "Description: We resolved an information disclosure vulnerability in the\nhello.ts.net service.\nWhat happened?\nOn January 15 2024, we became aware of a potential information disclosure\nvulnerability in the hello.ts.net service, which could show the identity of a\ndifferent Tailscale user when loaded. The hello.ts.net service receives\nidentity information and public keys of nodes tied to their IP address. On\nNovember 28 2023, we made a change to how IPs are assigned to\nTailscale nodes, making them globally non-unique. When the Tailscale service\nassigned the same IP to multiple nodes, hello.ts.net would receive identity\ninformation for one of the nodes at random. We confirmed on January 26 2024\nthat, if one of the other nodes with that IP loaded hello.ts.net, they would\nsee another user's name, email, and hostname.\nThe Tailscale Security Team immediately took hello.ts.net offline while the\nfix was in progress. The issue has been fixed and the hello.ts.net service\nwas restored on January 29 2024.\nWho was affected?\nThe incident was isolated to 10 users across 9 tailnets who could have had\ntheir information leaked to other Tailscale users. We notified the tailnet\nsecurity contacts directly in accordance with our obligations under applicable\ndata privacy laws. Due to the random nature of the vulnerability, we cannot\nconfirm that all of those users were indeed affected.\nRegular shared nodes always see unique node IPs and were not\nvulnerable in a manner similar to hello.ts.net.\nWhat was the impact?\nA small number of users had their name, email, and hostname potentially exposed\nto other Tailscale users that had nodes sharing the same IP.\nIn addition, the hello.ts.net service was offline between January 26-29\n2024. Several users reported being negatively impacted by this.\nWhat do I need to do?\nNo action is needed at this time.\nIf you have a dependency on hello.ts.net as a probing target for Tailscale\nconnectivity, consider using a different probing\nmechanism.",
          "link": "https://tailscale.com/security-bulletins/#ts-2024-002",
          "publishedOn": "2024-01-30T00:00:00.000Z",
          "wordCount": 10683,
          "title": "TS-2024-002",
          "imageUrl": "https://cdn.sanity.io/images/w77i7m8x/production/8e0455b2d9b33c6151016afdf2ea81d7623c2f04-1200x628.png"
        }
      ]
    },
    {
      "title": "Airbnb API Status - Incident History",
      "feedUrl": "https://airbnbapi.statuspage.io/history.rss",
      "siteUrl": "https://airbnbapi.statuspage.io",
      "articles": [
        {
          "id": "https://airbnbapi.statuspage.io/incidents/bs3vrsstwjvz",
          "author": null,
          "description": "Feb  7, 09:48 PST\nResolved - This incident has been resolved.\nFeb  7, 08:55 PST\nMonitoring - Our Async Request Processing system had an issue this morning, which resulted in increased delays between the time a request was enqueued and when it was processed, and may have resulted in an elevated processing failure rate. This began around 8:10 AM PST, and was resolved by 9:15 AM PST.\nWe are still actively monitoring, but are not expecting any ongoing issues at this time.",
          "link": "https://airbnbapi.statuspage.io/incidents/bs3vrsstwjvz",
          "publishedOn": "2024-02-07T17:48:58.000Z",
          "wordCount": 3891,
          "title": "Issues with Async Request Processing",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://airbnbapi.statuspage.io/incidents/dmybzf132ygz",
          "author": null,
          "description": "Feb  5, 16:00 PST\nResolved - We've identified spikes in errors across multiple endpoints that have occurred over the past day. The two distinct spikes were:\n- February 5th, 4:10 PM to 4:30 PM (PST)\n- February 6th, 6:30 AM to 7:30 AM (PST)\nThe issue is now resolved, and we don't expect any ongoing impact.",
          "link": "https://airbnbapi.statuspage.io/incidents/dmybzf132ygz",
          "publishedOn": "2024-02-06T00:00:00.000Z",
          "wordCount": 3861,
          "title": "500 Errors Across Multiple Endpoints",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    },
    {
      "title": "Twilio Status - Incident History",
      "feedUrl": "https://status.twilio.com/history.rss",
      "siteUrl": "https://status.twilio.com",
      "articles": [
        {
          "id": "https://status.twilio.com/incidents/h0w6vjlkbp3g",
          "author": null,
          "description": "THIS IS A SCHEDULED EVENT Feb 7, 18:00 - 20:30 PST\nJan 24, 07:40 PST\nScheduled - Our Voice carrier partner in Czech Republic is conducting a planned maintenance from 07 February 2024 at 18:00 PST until 07 February 2024 at 20:30 PST. During the maintenance window, there could be call failures to and from a subset of Czech Republic phone numbers.",
          "link": "https://status.twilio.com/incidents/h0w6vjlkbp3g",
          "publishedOn": "2024-02-08T02:00:00.000Z",
          "wordCount": 7515,
          "title": "Czech Republic Voice Carrier Partner Maintenance",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/b5m2sklz48tn",
          "author": null,
          "description": "THIS IS A SCHEDULED EVENT Feb 7, 17:00 - 18:00 PST\nFeb  6, 06:06 PST\nScheduled - The Motiv network in Russia is conducting a planned maintenance from 07 February 2024 at 17:00 PST until 07 February 2024 at 18:00 PST. During the maintenance window, there could be intermittent delays delivering SMS to Motiv Russia handsets.",
          "link": "https://status.twilio.com/incidents/b5m2sklz48tn",
          "publishedOn": "2024-02-08T01:00:00.000Z",
          "wordCount": 7506,
          "title": "Russia SMS Carrier Maintenance - Motiv",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/sw0snlpssh56",
          "author": null,
          "description": "Feb  7, 10:12 PST\nResolved - 503 errors have been resolved and access to twilio.com/docs is working normally at this time.\nFeb  7, 09:34 PST\nMonitoring - Access to twilio.com/docs is now working normally. We will continue to monitor for system stability. We'll provide another update in 30 minutes or as soon as more information becomes available.\nFeb  7, 09:13 PST\nIdentified - Our engineers have identified the issue causing intermittent 503 errors when accessing twilio.com/docs and are working to deploy a fix. We expect to provide another update in 2 hours or as soon as more information becomes available.\nFeb  7, 08:56 PST\nUpdate - We are continuing to investigate intermittent 503 errors when accessing twilio.com/docs. We expect to provide another update in 2 hour or as soon as more information becomes available.\nFeb  7, 07:50 PST\nUpdate - We are investigating intermittent 503 errors when accessing twilio.com/docs. We expect to provide another update in 1 hour or as soon as more information becomes available.\nFeb  7, 07:40 PST\nInvestigating - We are investigating intermittent 503 errors when accessing twilio.com/docs. We expect to provide another update in 30 minutes or as soon as more information becomes available.",
          "link": "https://status.twilio.com/incidents/sw0snlpssh56",
          "publishedOn": "2024-02-07T18:12:09.000Z",
          "wordCount": 7659,
          "title": "Intermittent Errors When Accessing Twilio Documentation",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/ztpmrrwtgpss",
          "author": null,
          "description": "Feb  7, 08:37 PST\nResolved - Issue affecting the Analyze and Dashboard view from Flex Insights has been resolved and the service is operating normally at this time.\nFeb  7, 08:05 PST\nMonitoring - Analyze and Dashboard view from Flex Insights is now operating normally. We will continue to monitor for system stability. We'll provide another update in 30 minutes or as soon as more information becomes available.\nFeb  7, 04:00 PST\nIdentified - Our engineers have pinpointed the issue affecting the launch of Analyze and Dashboard View, and they are currently working with their vendor to fix it. We anticipate providing another update within 4 hours or as soon as additional information becomes available.\nFeb  7, 02:00 PST\nUpdate - We are investigating a service interruption with Analyze and Dashboard View on Twilio Flex. We expect to provide another update in 2 hours or as soon as more information becomes available.\nFeb  7, 01:00 PST\nInvestigating - We are seeing issues with Twilio Flex where subset of customers are Unable to launch Analyze and Dashboard View on Twilio Flex.Our engineers are working to resolve the issue. We expect to provide another update in 1 hour or as soon as more information becomes available.",
          "link": "https://status.twilio.com/incidents/ztpmrrwtgpss",
          "publishedOn": "2024-02-07T16:37:27.000Z",
          "wordCount": 7675,
          "title": "Unable to launch Analyze and Dashboard View on Twilio Flex",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/nrxh559lj8b4",
          "author": null,
          "description": "Feb  7, 07:00 PST\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nFeb  5, 03:24 PST\nScheduled - Our carrier partner XL Axiata is conducting a planned maintenance from 07 February 2024 at 07:00 PST until 07 February 2024 at 19:00 PST. During the maintenance window, there could be intermittent API request failures for XL Axiata customers.\n\nImpacted Products: Verify Silent Network Auth.",
          "link": "https://status.twilio.com/incidents/nrxh559lj8b4",
          "publishedOn": "2024-02-07T15:00:56.000Z",
          "wordCount": 7540,
          "title": "Indonesia Account Security Carrier Partner Maintenance - XL Axiata",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/rt47t7bs9cl2",
          "author": null,
          "description": "Feb  7, 04:06 PST\nResolved - We are no longer experiencing SMS delivery failures to US Proximus Mobility Network from Shortcode Sender IDs. This incident has been resolved.\nFeb  7, 02:24 PST\nMonitoring - We are observing successful SMS delivery to US Proximus Mobility Network from Shortcode Sender IDs.  We will continue to monitor to ensure full service recovery. We expect to provide another update in 2 hours or as soon as more information becomes available.\nFeb  7, 01:32 PST\nInvestigating - We are experiencing SMS delivery Failures to US Proximus Mobility Network from Shortcode Sender IDs. Our engineers are working with our carrier partner to resolve the issue. We expect to provide another update in 1 hour or as soon as more information becomes available.",
          "link": "https://status.twilio.com/incidents/rt47t7bs9cl2",
          "publishedOn": "2024-02-07T12:06:31.000Z",
          "wordCount": 7603,
          "title": "SMS Delivery Failures to US Proximus Mobility Network from Shortcode Sender IDs.",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/qmjy9clvmfjl",
          "author": null,
          "description": "Feb  6, 20:30 PST\nCompleted - The scheduled maintenance has been completed.\nFeb  6, 18:00 PST\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nFeb  6, 07:29 PST\nScheduled - The Entel network in Chile is conducting an emergency maintenance from 06 February 2024 at 18:00 PST until 06 February 2024 at 20:30 PST. During the maintenance window, there could be intermittent delays delivering SMS to and from Entel Chile handsets.",
          "link": "https://status.twilio.com/incidents/qmjy9clvmfjl",
          "publishedOn": "2024-02-07T04:30:56.000Z",
          "wordCount": 7536,
          "title": "Chile SMS Carrier Maintenance - Entel",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/0cr7rsqhjp21",
          "author": null,
          "description": "Feb  6, 20:00 PST\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nJan  4, 06:00 PST\nScheduled - Our SMS and MMS carrier partner in US, Canada and Puerto Rico is conducting a planned maintenance from 06 February 2024 at 20:00 PST until 08 February 2024 at 03:00 PST. During the maintenance window, there could be intermittent delays delivering SMS and MMS to and from US, Canada and Puerto Rico handsets via subset of Shortcodes and Longcodes.",
          "link": "https://status.twilio.com/incidents/0cr7rsqhjp21",
          "publishedOn": "2024-02-07T04:00:57.000Z",
          "wordCount": 7558,
          "title": "US, Canada and Puerto Rico Carrier Partner Maintenance",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/2s0qjvvkxpm8",
          "author": null,
          "description": "Feb  6, 16:54 PST\nResolved - We are no longer experiencing SMS delivery delays to Tigo network in Guatemala. This incident is resolved.\nFeb  6, 14:58 PST\nMonitoring - We are observing improvement with SMS delivery delays to Tigo network in Guatemala. Our engineers are continuing to monitor the situation. We will provide another update in 2 hours or as soon as more information becomes available.\nFeb  6, 00:24 PST\nUpdate - We continue to experience SMS delivery delays to Tigo network in Guatemala. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 24 hours or as soon as more information becomes available.\nFeb  5, 08:58 PST\nUpdate - We continue to experience SMS delivery delays to Tigo network in Guatemala. Our engineers are working withâ€¦",
          "link": "https://status.twilio.com/incidents/2s0qjvvkxpm8",
          "publishedOn": "2024-02-07T00:54:35.000Z",
          "wordCount": 8155,
          "title": "SMS Delivery Delays to Tigo Network in Guatemala",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    },
    {
      "title": "DigitalOcean Status - Incident History",
      "feedUrl": "https://status.digitalocean.com/history.rss",
      "siteUrl": "http://status.digitalocean.com",
      "articles": [
        {
          "id": "https://status.digitalocean.com/incidents/w1sspyd728kg",
          "author": null,
          "description": "Feb  7, 20:54 UTC\nResolved - As of 19:37 UTC, our Engineering team has confirmed the full resolution of the problem impacting the Droplet resize events in all regions. All the Droplet resize events should now be succeeding normally. \nIf you continue to experience problems, please open a ticket with our Support team. \nThank you for your patience and we apologize for the inconvenience.\nFeb  7, 19:41 UTC\nMonitoring - Our Engineering team has fully deployed the fix for the issue with Droplet resizes and is now monitoring the situation. Users can now retry Droplet resizes and should see them succeed.\nWe'll post another update once we confirm the fix resolves this incident.\nFeb  7, 15:49 UTC\nIdentified - Our Engineering team has identified the root cause of the issue with failed Droplet resizes and a fix is in the process of being deployed. \nUsers attempting to resize Droplets where the image for the Droplet has been deleted or retired (e.g. a user created a Droplet from a Snapshot, but later deleted that Snapshot) will see failures. All other resizes are succeeding normally.\nWe'll post another update once the fix has completed deployment.\nFeb  7, 15:32 UTC\nInvestigating - Our Engineering team is investigating an uptick in failed Droplet resizes, beginning Feb 6, 20:57 UTC. \nDuring this time, some users may experience failures when attempting to resize Droplets, in all regions. \nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/w1sspyd728kg",
          "publishedOn": "2024-02-07T20:54:58.000Z",
          "wordCount": 6430,
          "title": "Droplet Resize Events",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/y2cm9wm1bvv7",
          "author": null,
          "description": "Feb  7, 07:21 UTC\nResolved - Our Engineering team has confirmed the resolution of the issue impacting network latency in our NYC regions.\nThe issues were a direct result of traffic congestion from our upstream providers, which has been repaired. Users should no longer experience packet loss or increased latency while interacting with their resources in the NYC regions.\nWe sincerely apologize and thank you for your patience as we worked through this issue. In case of any questions or concerns, please open a ticket with our Support team.\nFeb  7, 04:03 UTC\nInvestigating - Our Engineering team is investigating multiple reports of network latency when connecting to services in our NYC regions. During this time, users may experience intermittent packet loss or increased latency while interacting with their resources in the NYC regions.\nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/y2cm9wm1bvv7",
          "publishedOn": "2024-02-07T07:21:30.000Z",
          "wordCount": 6332,
          "title": "Networking in NYC Regions",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/1jwy0vy3hjfb",
          "author": null,
          "description": "Feb  6, 22:21 UTC\nCompleted - The scheduled maintenance has been completed.\nFeb  6, 17:00 UTC\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nFeb  2, 20:23 UTC\nScheduled - Start Time: 17:00 UTC Feb 6, 2024\nEnd Time: 00:00 UTC Feb 7, 2024\nDuring the above time, our Engineering Team will be performing maintenance to failover some internal databases from one cluster to another.\nExtensive testing has been conducted to ensure this maintenance will be successful and result in minimal impact to DigitalOcean users. The actual failover is estimated to take less than 3 seconds.\nExisting infrastructure, including Droplets and Droplet-based services, should continue running without issue. There is no network disruption to existing services expected as part of this maintenance. However, there are dependencies on multiple services. During the failover, there may be customer impacts that should be brief and transitory. The following actions may experience increased latency or failure rates during the maintenance period:\n- API calls to the DigitalOcean public API \n- Events for Droplets and Droplet-based services such as create, delete, power on/off, resize, etc \n- Control operations through the DigitalOcean Cloud Control Panel \nMultiple teams will be engaged to keep downtime to a minimum and mitigate any impact that does occur. Weâ€™ll post updates here for any unexpected changes to this scheduled maintenance, as well as progress updates during the maintenance itself.\nIf you have any questions or concerns, please reach out to the Support team from within your account.",
          "link": "https://status.digitalocean.com/incidents/1jwy0vy3hjfb",
          "publishedOn": "2024-02-06T22:21:17.000Z",
          "wordCount": 6438,
          "title": "Core Infrastructure Maintenance",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/1q1jhbr85zvv",
          "author": null,
          "description": "Feb  5, 05:54 UTC\nResolved - Our Engineering team has confirmed the resolution of the issue impacting Spaces CDN in our SGP1 region.\nFrom 03:02 UTC - 05:15 UTC, users were experiencing errors for objects served over the CDN.\nWe apologize for the inconvenience. If you have any questions or continue to experience issues, please reach out via a Support ticket on your account.\nFeb  5, 05:10 UTC\nMonitoring - Our Engineering team has applied a fix to mitigate the issue related to the Spaces CDN in the SGP1 region. Users should no longer experience errors for objects served over the CDN. \nWe apologize for the inconvenience and will post another update once we're confident that the issue is fully resolved.\nFeb  5, 04:52 UTC\nIdentified - From 03:02 UTC, our Engineering team has identified an issue with the Spaces CDN in our SGP1 region and is actively working on a fix. During this time, users may experience errors for objects served over the CDN. \nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/1q1jhbr85zvv",
          "publishedOn": "2024-02-05T05:54:58.000Z",
          "wordCount": 6365,
          "title": "Spaces CDN in SGP1",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/swc8grzsb33n",
          "author": null,
          "description": "Jan 31, 15:26 UTC\nResolved - Our team has confirmed the full resolution for the problem with our support portal at https://cloudsupport.digitalocean.com/s/ where customers were unable to create tickets with 'Billing' ticket type. \nWe sincerely apologize and thank you for your patience as we worked through this issue. \nIn case of any questions or concerns, please open a ticket with our Support team.\nJan 31, 15:12 UTC\nMonitoring - Our Engineering team has identified the cause of the issue and implemented a fix to resolve the problem with the Support Portal. Users should now be able to create the tickets in the Support portal with Billing ticket type. \nWe are monitoring the situation now and will post an update as soon as the issue is fully resolved.\nJan 31, 14:26 UTC\nInvestigating - Our Engineering team is investigating an issue with customers being unable to create the support tickets to our support portal for Ticket type \"Billing\" at https://cloudsupport.digitalocean.com. \nAs a temporary workaround, users may still contact us via the form here: https://www.digitalocean.com/company/contact/support\nWe apologize for the inconvenience and will post an update as soon as further information is available.",
          "link": "https://status.digitalocean.com/incidents/swc8grzsb33n",
          "publishedOn": "2024-01-31T15:26:00.000Z",
          "wordCount": 6375,
          "title": "Customer Support Ticket Portal",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/39r97dl3v2l0",
          "author": null,
          "description": "Jan 30, 16:42 UTC\nResolved - Our Engineering team identified and resolved an issue impacting the Snapshots page in our Cloud Control Panel. \nFrom 13:00 - 15:00 UTC, users attempting to navigate to https://cloud.digitalocean.com/images/snapshots (via Images -> Snapshots) were unable to access the page, and instead saw an error page returned. \nWe apologize for the inconvenience. If you have any questions or continue to experience issues, please reach out via a Support ticket on your account.",
          "link": "https://status.digitalocean.com/incidents/39r97dl3v2l0",
          "publishedOn": "2024-01-30T16:42:28.000Z",
          "wordCount": 6259,
          "title": "Snapshots Page - Cloud Control Panel",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/r9w0yrbyy9ls",
          "author": null,
          "description": "Jan 29, 18:36 UTC\nResolved - Our Engineering team has confirmed the workaround fix is successful and all services should now be operating normally. We will now close this incident and work with the DNS provider separately on the root cause. \nWe appreciate your patience throughout the process and if you continue to experience problems, please open a ticket with our support team for further review.\nJan 29, 18:18 UTC\nMonitoring - Our Engineering team has identified the root cause of the issue with DNS resolution. DigitalOcean resolvers in use in FRA1, AMS3, and LON1 are unable to reach an upstream DNS provider, resulting in resolution for a subset of domain names being unavailable from our resolvers. Our Engineering team is reaching out to the provider for assistance.\nIn the meantime, our Engineering team has been able to implement a workaround fix by filtering some incorrectly announced network routes. At this time, we are seeing recovery and resolution of hostnames returning to normal in the impacted regions. We'll continue to await an update from the DNS provider. We're now monitoring the workaround fix for stability and will post an update once we are confident it is successful.\nJan 29, 17:27 UTC\nInvestigating - Our Engineering team is currently investigating issues with DNS resolution in FRA1, AMS3, and LON1. During this time, customers may experience errors trying to resolve domain names from within DigitalOcean services in those regions, including Droplets and Droplet-based services, as well as App Platform. Additionally, App Platform builds may fail or experience delays. \nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/r9w0yrbyy9ls",
          "publishedOn": "2024-01-29T18:36:45.000Z",
          "wordCount": 6473,
          "title": "DNS Resolution in FRA1, AMS3 and LON1 Regions",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/2yxmsbx1r89b",
          "author": null,
          "description": "Jan 25, 02:56 UTC\nResolved - Our Engineering team has resolved the issue with snapshots taken by customers in the NYC3 and SFO3 regions. If you continue to experience problems, please open a ticket with our support team. Thank you for your patience and we apologize for any inconvenience.\nJan 25, 01:50 UTC\nMonitoring - Our Engineering team has implemented a fix to resolve the issue with snapshots taken by customers in the NYC3 and SFO3 regions and are monitoring the situation closely. \nWe will post another update once we're confident that the issue is fully resolved.\nJan 25, 00:26 UTC\nIdentified - Our Engineering team has identified an issue with snapshots taken by customers in the NYC3 and SFO3 regions and is actively working on a fix. We will post an update as soon as additional information is available.",
          "link": "https://status.digitalocean.com/incidents/2yxmsbx1r89b",
          "publishedOn": "2024-01-25T02:56:12.000Z",
          "wordCount": 6340,
          "title": "Snapshots are failing in SFO3 and NYC3",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/s4kt15q6xq19",
          "author": null,
          "description": "Jan 23, 22:50 UTC\nResolved - Our Engineering team has completed mitigation efforts for the issue impacting Managed Kubernetes in the FRA1 region and we are marking this incident as Resolved. \nAt this time, functionality to impacted clusters has been restored but customers may need to reconfigure some Kubernetes resources. Customer Support is contacting impacted customers directly with further instructions. \nIf you have any questions or concerns regarding this incident, please open a ticket with our support team.\nJan 23, 18:44 UTC\nUpdate - Our Engineering team continues to work on mitigation efforts. An additional small bug has been discovered and remediated. About 10% of clusters have had accessibility restored and restoration efforts are ongoing. \nWe will post another update as soon as we have new developments.\nThank you for your patience and we apologize for any inconvenience.\nJan 23, 15:12 UTC\nIdentified - Our Engineering team has identified the cause of the issue with Managed Kubernetes clusters in the FRA1 region. 200 clusters are impacted by the issue and remain inaccessible to users at this time. \nOur Engineering team is engaged in remediating these clusters to restore accessibility. As soon as we are able to provide an estimated time to restore, we will provide an update.\nJan 23, 13:02 UTC\nInvestigating - As of 12:18 UTC, our Engineering team is investigating an issue with Kubernetes clusters in the FRA1 region. During this time, users may experience errors while communicating with their clusters in the FRA1 region. \nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/s4kt15q6xq19",
          "publishedOn": "2024-01-23T22:50:40.000Z",
          "wordCount": 6827,
          "title": "Managed Kubernetes Cluster in FRA1",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/9y133zrfqngf",
          "author": null,
          "description": "Jan 22, 18:38 UTC\nResolved - As of 18:37 UTC, our Engineering team has confirmed the full resolution of the issue that impacted network reachability in the LON1 region. All services and resources should now be fully reachable.\nIf you continue to experience problems, please open a ticket with our support team from within your Cloud Control Panel. \nThank you for your patience and we apologize for any inconvenience.\nJan 22, 13:32 UTC\nMonitoring - The network issues affecting our LON1 region have been mitigated. Users should no longer experience packet loss/latency, timeouts, and related issues with Droplet-based services in this region, including Droplets, LBaas, Managed Kubernetes, and Managed Database. \nWe are currently monitoring the situation closely and will share an update as soon as the issue is fully resolved.\nJan 22, 12:25 UTC\nIdentified - Our Engineering team has identified the cause of the issue impacting networking in the LON1 region and is actively working on a fix.\nDuring this time, users may still experience packet loss/latency, timeouts, and related issues with Droplet-based services in this region, including Droplets, LBaaS, Managed Kubernetes, and Managed Databases.\nWe will post an update as soon as additional information is available\nJan 22, 11:36 UTC\nInvestigating - Our Engineering team is investigating a networking issue in our LON1 region. At this time, you may experience packet loss or dropped connections.\nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/9y133zrfqngf",
          "publishedOn": "2024-01-22T18:38:44.000Z",
          "wordCount": 6426,
          "title": "Network connectivity in LON1",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/299xh1cfs8s5",
          "author": null,
          "description": "Jan 22, 10:32 UTC\nResolved - Our Engineering team has resolved the issue impacting Spaces API availability in our SFO2 region. From approximately 09:00 UTC - 10:00 UTC, users may have experienced latency or timeouts when trying to access or manage their Spaces buckets. Spaces should now be operating normally.\nIf you continue to experience problems, please open a ticket with our Support team. Thank you for your patience and we apologize for any inconvenience.\nJan 22, 10:10 UTC\nMonitoring - Our Engineering team has implemented a fix to resolve the issue impacting SFO2 Spaces API availability and monitoring the situation. We will post an update as soon as the issue is fully resolved.\nJan 22, 09:59 UTC\nIdentified - As of 09:50 UTC, our Engineering team has identified the cause of the issue impacting Spaces API availability in our SFO2 region and is actively working on a fix.\nWe will post an update as soon as additional information is available\nJan 22, 09:13 UTC\nInvestigating - As of 09:00 UTC, Our Engineering team is investigating an issue impacting Spaces API availability in our SFO2 region.\nDuring this time, users may experience slowness or timeouts when trying to access or manage their Spaces resources in SFO2.\nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/299xh1cfs8s5",
          "publishedOn": "2024-01-22T10:32:23.000Z",
          "wordCount": 6405,
          "title": "Spaces availability in SFO2",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/x0f8bvr688rs",
          "author": null,
          "description": "Jan 17, 09:34 UTC\nResolved - As of 09:17 UTC, our Engineering team has confirmed the full resolution of the issue impacting the Droplet rebuild via the Cloud Control Panel.\nWe appreciate your patience throughout the process. If you continue to experience problems, please open a ticket with our support team.\nJan 17, 09:22 UTC\nMonitoring - Our Engineering team has taken actions to mitigate the issue impacting the Droplet rebuild via Cloud Control Panel and is monitoring the situation.\nThe impact has been subsided and the users should no longer experience issues when rebuilding Droplets from the Cloud Control Panel. We apologize for the inconvenience and we will post an update once we confirm this incident is fully resolved.\nJan 17, 08:26 UTC\nIdentified - Our Engineering team has identified the cause of the issue impacting the Droplet rebuild via the Cloud Control Panel and is actively working on a fix. During this time, users may get an error response when trying to rebuild the Droplet via the Cloud Control Panel. We will post an update as soon as additional information is available.\nJan 17, 07:15 UTC\nInvestigating - As ofÂ 06:50 UTC, our Engineering team is investigating an issue impacting the Droplet rebuild via the Cloud Control Panel.\nDuring this time, users may get an error response when trying to rebuild the Droplet via the Cloud Control Panel.\nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/x0f8bvr688rs",
          "publishedOn": "2024-01-17T09:34:03.000Z",
          "wordCount": 6436,
          "title": "Droplet rebuild",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/j4jwmwl3szxz",
          "author": null,
          "description": "Jan 16, 13:34 UTC\nResolved - Our Engineering team has resolved the issue impacting multiple spaces-related functionalities. From approximately 10:30 UTC - 13:30 UTC, users may have experienced issues while trying to perform multiple actions on Spaces via the Cloud Control Panel and API. Spaces-related functionalities should now be operating normally.\nIf you continue to experience problems, please open a ticket with our Support team. Thank you for your patience and we apologize for any inconvenience.\nJan 16, 12:51 UTC\nMonitoring - Our Engineering team has taken actions to mitigate the issue affecting multiple Spaces-related functionalities and is monitoring the situation.\nThe impact has been subsided and the users should no longer experience issues with Spaces-related functionalities. \nWe apologize for the inconvenience and we will post an update once we confirm this incident is fully resolved.\nJan 16, 12:03 UTC\nIdentified - Our Engineering team has identified the issue affecting multiple Spaces-related functionalities and is actively working on a fix.\nDuring this time, users may experience issues while trying to perform multiple actions on Spaces via the Cloud Control Panel and API.\nAdditionally, this may also impact Container Registry creation and issues with transferring images between regions. \nWe apologize for the inconvenience and will share an update once we have more information.\nJan 16, 10:54 UTC\nInvestigating - As of 10:30 UTC, our Engineering team is investigating an issue with multiple Spaces functionalities via the Cloud Control Panel. \nDuring this time, users may experience errors when attempting to delete objects via the Cloud Control Panel. At this moment we are investigating the exact impact and will share more information as soon as we have it.\nWe apologize for the inconvenience.",
          "link": "https://status.digitalocean.com/incidents/j4jwmwl3szxz",
          "publishedOn": "2024-01-16T13:34:24.000Z",
          "wordCount": 6481,
          "title": "Spaces Functionality",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/47dqh6pzqybt",
          "author": null,
          "description": "Jan 16, 09:30 UTC\nResolved - As of 08:50 UTC, our Engineering team has confirmed the full resolution of the issue impacting the ability to access and manage Functions through the Cloud Control Panel.\nWe appreciate your patience throughout the process. If you continue to experience problems, please open a ticket with our support team.\nJan 16, 08:59 UTC\nMonitoring - Our Engineering team has been able to mitigate the issue related to the access and operations with Functions through the Cloud Control Panel.\nUsers should no longer face any problems in accessing or operating Functions using the Cloud Control Panel. \nWe apologize for the inconvenience. We are monitoring the situation and will post an update once we confirm this incident is fully resolved.\nJan 16, 08:17 UTC\nInvestigating - As of 03:00 AM UTC, our Engineering team is investigating an issue impacting Functions. \nDuring this time, users may experience issues with accessing Functions via the Cloud Control Panel. At this time, API operations shouldn't be impacted and should continue to function as intended. \nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/47dqh6pzqybt",
          "publishedOn": "2024-01-16T09:30:15.000Z",
          "wordCount": 6372,
          "title": "Functions",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/33vqf05m8396",
          "author": null,
          "description": "Jan 11, 00:18 UTC\nResolved - Our Engineering team has confirmed full resolution of this incident. \nFrom approximately 20:15 - 21:45 UTC, DigitalOcean experienced a global networking issue that impacted multiple services and products. Users saw increased error rates and latency for event processing, accessing our Cloud Control Panel/API, applying Cloud Firewall policies, accessing www.digitalocean.com and our Community site, and DNS resolution. Additionally, users saw timeouts/increased latency for networking requests to Droplets and Droplet-based services, as well as connections to existing App Platform Apps. \nWe sincerely apologize for the disruption. If you continue to experience issues or have questions, please reach out to our Support team by opening a ticket from within your account. â€¦",
          "link": "https://status.digitalocean.com/incidents/33vqf05m8396",
          "publishedOn": "2024-01-11T00:18:25.000Z",
          "wordCount": 6746,
          "title": "Global Networking",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/8fm83lgfsdhm",
          "author": null,
          "description": "Jan  9, 12:55 UTC\nResolved - As of 12:30  UTC, our Engineering team has resolved the issue impacting CRUD (create, read, update, delete) operations for Managed Database Clusters in all the regions.\nEverything should now be functioning normally. We appreciate your patience throughout the process.\nIf you continue to experience problems, please open a ticket with our support team.\nJan  9, 10:17 UTC\nMonitoring - Our Engineering team has confirmed that the action taken to mitigate the recurrence of the issue is successful. Users should no longer experience errors in CRUD (create, read, update, delete) operations for Managed Database Clusters in all regions, via both the Cloud Control Panel and API requests.\nWe are actively monitoring the situation to ensure stability and will provide an update â€¦",
          "link": "https://status.digitalocean.com/incidents/8fm83lgfsdhm",
          "publishedOn": "2024-01-09T12:55:23.000Z",
          "wordCount": 6555,
          "title": "Managed Database Operations",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    },
    {
      "title": "Notion Status - Incident History",
      "feedUrl": "https://status.notion.so/history.rss",
      "siteUrl": "https://status.notion.so",
      "articles": [
        {
          "id": "https://status.notion.so/incidents/2wtslqc6bv54",
          "author": null,
          "description": "Feb  6, 09:58 PST\nResolved - This incident has been resolved.\nFeb  6, 09:16 PST\nUpdate - We are working hard to resolve the issue for you. Thank you for your continuous patience.\nFeb  6, 07:00 PST\nUpdate - We are still working on fixing the issue and appreciate your patience.\nFeb  6, 05:05 PST\nIdentified - We are experiencing an issue with the Notion's database automations service that cause automation actions to fail or experience delays. Our engineers have identified this & are working on a fix.",
          "link": "https://status.notion.so/incidents/2wtslqc6bv54",
          "publishedOn": "2024-02-06T17:58:31.000Z",
          "wordCount": 3395,
          "title": "Database Automations failing",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/f88y9tn65kl1",
          "author": null,
          "description": "Feb  5, 16:32 PST\nResolved - This incident has been resolved.\nFeb  5, 16:03 PST\nUpdate - We are continuing to investigate this issue.\nFeb  5, 16:02 PST\nInvestigating - We are currently investigating this issue.",
          "link": "https://status.notion.so/incidents/f88y9tn65kl1",
          "publishedOn": "2024-02-06T00:32:44.000Z",
          "wordCount": 3396,
          "title": "A number of South Korean users inadvertently banned from using vital APIs in Notion, potentially affecting some functionalities within the app.",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/w7ppqptykrdz",
          "author": null,
          "description": "Feb  5, 06:56 PST\nResolved - Between 3:00 UTC - 14:22 UTC, some users may have experienced database automation failures or delays in actions being triggered.\nThis is now resolved, and the affected automations have completed. Database automation services are now running as normal. \nThank you for your patience while we worked through this issue.\nFeb  5, 05:30 PST\nMonitoring - Notion's database automation service began experiencing problems at approximately 3 AM UTC today, which caused a number of automation actions to fail or experience delays. \nOur engineers have identified a fix, and are now retrying automations that failed to trigger during this period. \nWe will continue to monitor the situation and share an update when this is fully resolved.",
          "link": "https://status.notion.so/incidents/w7ppqptykrdz",
          "publishedOn": "2024-02-05T14:56:59.000Z",
          "wordCount": 3422,
          "title": "Database Automation Failures",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/q9j3jvg634lx",
          "author": null,
          "description": "Feb  2, 14:45 PST\nResolved - As of 2:44 PM PT, this incident has been resolved.\nFeb  2, 11:52 PST\nMonitoring - As of 11:44 AM PT, a fix has been implemented and we are monitoring the results.\nFeb  2, 11:42 PST\nUpdate - We are continuing to investigate this issue.\nFeb  2, 11:42 PST\nUpdate - Users cannot join and create a workspace from their sidebar. In addition, users may experience increased latency across search, viewing and editing content, and syncing content.\nWe are actively investigating these issues and will follow up here with an update.\nFeb  2, 11:36 PST\nInvestigating - Currently, the \"Join or create a workspace\" button from the workspace sidebar is broken.\nWe are actively investigating the issue and will follow up here with an update.",
          "link": "https://status.notion.so/incidents/q9j3jvg634lx",
          "publishedOn": "2024-02-02T22:45:22.000Z",
          "wordCount": 3457,
          "title": "Joining or creating a workspace from sidebar is broken",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/t93zz4ynglj2",
          "author": null,
          "description": "Jan 31, 15:01 PST\nResolved - This incident has been resolved.\nJan 31, 15:00 PST\nUpdate - We are continuing to work on a fix for this issue.\nJan 31, 13:41 PST\nIdentified - We identified the root cause and are preparing a hotfix.\nJan 31, 11:05 PST\nUpdate - We are continuing to investigate this issue.\nJan 31, 11:05 PST\nInvestigating - As of 12:35 AM PT the /search endpoint (https://api.notion.com/v1/search) has been down. \nWe are currently investigating the issue and will share an update once the issue has been identified.",
          "link": "https://status.notion.so/incidents/t93zz4ynglj2",
          "publishedOn": "2024-01-31T23:01:16.000Z",
          "wordCount": 3408,
          "title": "Search API endpoint is down",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/wn8zmpphxwr9",
          "author": null,
          "description": "Jan 15, 11:19 PST\nResolved - We've pushed a fix for this issue now and users can move pages in bulk again without errors. We apologize for the earlier disruption and thank you for bearing with us through this. \nPlease open Notion and press Cmd/Ctrl + Shift + R to reload the latest changes before trying to move pages again.\nJan 15, 10:24 PST\nIdentified - Our team has identified the cause of problems when moving pages in bulk across Notion databases and is working on a fix. We will share further updates as soon as the problem is resolved.\nJan 15, 07:53 PST\nInvestigating - Users may be experiencing degraded behavior when moving pages in bulk across Notion databases. We are investigating this issue and will share an update as soon as possible.",
          "link": "https://status.notion.so/incidents/wn8zmpphxwr9",
          "publishedOn": "2024-01-15T19:19:20.000Z",
          "wordCount": 3452,
          "title": "Degraded behavior when moving pages in bulk",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/qbkb93dwrm9r",
          "author": null,
          "description": "Jan 11, 22:56 PST\nResolved - This incident has been resolved.\nJan 11, 20:52 PST\nIdentified - We are experiencing issues with MFA  login method. The team has identified the cause and is working on the fix.",
          "link": "https://status.notion.so/incidents/qbkb93dwrm9r",
          "publishedOn": "2024-01-12T06:56:42.000Z",
          "wordCount": 3344,
          "title": "Issue with MFA Login",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    },
    {
      "title": "Rippling Status - Incident History",
      "feedUrl": "https://status.rippling.com/history.rss",
      "siteUrl": "https://status.rippling.com",
      "articles": []
    },
    {
      "title": "Google Workspace Status Dashboard Updates",
      "feedUrl": "https://www.google.com/appsstatus/dashboard/en/feed.atom",
      "siteUrl": "https://www.google.com/appsstatus/dashboard/",
      "articles": []
    },
    {
      "title": "GitHub Status - Incident History",
      "feedUrl": "https://www.githubstatus.com/history.rss",
      "siteUrl": "https://www.githubstatus.com",
      "articles": [
        {
          "id": "https://www.githubstatus.com/incidents/3k40h28fkb2r",
          "author": null,
          "description": "Feb  5, 09:53 UTC\nResolved - On 2024-02-05, from 09:26 to 13:20 UTC some GitHub customers experienced errors when trying to download raw files. An overloaded server exposed a bug, causing us to return HTTP 500 error codes.\nThe issue was mitigated by disabling the server and re-routing traffic. We are implementing improvements to our routing logic to more quickly avoid troublesome hosts in the future. \n\nFeb  5, 09:40 UTC\nInvestigating - We are investigating reports of degraded performance for Git Operations",
          "link": "https://www.githubstatus.com/incidents/3k40h28fkb2r",
          "publishedOn": "2024-02-05T09:53:13.000Z",
          "wordCount": 5329,
          "title": "Incident with Git Operations",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/7k5wl5j4f1t4",
          "author": null,
          "description": "Feb  1, 04:41 UTC\nResolved - An update to our design system caused issues loading dynamic content in the global side navigation menu and in other page-specific sidebar navigation elements. Impacted users saw continuous loading spinners in place of dynamic menu content. User impact lasted from 0:55 UTC to 4:41 UTC on February 1st.\nWe are working on a number of improvements in response to this incident. We are adding request volume monitors to sidebar navigation endpoints and making changes to our front end escalation paths to improve our time to detect and time to recovery for incidents of this nature. We have also begun work to improve both automated and manual testing for these types of changes in order to prevent recurrence.\nFeb  1, 04:41 UTC\nUpdate - This issue has been resolved. A reload of your browser window/tab may be required if you continue to experience issues with the collapsable navigation sidebars not loading.\nFeb  1, 04:21 UTC\nUpdate - We are in the process of deploying a remediation, and expect to see restoration of impacted functionality within the next hour.\nFeb  1, 03:55 UTC\nUpdate - We have identified an issue that is preventing some navigation components from loading while browsing GitHub.com, and are testing a remediation prior to deployment.\nFeb  1, 03:14 UTC\nUpdate - We are currently investigating reports of some components of the GitHub.com website not loading for some users.\nFeb  1, 03:13 UTC\nInvestigating - We are currently investigating this issue.",
          "link": "https://www.githubstatus.com/incidents/7k5wl5j4f1t4",
          "publishedOn": "2024-02-01T04:41:36.000Z",
          "wordCount": 5507,
          "title": "We are investigating reports of degraded performance.",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/5y8b8lsqbbyq",
          "author": null,
          "description": "Jan 31, 14:57 UTC\nResolved - This incident was the result of an infrastructure change that was made to our load balancers to prepare us for IPv6 enablement of GitHub.com. This change was deployed to a subset of our global edge sites.\nThe change had the unintended consequence of causing IPv4 addresses to start being passed as an IPv4-mapped IPv6-compatible address to our IP Allow List functionality.\nFor example 10.1.2.3 became ::ffff:10.1.2.3. While our IP Allow List functionality was developed with IPv6 in mind, it wasn't developed to handle these mapped addresses, and hence started blocking requests as it deemed these to be not in the defined list of allowed addresses. Request error rates peaked at 0.23% of all requests.\nWe have so far identified three remediation items here:\n- Update the IP Allow List functionality to handle IPv4-mapped addresses.\n- Audit the rest of our stack to confirm there are no further places this IPv4-mapped IPv6 addresses flaw exists.\n- Improve our testing and monitoring processes to better catch these issues in the future.\nJan 31, 14:56 UTC\nUpdate - We have resolved the issue and confirmed all regions are now operating as expected.\nJan 31, 14:49 UTC\nUpdate - The fix for ip allow lists is currently rolling out; and we are awaiting confirmation from specific geographic regions.\nJan 31, 14:33 UTC\nUpdate - We are rolling out a fix to resolve the issues with IP allow lists. This should be resolved shortly.\nJan 31, 14:14 UTC\nUpdate - Some customers are experiencing issues with IP allow lists.\nJan 31, 14:14 UTC\nInvestigating - We are currently investigating this issue.",
          "link": "https://www.githubstatus.com/incidents/5y8b8lsqbbyq",
          "publishedOn": "2024-01-31T14:57:16.000Z",
          "wordCount": 5526,
          "title": "We are investigating reports of degraded performance.",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/g6drnqm54qd4",
          "author": null,
          "description": "Jan 28, 14:42 UTC\nResolved - On January 28, 2024, between 01:00 UTC and 14:00 UTC the Avatars service was degraded and could not return all avatar images requested by users, instead it would return a default, fallback avatar image. This incident impacted, at peak time 6% of the requests for viewing Avatars. Requests that were impacted did not prevent the users from continuing to use any GitHub services. This was due to an issue with the Avatars service connecting to a database host.\n We mitigated the incident by restarting the malfunctioning hosts that were not able to return the user avatar images.\n We are working to improve alerting and monitoring of our services to reduce our time to detection and mitigation.\nJan 28, 14:27 UTC\nUpdate - We have mitigated all customer impact. We are no longer serving fallback avatar icons when loading web pages for some customers. We continue to monitor the results.\nJan 28, 13:57 UTC\nUpdate - A fix has been implemented for customers seeing the default avatar (octocat) when loading web pages and we are monitoring the results.\nJan 28, 13:20 UTC\nUpdate - Some requests for getting the Avatars are returning the fallback response instead of the asked avatar since they are having issues connecting to the Mysql host\nJan 28, 13:20 UTC\nInvestigating - We are currently investigating this issue.",
          "link": "https://www.githubstatus.com/incidents/g6drnqm54qd4",
          "publishedOn": "2024-01-28T14:42:55.000Z",
          "wordCount": 5485,
          "title": "We are investigating reports of degraded performance.",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/bsk6hmj0d7nv",
          "author": null,
          "description": "Jan 23, 18:53 UTC\nResolved - On January 23, 2024 at 14:36 UTC, our internal metrics began showing an increase in exceptions originating from our live update service. Live updates to Issues, PRs, Actions, and Projects were failing, but refreshing the page successfully updated page content. We resolved the issue by rolling back a problematic dependency update and reenabled live updates at 18:53 UTC. \nWe are working to improve alerting and monitoring of our live update service to reduce our time to detection and mitigation.\nJan 23, 18:53 UTC\nUpdate - Live updates have been restored and the system is operating normally.\nJan 23, 18:14 UTC\nUpdate - We have identified and are beginning to roll out a potential fix for issues with live updates to our Web UI that power automatic page updates such asâ€¦",
          "link": "https://www.githubstatus.com/incidents/bsk6hmj0d7nv",
          "publishedOn": "2024-01-23T18:53:29.000Z",
          "wordCount": 5695,
          "title": "We are investigating reports of degraded performance.",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/7ck5966p1073",
          "author": null,
          "description": "Jan 21, 09:34 UTC\nResolved - On 2024-01-21 at 3:38 UTC, we experienced an incident that affected customers using Codespaces. Customers encountered issues creating and resuming Codespaces in multiple regions due to operational issues with compute and storage resources.\nAround 25% of customers were impacted, primarily in East US and West Europe. We re-routed traffic for Codespace creations to less impacted regions, but existing Codespaces in these regions may have been unable to resume during the incident.\nBy 7:30 UTC, we had recovered connectivity to all regions except West Europe, which had an extended recovery time due to increased load in that particular region. The incident was resolved on 2024-01-21 at 9:34 UTC once Codespace creations and resumes were working normally in all regions.\nâ€¦",
          "link": "https://www.githubstatus.com/incidents/7ck5966p1073",
          "publishedOn": "2024-01-21T09:34:34.000Z",
          "wordCount": 5691,
          "title": "Incident with Codespaces",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/hmvr5kpgzc45",
          "author": null,
          "description": "Jan 21, 06:19 UTC\nResolved - On 2024-01-21 from 02:05 UTC to 06:19 UTC, GitHub Hosted Runners experienced increased error rates from our main cloud service provider. The errors were initially limited to a single region and we were able to route around the issue by transparently failing over to other regions. However, errors gradually expanded across all regions we deploy to and led to our available compute capacity being exhausted.\nDuring the incident, up to 35% of Actions jobs using Larger Runners and 2% of Actions jobs using GitHub Hosted Runners overall may have experienced intermittent delays in starting. Once the issue was resolved by our cloud service provider, our systems made a full recovery without intervention.\nWeâ€™re working closely with our service provider to understand the cause of the outage and mitigations we can put in place. Weâ€™re also working to increase our resilience to outages of this nature by expanding the regions we deploy to beyond the existing set, especially for Larger Runners.\nJan 21, 05:54 UTC\nUpdate - We've applied a mitigation to fix the issues with queuing and running Actions jobs. We are seeing improvements in telemetry and are monitoring for full recovery.\nJan 21, 05:26 UTC\nUpdate - We have mitigated the issues impacting Actions Larger Runners. We are still experiencing delays starting normal jobs, and are continuing to investigate.\nJan 21, 04:53 UTC\nUpdate - The team has identified the cause of the issues with Actions Larger Runners and has begun mitigation.\nJan 21, 04:16 UTC\nUpdate - The team continues to investigate issues with some Actions jobs being queued for a long time and a percentage of jobs failing. We will continue providing updates on the progress towards mitigation.\nJan 21, 03:45 UTC\nInvestigating - We are investigating reports of degraded performance for Actions",
          "link": "https://www.githubstatus.com/incidents/hmvr5kpgzc45",
          "publishedOn": "2024-01-21T06:19:52.000Z",
          "wordCount": 5552,
          "title": "Incident with Actions",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/pxg3dz4yg7lp",
          "author": null,
          "description": "Jan  9, 14:40 UTC\nResolved - On January 9 between 12:45 and 13:56 UTC, services in one of our three sites experienced elevated latency for connections.  This led to a sustained period of timed out requests across a number of services, including but not limited to our git backend.  An average of 5% and max of 10% of requests failed with a 5xx response or timed out during this period.  This was caused by a combination of events that led to connection limits being hit in load balancer proxies in that site.  An upgrade of hosts was in flight, which meant a subset of proxy hosts were draining and coming offline as the upgrade rolled through the fleet.  A config change event also triggered a connection reset across all services in that site.  These events are commonplace, but led to a spike in câ€¦",
          "link": "https://www.githubstatus.com/incidents/pxg3dz4yg7lp",
          "publishedOn": "2024-01-09T14:40:45.000Z",
          "wordCount": 5941,
          "title": "Incident with Issues, API Requests, Pull Requests, Actions, Pages, Git Operations, Webhooks, Packages and Codespaces",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        }
      ]
    },
    {
      "title": "Slack System Status",
      "feedUrl": "https://status.slack.com/feed/rss",
      "siteUrl": "https://status.slack.com/",
      "articles": [
        {
          "id": "https://status.slack.com//2024-02/558e3bb8ce654659",
          "author": null,
          "description": "Users should no longer be experiencing any trouble connecting to Slack. We apologize for the disruption and thank you for your patience.",
          "link": "https://status.slack.com//2024-02/558e3bb8ce654659",
          "publishedOn": "2024-02-07T21:14:24.000Z",
          "wordCount": 148,
          "title": "Incident: Some users may be having trouble connecting to Slack.",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2024-02/30dfe547672802a4",
          "author": null,
          "description": "Issue Summary:\n\r\n\r\nOn February 1, 2024 between 12:57 AM PST and 3:52 AM PST, some users in Germany were having trouble receiving two-factor authentication codes via SMS.\n\r\n\r\nThis was caused by an issue with a service provider and has now been resolved.\n\r\n\r\nUsers in Germany should no longer be having trouble and may also choose to use an authentication app to receive their 2FA codes instead of SMS.\n\r\n\r\nThank you for being patient with us, we appreciate it.",
          "link": "https://status.slack.com//2024-02/30dfe547672802a4",
          "publishedOn": "2024-02-01T14:43:18.000Z",
          "wordCount": 197,
          "title": "Incident: Users in Germany having trouble receiving 2FA SMS codes",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2024-01/8e9a7cb95549d34c",
          "author": null,
          "description": "Issue Summary:\n\r\n\r\nOn January 31, 2024 between 7:43 AM PST and 8:27 AM PST, some users were unable to load threads and send messages.\n\r\n\r\nWe traced the issue to a backend failure and immediately implemented a change which fixed the issue for all affected users.\n\r\n\r\nWe apologize for any disruption to your work day and appreciate your patience while we resolved the issue.",
          "link": "https://status.slack.com//2024-01/8e9a7cb95549d34c",
          "publishedOn": "2024-01-31T18:14:04.000Z",
          "wordCount": 180,
          "title": "Incident: Users may be experiencing issues loading threads and sending mesages.",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2024-01/0a000b0ad09623a0",
          "author": null,
          "description": "Issue summary:\n\r\nFrom 11:37 AM PST to 11:48 AM PST on January 24, 2024, we experienced an unexpected amount of API calls to our servers that occurred within a short window of time. The volume of API calls resulted in some users experiencing latency loading channels and general difficulties connecting to Slack. We investigated the impact with a broad lens and began to observe signs of recovery around 12:09 PM PST.\n\r\n\r\nDuring this time, we cautiously observed our health metrics to ensure our servers were accurately recovering. As a result of our thorough monitoring, there was a delay before we could confirm the issue was fully resolved. Our teams have also put in measures to help reduce the likelihood of this occurring again in the future.",
          "link": "https://status.slack.com//2024-01/0a000b0ad09623a0",
          "publishedOn": "2024-01-30T17:58:00.000Z",
          "wordCount": 270,
          "title": "Incident: Some latency with Slack",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2024-01/8ad463b92a084387",
          "author": null,
          "description": "Issue summary: \n\r\nFrom 11:45 AM PST to around 5:20 PM PST on January 29, 2024, some customers experienced problems using keyboard shortcuts to paste text into Slack. \n\r\n\r\nA code change inadvertently introduced an issue that prevented the use of Cmd/Ctrl + V to paste text into Slack. We reverted this change, then deployed a fix to fully resolve the issue.",
          "link": "https://status.slack.com//2024-01/8ad463b92a084387",
          "publishedOn": "2024-01-30T03:44:32.000Z",
          "wordCount": 194,
          "title": "Incident: Pasting via Cmd/Ctrl + V not working",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2024-01/f39851209d6c471a",
          "author": null,
          "description": "Issue Summary:\n\r\n\r\nFrom 1:00pm PST on January 23, 2024 to 2:30pm PST on January 23, 2024, some users encountered trouble uploading, downloading, and viewing files in Slack.\n\r\n\r\nWe determined that an API call was not functioning correctly, and made a change to mitigate the issue. The upload problems were caused by a slowing down of responses due to a higher than normal volume of API calls due to the malfunction. This issue has been resolved and steps have been taken to avoid it happening in the future.",
          "link": "https://status.slack.com//2024-01/f39851209d6c471a",
          "publishedOn": "2024-01-27T00:22:52.000Z",
          "wordCount": 277,
          "title": "Incident: Some users are unable to upload, download, and view files in Slack.",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2024-01/8b623c0b5640c28f",
          "author": null,
          "description": "Issue summary:\n\r\nOn January 24, 2024 from 5:40 AM PST to around 9:00 AM PST, a small number of users experienced issues connecting to Slack and running workflows.\n\r\n\r\nA change to routing in our servers resulted in requests failing due to a lack of available resources. This change was rolled back and Slack returned to a normal state.",
          "link": "https://status.slack.com//2024-01/8b623c0b5640c28f",
          "publishedOn": "2024-01-26T14:18:08.000Z",
          "wordCount": 231,
          "title": "Incident: Service wide connection issues",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2024-01/166eb312bd134031",
          "author": null,
          "description": "Issue summary:\n\r\nFrom 12:20pm PST until 3:00pm PST on January 22, 2024, some Enterprise Grid users noticed multiple Slackbot responses being triggered unexpectedly.\n\r\n\r\nWe determined that the rollout of a fix for an older bug report pertaining to Slackbot responses not working in org-wide or multi-workspace channels, was the root cause. \n\r\n\r\nWhilst the fix for the bug was intended to improve this features behaviour, ensuring that Slackbot custom responses would work in these channel types, our wider team concluded that the fixed behaviour might not function well for organizations with potentially thousands of custom Slackbot responses.\n\r\n\r\nWe rolled back the deployment which caused this behaviour. Customers will no longer see these Slackbot custom responses being triggered unexpectedly.\n\r\n\r\nA discussion is underway about the long-term future of Slackbot custom response behaviour within large organizations.\n\r\n\r\nThank you for your patience whilst we resolved this.",
          "link": "https://status.slack.com//2024-01/166eb312bd134031",
          "publishedOn": "2024-01-23T03:06:24.000Z",
          "wordCount": 327,
          "title": "Incident: Some Enterprise Grid users may be seeing unexpected Slackbot responses",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2024-01/9301a4fb7cc577ea",
          "author": null,
          "description": "Issue summary:\n\r\nFrom 11:26 AM PST on January 12, 2024 to 10:04 AM PST on January 15, 2024, some users were unable to configure 2FA on their accounts. We were made aware of this after a spike in reports early in the morning of Monday, January 15.\n\r\n\r\nUpon investigation, this issue was traced back to a recent code change which we discovered was preventing users from being redirected back to the 2FA configuration page after entering their password during the 2FA setup process. We immediately reverted this change which fully resolved the issue.",
          "link": "https://status.slack.com//2024-01/9301a4fb7cc577ea",
          "publishedOn": "2024-01-15T23:51:07.000Z",
          "wordCount": 242,
          "title": "Incident: Some users may not be able to configure 2FA",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        }
      ]
    },
    {
      "title": "Make Status - Incident History",
      "feedUrl": "https://status.make.com/history.rss",
      "siteUrl": "https://status.make.com",
      "articles": [
        {
          "id": "https://status.make.com/incidents/wtq70l2b2g74",
          "author": null,
          "description": "Feb  8, 01:19 CET\nMonitoring - A fix has been implemented and we are monitoring the current behavior.\nFeb  8, 00:45 CET\nInvestigating - We are currently experiencing issues with some of our services responsible for shared hooks on our clusters.\nShared hooks might currently be unresponsive. We are actively investigating the issue.",
          "link": "https://status.make.com/incidents/wtq70l2b2g74",
          "publishedOn": "2024-02-08T00:19:53.000Z",
          "wordCount": 3864,
          "title": "Unresponsive shared hooks",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.make.com/incidents/h3gvmlbldj1q",
          "author": null,
          "description": "Jan 15, 16:18 CET\nResolved - We have reactivated the affected scenarios. Please note that this reactivation will not be visible in the scenario logs. Currently, the Monday app is fully operational.\nJan 15, 11:42 CET\nUpdate - A fix has been rolled and we are investigating options to re-enable affected scenarios automatically.\nJan 15, 10:27 CET\nMonitoring - A fix has been implemented and we are monitoring the results.\nJan 15, 09:47 CET\nIdentified - The issue has been identified and a fix is being implemented.",
          "link": "https://status.make.com/incidents/h3gvmlbldj1q",
          "publishedOn": "2024-01-15T15:18:40.000Z",
          "wordCount": 3892,
          "title": "Monday app not working",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    }
  ],
  "cliVersion": "1.15.1"
}