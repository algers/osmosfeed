{
  "sources": [
    {
      "title": "BookingSync.com news",
      "feedUrl": "https://changelog.bookingsync.com/rss",
      "siteUrl": "https://changelog.bookingsync.com",
      "articles": []
    },
    {
      "title": "Security Bulletins on Tailscale",
      "feedUrl": "https://tailscale.com/security-bulletins/index.xml",
      "siteUrl": "https://tailscale.com/security-bulletins/",
      "articles": [
        {
          "id": "https://tailscale.com/security-bulletins/#ts-2023-008/",
          "author": null,
          "description": "Description: Privilege escalation bugs in the Tailscale\nKubernetes operator’s API proxy allowed authenticated tailnet clients\nto send Kubernetes API requests as the operator’s service account.\nTailscale Kubernetes operator version v1.53.37 fixes the issue and\nusers of the operator who enable the API proxy functionality should\nupdate as described below.\nWhat happened?\nThe Tailscale Kubernetes operator can optionally act as an API server\nproxy\nfor the cluster’s Kubernetes API. This proxy allows authenticated\ntailnet users to use their tailnet identity in Kubernetes\nauthentication and RBAC rules. The API server proxy uses\nimpersonation\nheaders\nto translate tailnet identities to Kubernetes identities.\nThe operator prior to v1.53.37 has two bugs in the forwarding logic,\nwhich affects different …",
          "link": "https://tailscale.com/security-bulletins/#ts-2023-008/",
          "publishedOn": "2023-11-01T00:00:00.000Z",
          "wordCount": 4677,
          "title": "TS-2023-008",
          "imageUrl": "https://tailscale.com/files/images/og-image.png"
        },
        {
          "id": "https://tailscale.com/security-bulletins/#ts-2023-007/",
          "author": null,
          "description": "Description: Microsoft Defender is flagging Tailscale 1.46.1 as malware.\nThese classifications are false positives, and we are working with Microsoft to\nresolve the situation.\nAs of 2023-10-27 1:05 AM UTC, we have confirmed that Microsoft have addressed\nthe false positive, meaning Defender no longer flags Tailscale 1.46.1 as\nmalware. A rescan of tailscaled.exe 1.46.1 on VirusTotal confirms this.\nWhat happened?\nMicrosoft Defender was flagging Tailscale 1.46.1 as malware. This caused\nDefender to quarantine the binaries, meaning they could not run.\nWe submitted Tailscale 1.46.1 to Microsoft to investigate the false positive,\nwho then updated Defender to avoid flagging this release as malware at\n2023-10-27 1:05 AM UTC.\nWho is affected?\nPeople using Defender and Tailscale 1.46.1.\nWhat is the impact?\nTailscale will not run on affected machines.\nWhat do I need to do?\nTo resolve this issue on your own tailnet, you can take either or both of 2\napproaches:\nUpdate to a newer version of Tailscale. Newer versions are not affected by this problem.\nCreate an exception in Microsoft Defender. Microsoft has published instructions explaining how to do this.\nUpdate Microsoft Defender.",
          "link": "https://tailscale.com/security-bulletins/#ts-2023-007/",
          "publishedOn": "2023-10-26T00:00:00.000Z",
          "wordCount": 4677,
          "title": "TS-2023-007",
          "imageUrl": "https://tailscale.com/files/images/og-image.png"
        }
      ]
    },
    {
      "title": "Airbnb API Status - Incident History",
      "feedUrl": "https://airbnbapi.statuspage.io/history.rss",
      "siteUrl": "https://airbnbapi.statuspage.io",
      "articles": [
        {
          "id": "https://airbnbapi.statuspage.io/incidents/l9cxvbj0pq59",
          "author": null,
          "description": "Nov 16, 00:00 PST\nResolved - On Nov 16 and 17, some inquiries and pre-approvals expired prematurely, causing guests to be unable to accept them because Airbnb incorrectly showed these listings as unavailable, even though they were actually available. Additionally, Hosts were experiencing difficulties in creating new pre-approvals during this period. We apologize for the inconvenience that this issue has caused.\nThis issue started on Nov 16 around 12:00 AM PST and was resolved on Nov 17 at 9:10 AM PST, and we expect this to be fully resolved. Please contact us if you are still seeing this issue.",
          "link": "https://airbnbapi.statuspage.io/incidents/l9cxvbj0pq59",
          "publishedOn": "2023-11-16T08:00:00.000Z",
          "wordCount": 3903,
          "title": "Inquiry and Pre-Approval Issues",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://airbnbapi.statuspage.io/incidents/ztkbs9kly4mt",
          "author": null,
          "description": "Nov  9, 14:49 PST\nResolved - This incident has been resolved.\nNov  8, 10:38 PST\nIdentified - We have observed a higher number of intermittent 500 errors on the GET Resolutions API. We are actively working on resolving this issue and plan to deploy a fix tomorrow (Nov 9, 2023). Thank you for your understanding and patience as we work to rectify this situation.",
          "link": "https://airbnbapi.statuspage.io/incidents/ztkbs9kly4mt",
          "publishedOn": "2023-11-09T22:49:38.000Z",
          "wordCount": 3883,
          "title": "Intermittent 500 errors on the GET Resolutions API",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://airbnbapi.statuspage.io/incidents/875yz70rnb1p",
          "author": null,
          "description": "Oct 31, 10:00 PDT\nResolved - This incident has been resolved.\nOct 30, 18:14 PDT\nMonitoring - Today (Oct 30, 2023) between 1:00 PM and 3:00 PM PDT we encountered an incident that impacted our webhooks functionality. As a result, some reservations may have been missing webhooks during this time period. The issue has been resolved, and our team is actively monitoring the results to ensure the stability of our systems. If you have noticed any reservations missing webhooks, we recommend using the GET Reservations API to retrieve the details of those reservations. Alternatively, you can contact us with a list of affected reservations, and we will assist you in backfilling the missing information.\nWe apologize for any inconvenience this may have caused and appreciate your understanding.",
          "link": "https://airbnbapi.statuspage.io/incidents/875yz70rnb1p",
          "publishedOn": "2023-10-31T17:00:19.000Z",
          "wordCount": 3930,
          "title": "Issue Affecting Webhooks",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    },
    {
      "title": "Twilio Status - Incident History",
      "feedUrl": "https://status.twilio.com/history.rss",
      "siteUrl": "https://status.twilio.com",
      "articles": [
        {
          "id": "https://status.twilio.com/incidents/qbhk6g6vz30c",
          "author": null,
          "description": "THIS IS A SCHEDULED EVENT Nov 24, 00:00 - 02:00 PST\nNov 15, 16:26 PST\nScheduled - Our service partner is conducting a planned maintenance from 24 November 2023 at 00:00 PST until 24 November 2023 at 02:00 PST. During the maintenance window, there could be intermittent API request failures for the following destination: Canada.\nImpacted Products: Lookup Identity Match, Lookup Line Type Intelligence (Twilio API), Lookup SIM Swap, Legacy Identity MatchAndAttributes",
          "link": "https://status.twilio.com/incidents/qbhk6g6vz30c",
          "publishedOn": "2023-11-24T08:00:00.000Z",
          "wordCount": 7268,
          "title": "Canada Account Security Service Partner Maintenance",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/3d384mtdrzjr",
          "author": null,
          "description": "Nov 23, 15:18 PST\nUpdate - We are still investigating the issue with the Billing overview page. Customers may be received errors while trying to load balance in the overview page. We expect to provide another update in 4 hours or as soon as more information becomes available\nNov 23, 13:18 PST\nUpdate - We keep investigating an issue with the Billing overview page. Customers may be received errors while trying to load balance in the overview page. We expect to provide another update in 2 hours or as soon as more information becomes available\nNov 23, 12:24 PST\nInvestigating - We are investigating an issue with the Billing overview page. Customers may be receive errors while trying to load balance in the overview page. We expect to provide another update in 1 hour or as soon as more information becomes available",
          "link": "https://status.twilio.com/incidents/3d384mtdrzjr",
          "publishedOn": "2023-11-23T23:18:08.000Z",
          "wordCount": 7335,
          "title": "Billing Overview Page Balance Not Loading",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/q10r3vnmwb47",
          "author": null,
          "description": "Nov 23, 15:01 PST\nInvestigating - Due to increased traffic demand on mobile communication networks, we will expect potential congestion for US carrier networks during the Black Friday and Cyber Monday period. Customers may experience intermittent SMS and MMS delivery delays. Please refer to our Black Friday / Cyber Monday FAQ page, in the Help Center on Twilio.com, for more information.",
          "link": "https://status.twilio.com/incidents/q10r3vnmwb47",
          "publishedOn": "2023-11-23T23:01:59.000Z",
          "wordCount": 7244,
          "title": "Black Friday / Cyber Monday Alert",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/3l094yp5mf06",
          "author": null,
          "description": "Nov 23, 14:40 PST\nResolved - We are no longer experiencing MMS delivery delays when sending messages to Verizon network over a subset of Short-Codes in the US. This incident has been resolved.\nNov 23, 14:32 PST\nUpdate - We are observing recovery in MMS delivery delays when sending messages to Verizon network over a subset of Short-Codes in the US. We will continue monitoring the service to ensure a full recovery. We will provide another update in 2 hours or as soon as more information becomes available.\nNov 23, 12:31 PST\nMonitoring - We are observing recovery in MMS delivery delays when sending messages to Verizon network over a subset of Short-Codes in the US. We will continue monitoring the service to ensure a full recovery. We will provide another update in 2 hours or as soon as more information becomes available.\nNov 23, 10:44 PST\nUpdate - We continue experiencing MMS delivery delays when sending messages to Verizon network over a subset of Short-Codes in the US. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 4 hours or as soon as more information becomes available.\nNov 23, 08:43 PST\nUpdate - We are still experiencing MMS delivery delays when sending messages to Verizon network over a subset of Short-Codes in the US. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 2 hours or as soon as more information becomes available.\nNov 23, 07:41 PST\nInvestigating - We are experiencing MMS delivery delays when sending messages to Verizon network over a subset of Short-Codes in the US. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 1 hour or as soon as more information becomes available.",
          "link": "https://status.twilio.com/incidents/3l094yp5mf06",
          "publishedOn": "2023-11-23T22:40:13.000Z",
          "wordCount": 7529,
          "title": "MMS Delivery Delays to Verizon Network Over a Subset of Short-Codes in the US",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/ftv298gzjjt4",
          "author": null,
          "description": "Nov 23, 13:00 PST\nCompleted - The scheduled maintenance has been completed.\nNov 23, 12:00 PST\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nNov 21, 05:48 PST\nScheduled - The Gazprom Bank Mobile network in Russia is conducting a planned maintenance from 23 November 2023 at 12:00 PST until 23 November 2023 at 13:00 PST. During the maintenance window, there could be intermittent delays delivering SMS to Gazprom Bank Mobile Russia handsets.",
          "link": "https://status.twilio.com/incidents/ftv298gzjjt4",
          "publishedOn": "2023-11-23T21:00:23.000Z",
          "wordCount": 7272,
          "title": "Russia SMS Carrier Maintenance - GazpromBankMobile",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/cpd8z6rb26wc",
          "author": null,
          "description": "Nov 23, 13:00 PST\nCompleted - The scheduled maintenance has been completed.\nNov 23, 12:00 PST\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nNov 17, 04:38 PST\nScheduled - The Beeline network in Russia is conducting a planned maintenance from 23 November 2023 at 12:00 PST until 23 November 2023 at 13:00 PST. During the maintenance window, there could be intermittent delays delivering SMS to Beeline Russia handsets.",
          "link": "https://status.twilio.com/incidents/cpd8z6rb26wc",
          "publishedOn": "2023-11-23T21:00:17.000Z",
          "wordCount": 7268,
          "title": "Russia SMS Carrier Maintenance - Beeline",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/5mrlkgsb9bv8",
          "author": null,
          "description": "Nov 23, 11:41 PST\nUpdate - For customers who are requesting historical data about messages, that have been sent during the past 7 hours, via the Console or API, there is a small probability that the data could be delayed. The root cause has been identified and eliminated. We have started to process the queued messages and expect to provide another update in 8 hours or as soon as more information becomes available.\nNov 23, 07:50 PST\nUpdate - For customers who are requesting historical data about messages, that have been sent during the past 7 hours, via the Console or API, there is a small probability that the data could be delayed.  The root cause has been identified and eliminated. We have started to process the queued messages and expect to provide another update in 4 hours or as soon as…",
          "link": "https://status.twilio.com/incidents/5mrlkgsb9bv8",
          "publishedOn": "2023-11-23T19:41:59.000Z",
          "wordCount": 7655,
          "title": "Delays in Retrieving Some Historical Messaging Data",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/lc2mdb3b9t05",
          "author": null,
          "description": "Nov 23, 10:38 PST\nResolved - We have fully investigated the Billing Overview Page issue triggered by our automated alert, and it was determined that this is related to an active incident post. Find all details at https://status.twilio.com/incidents/w79nz44bxfh5. We’ll proceed to resolve this alert.\nNov 23, 10:17 PST\nInvestigating - Our monitoring systems have detected a potential issue the billing overview page. Our engineering team has been alerted and is actively investigating. We will update as soon as we have more information.",
          "link": "https://status.twilio.com/incidents/lc2mdb3b9t05",
          "publishedOn": "2023-11-23T18:38:51.000Z",
          "wordCount": 7260,
          "title": "Automated Alert: Billing Overview Page",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/5hhy31890z84",
          "author": null,
          "description": "Nov 23, 03:31 PST\nResolved - Twilio Messaging callbacks were degraded between 18:00 UTC and 23:00 UTC on 22nd November. During this period of time customers may have experienced failed callbacks.  This incident has now been resolved.",
          "link": "https://status.twilio.com/incidents/5hhy31890z84",
          "publishedOn": "2023-11-23T11:31:30.000Z",
          "wordCount": 7207,
          "title": "Failed Messaging Callbacks",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/8tg0crh4clm6",
          "author": null,
          "description": "Nov 23, 02:13 PST\nResolved - The authorization flow in connected-apps is operating normally at this time.\nNov 23, 01:31 PST\nMonitoring - The authorization flow in connected-apps is now operating normally. We will continue to monitor for system stability. We'll provide another update in 30 minutes or as soon as more information becomes available.\nNov 23, 00:18 PST\nIdentified - Our engineers have identified the issue with the authorization flow in connected-apps and are working to deploy a fix. We expect to provide another update in 1 hour or as soon as more information becomes available.\nNov 23, 00:05 PST\nInvestigating - Our monitoring systems have detected a potential issue with connect-apps authorize flow shadow route mapping is not working correctly. Our engineering team has been alerted and is actively investigating. We will update as soon as we have more information.",
          "link": "https://status.twilio.com/incidents/8tg0crh4clm6",
          "publishedOn": "2023-11-23T10:13:18.000Z",
          "wordCount": 7343,
          "title": "The Authorization Flow in Connected-Apps Is Not Working Correctly",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    },
    {
      "title": "DigitalOcean Status - Incident History",
      "feedUrl": "https://status.digitalocean.com/history.rss",
      "siteUrl": "http://status.digitalocean.com",
      "articles": [
        {
          "id": "https://status.digitalocean.com/incidents/wpz7gdly2p32",
          "author": null,
          "description": "Nov 15, 01:59 UTC\nResolved - Our Engineering team has confirmed the full resolution of the issue impacting DOKS across all regions. \nAfter the rollout, we are no longer reliant on that affected upstream provider for our DOKS product.\nIf you continue to experience problems, please open a ticket with our support team. We apologize for any inconvenience.\nNov 15, 00:42 UTC\nMonitoring - Our Engineering team has completed the rollout to pivot away from the affected upstream provider and we are no longer reliant on that provider for our DOKS product. \nAt this time, Users should no longer see any issues with nodes going into not ready states, creating new clusters, or scaling up additional nodes. \nWe're monitoring the fix and will post another update once we confirm this issue is fully resolved.\nNov 14, 23:24 UTC\nUpdate - Our Engineering team is currently working to pivot away from the affected upstream provider to mitigate impact from this incident. That fix is rolling out across our fleet and users should start to see conditions on affected clusters improve. \nAs soon as the fix is rolled out completely, we'll post another update.\nNov 14, 22:20 UTC\nUpdate - Our Engineering team has confirmed an issue on our upstream provider's end impacting DOKS across all regions which was initially reported for a few regions. \nDuring this time, Users will not be able to create new clusters, scale up additional nodes or may see nodes in an unready state across all regions.\nWe will share an update as soon as we have any information from our upstream provider.\nNov 14, 21:59 UTC\nIdentified - Beginning around 20:00 UTC, our Engineering team has confirmed an issue on our upstream provider's end impacting DOKS in our multiple regions. \nDuring this time, Users will not be able to create new clusters, scale up additional nodes or may see nodes in an unready state. \nWe will share an update as soon as we have any information from our upstream provider.",
          "link": "https://status.digitalocean.com/incidents/wpz7gdly2p32",
          "publishedOn": "2023-11-15T01:59:25.000Z",
          "wordCount": 6266,
          "title": "DOKS in Multiple Regions",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/hxcw6mrw1ywv",
          "author": null,
          "description": "Nov  8, 18:07 UTC\nResolved - Our Engineering team has seen no recurrences and performance has remained stable since 16:40 UTC. This incident is fully resolved.\nIf you continue to experience problems, please open a ticket with our support team. Thank you for your patience!\nNov  8, 17:23 UTC\nUpdate - Our Engineering team identified a configuration that was responsible for the recurrence we saw. From 16:20 - 16:40 UTC, connectivity between SFO2 and the rest of DigitalOcean's network was impacted.\nAs of 16:40 UTC, all impact has subsided and users should no longer face any issues.\nWe are monitoring the situation closely and will share an update once the issue is completely resolved.\nNov  8, 16:32 UTC\nUpdate - Our Engineering team is seeing a recurrence of network alerts that indicate we're exp…",
          "link": "https://status.digitalocean.com/incidents/hxcw6mrw1ywv",
          "publishedOn": "2023-11-08T18:07:20.000Z",
          "wordCount": 6263,
          "title": "Networking Connectivity Between NYC and SFO",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/bw3r3j9b5ph5",
          "author": null,
          "description": "Nov  4, 08:18 UTC\nResolved - Our Engineering team has confirmed the full resolution of the issue impacting App Platform Deployments. \nFrom 11:54 on Nov 2nd to 06:42 on Nov 4th UTC, App Platform users may have experienced delays when deploying new apps or when deploying updates to existing Apps. Our Upstream provider and the Engineering team closely worked together to resolve the issue. \nThe impact has been completely subsided and users should no longer see any issues with the impacted services.\nIf you continue to experience problems, please open a ticket with our support team from your Cloud Control Panel. Thank you for your patience and we apologize for any inconvenience.\nNov  4, 06:53 UTC\nUpdate - As per the recent update from our Upstream provider, they fully recovered the services used…",
          "link": "https://status.digitalocean.com/incidents/bw3r3j9b5ph5",
          "publishedOn": "2023-11-04T08:18:05.000Z",
          "wordCount": 6442,
          "title": "App Platform Deployments",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/nz33vs0sjhqy",
          "author": null,
          "description": "Nov  3, 23:14 UTC\nResolved - Our Engineering team has confirmed the full resolution of issue impacting network connectivity in our SFO regions. \nUsers should no longer experience any latency or timeout issue with any of the Droplet based services. \nIf you continue to experience problems, please open a ticket with our support team. We apologize for any inconvenience.\nNov  3, 20:58 UTC\nMonitoring - As of 19:55 UTC, our Engineering team has confirmed that a fix has been implemented by our upstream carrier to mitigate the cause of the issue impacting network connectivity in our SFO region. \nWe are closely monitoring the situation and will update as soon as we have more information from the provider.\nNov  3, 19:43 UTC\nIdentified - Our Engineering team has identified the cause of the issue impacting network connectivity in our SFO region. Upstream congestion with a network provider between Los Angeles and Dallas is impacting traffic traversing out of our SFO datacentres.\nA case has been opened by our team with the provider. Our team has attempted to shift traffic to improve the situation, but unfortunately, we continue to see approximately 10% of customer traffic impacted by this issue.\nOur team is working on an option to shift to an alternate provider if this issue is not able to be resolved by the provider in a timely manner. We will share another update once we have further information from the provider or we have an update from our Engineering team.\nNov  3, 19:27 UTC\nInvestigating - As of 17:40 UTC, our Engineering team is investigating an issue impacting networking in the SFO regions. During this time, a subset of users may experience packet loss/latency and timeouts with Droplet based services in these regions, including Droplets, Managed Kubernetes, and Managed Database. We apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/nz33vs0sjhqy",
          "publishedOn": "2023-11-03T23:14:12.000Z",
          "wordCount": 6235,
          "title": "Networking in SFO Regions",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/y3q3gh220jyj",
          "author": null,
          "description": "Nov  2, 11:50 UTC\nResolved - Our Engineering team has confirmed the full resolution of the issue impacting the Cloud Control Panel, API, and multiple services.\nFrom 05:05 - 08:40 UTC, users may have encountered errors with the Cloud Control Panel and public API while attempting to create new user registrations, or while making payments. Users also may have experienced issues with processing Droplet and Managed Kubernetes cluster creations along with Droplet-based events and experienced latencies while accessing our Cloud Control Panel along with the DigitalOcean Container Registry. Our Upstream provider and the Engineering team closely worked together to resolve the issues. \nThe impact has been completely subsided and users should no longer see any issues with the impacted services.\nIf you…",
          "link": "https://status.digitalocean.com/incidents/y3q3gh220jyj",
          "publishedOn": "2023-11-02T11:50:30.000Z",
          "wordCount": 6571,
          "title": "Multiple services down and API availability",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/nwm1sn0gjfc3",
          "author": null,
          "description": "Oct 27, 14:47 UTC\nResolved - As of 14:30 UTC, our Engineering team has resolved the issue impacting Spaces in our SGP1 and SFO3 regions. Users should no longer experience slowness or timeouts when trying to create or access their Spaces resources in the SGP1 and SFO3 regions. \nIf you continue to experience problems, please open a ticket with our support team. We apologize for any inconvenience.\nOct 27, 14:03 UTC\nMonitoring - Our Engineering team has implemented a fix to resolve the issue impacting Spaces in our SGP1 and SFO3 regions and is monitoring the situation closely. We will post an update as soon as the issue is fully resolved.\nOct 27, 12:04 UTC\nUpdate - Our Engineering team is continuing to investigate an issue impacting Object Storage in our SGP1 region. Additionally, we have become aware that this issue has also impacted Object Storage in the SFO3 region. During this time, users may encounter difficulties accessing Spaces, creating new buckets, and uploading files to and from Spaces buckets. Our Engineers are actively working on isolating the root cause of the issue. While we don't have an exact timeframe for a resolution yet however we will be providing updates as developments occur.\nWe apologize for the inconvenience and thank you for your patience and continued support.\nOct 27, 11:25 UTC\nInvestigating - As of 10:22 UTC, our Engineering team is investigating an issue with Object Storage in our SGP1 region. During this time, users may encounter difficulties accessing Spaces, creating new buckets, and uploading files to and from Spaces buckets. \nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/nwm1sn0gjfc3",
          "publishedOn": "2023-10-27T14:47:58.000Z",
          "wordCount": 6209,
          "title": "Object Storage - SGP1 and SFO3",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/1zckjwhpq1xy",
          "author": null,
          "description": "Oct 26, 15:52 UTC\nResolved - As of 15:45 UTC, our Engineering team has confirmed the full resolution of the issue that impacted network reachability in the LON1 region. All services and resources should now be fully reachable.\nIf you continue to experience problems, please open a ticket with our support team from within your Cloud Control Panel. \nThank you for your patience and we apologize for any inconvenience.\nOct 26, 15:18 UTC\nMonitoring - The network issues affecting our LON1 region have been mitigated. Users should no longer experience packet loss/latency, timeouts, and related issues with Droplet-based services in this region, including Droplets, Managed Kubernetes, and Managed Database. \nWe will continue to monitor network conditions for a period of time to establish a return to pre-incident conditions.\nOct 26, 14:25 UTC\nIdentified - Our Engineering team has identified the cause of the issue impacting the networking in the LON1 region and is actively working on a fix. During this time, users may still experience packet loss/latency, timeouts, and related issues with Droplet-based services in these regions, including Droplets, Managed Kubernetes, and Managed Database. \nWe will post an update as soon as additional information is available.\nOct 26, 12:50 UTC\nInvestigating - As of 11:40 UTC, our Engineering team is investigating an issue impacting the networking in the LON1 region. During this time, a subset of users may experience packet loss/latency, timeouts, and related issues with Droplet-based services in this region, including Droplets, Managed Kubernetes, and Managed Database. \nWe will share an update once we have further information.",
          "link": "https://status.digitalocean.com/incidents/1zckjwhpq1xy",
          "publishedOn": "2023-10-26T15:52:41.000Z",
          "wordCount": 6179,
          "title": "Network Connectivity in LON1",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    },
    {
      "title": "Notion Status - Incident History",
      "feedUrl": "https://status.notion.so/history.rss",
      "siteUrl": "https://status.notion.so",
      "articles": [
        {
          "id": "https://status.notion.so/incidents/69628qhdf41j",
          "author": null,
          "description": "Nov 21, 18:00 PST\nResolved - This is resolved.\nNov 21, 16:50 PST\nUpdate - Provider calls are more stable. We are monitoring our provider.\nNov 21, 16:43 PST\nMonitoring - A fix has been implemented and we are monitoring the results.\nNov 21, 16:42 PST\nIdentified - Notion AI is partially not working as one of our service providers is down",
          "link": "https://status.notion.so/incidents/69628qhdf41j",
          "publishedOn": "2023-11-22T02:00:20.000Z",
          "wordCount": 3373,
          "title": "Notion AI is down",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/tk0hmlbd3lg9",
          "author": null,
          "description": "Nov 17, 16:04 PST\nResolved - Our team has now resolved the issue preventing template duplication, and this is working as normal again. We appreciate your patience while we worked through this issue.\nNov 17, 14:05 PST\nIdentified - We are experiencing an issue with duplicating published templates and our team is actively working on a fix.",
          "link": "https://status.notion.so/incidents/tk0hmlbd3lg9",
          "publishedOn": "2023-11-18T00:04:17.000Z",
          "wordCount": 3364,
          "title": "Issue affecting template duplication",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/vvx0wz4pgd9k",
          "author": null,
          "description": "Nov 16, 19:11 PST\nResolved - The incident has been resolved. Time of resolution Nov 16 2023 6:46PM PST\nNov 16, 19:09 PST\nIdentified - Notion AI is down. We are working with them on a fix. Time - Nov 16 2023 6:11PM PST",
          "link": "https://status.notion.so/incidents/vvx0wz4pgd9k",
          "publishedOn": "2023-11-17T03:11:59.000Z",
          "wordCount": 3351,
          "title": "Notion AI is down",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/n1sp5244k09v",
          "author": null,
          "description": "Nov  8, 07:28 PST\nResolved - The incident has been resolved. Time of resolution Nov 8 2023 7:28AM PST\nNov  8, 07:28 PST\nMonitoring - Our AI provider has implemented a fix and we are seeing Notion AI recover gradually since 7:28AM PST. We are currently monitoring the situation.\nNov  8, 06:57 PST\nUpdate - The issue has been identified now and a fix is being worked on for this issue.\nNov  8, 06:29 PST\nIdentified - One of our AI providers is down. We are working with them on a fix.",
          "link": "https://status.notion.so/incidents/n1sp5244k09v",
          "publishedOn": "2023-11-08T15:28:28.000Z",
          "wordCount": 3403,
          "title": "Notion AI is down",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    },
    {
      "title": "Rippling Status - Incident History",
      "feedUrl": "https://status.rippling.com/history.rss",
      "siteUrl": "https://status.rippling.com",
      "articles": [
        {
          "id": "https://status.rippling.com/incidents/sj7thsw4jlzl",
          "author": null,
          "description": "Nov 23, 22:41 UTC\nResolved - This incident has been resolved.\nNov 23, 16:29 UTC\nMonitoring - A fix has been implemented and we are monitoring the results.\nNov 22, 18:03 UTC\nIdentified - The issue has been identified and a fix is being implemented.\nNov 22, 17:37 UTC\nInvestigating - Customers are experiencing issues with the assignment of Adobe licenses to users. We are investigating this issue.",
          "link": "https://status.rippling.com/incidents/sj7thsw4jlzl",
          "publishedOn": "2023-11-23T22:41:38.000Z",
          "wordCount": 5054,
          "title": "Issues with the Adobe integration",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/248858/rippling_favicoon.png"
        },
        {
          "id": "https://status.rippling.com/incidents/54s1f3rs3n56",
          "author": null,
          "description": "Nov 10, 23:59 UTC\nResolved - This incident has been resolved.\nNov  9, 19:56 UTC\nMonitoring - A fix has been implemented and we are monitoring the results.\nNov  9, 18:41 UTC\nUpdate - We are continuing to investigate this issue.\nNov  9, 18:39 UTC\nUpdate - We are continuing to investigate this issue.\nNov  9, 18:34 UTC\nInvestigating - We are currently investigating this issue.",
          "link": "https://status.rippling.com/incidents/54s1f3rs3n56",
          "publishedOn": "2023-11-10T23:59:07.000Z",
          "wordCount": 5044,
          "title": "Issues loading Rippling",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/248858/rippling_favicoon.png"
        },
        {
          "id": "https://status.rippling.com/incidents/w8r2ldkc0rcj",
          "author": null,
          "description": "Nov  7, 07:51 UTC\nResolved - This incident has been fully resolved.\nNov  6, 19:08 UTC\nMonitoring - The Rippling app has mostly recovered but there are still a few lags in performance that we're further monitoring and investigating.\nNov  6, 18:33 UTC\nInvestigating - We are continuing to see degraded performance in the Rippling app, so we are continuing to investigate.\nNov  6, 17:28 UTC\nMonitoring - A fix has been implemented and we are monitoring the results.\nNov  6, 17:25 UTC\nInvestigating - There are issues loading Rippling. We are working on a fix.",
          "link": "https://status.rippling.com/incidents/w8r2ldkc0rcj",
          "publishedOn": "2023-11-07T07:51:01.000Z",
          "wordCount": 5074,
          "title": "Issues loading Rippling",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/248858/rippling_favicoon.png"
        },
        {
          "id": "https://status.rippling.com/incidents/fjw9lbztvc7f",
          "author": null,
          "description": "Oct 27, 15:51 UTC\nResolved - The issue has now been resolved. All admins are able to access their Admin Account view as expected.\nOct 27, 14:50 UTC\nIdentified - We are aware of an issue where 'Admin Account' is not visible in the account dropdown for Super Admins. After they navigate to their 'Employee Account' view they can't navigate back to their admin view. \nThe root cause has been identified and the issue should be resolved in the next hour.",
          "link": "https://status.rippling.com/incidents/fjw9lbztvc7f",
          "publishedOn": "2023-10-27T15:51:44.000Z",
          "wordCount": 5077,
          "title": "Admin account not visible in the account dropdown for Super Admins",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/248858/rippling_favicoon.png"
        },
        {
          "id": "https://status.rippling.com/incidents/vnm5lc6f0b91",
          "author": null,
          "description": "Oct 25, 21:10 UTC\nResolved - This incident has been resolved.\nOct 25, 21:02 UTC\nMonitoring - A fix has been implemented and we are monitoring the results.\nOct 25, 20:52 UTC\nIdentified - An issue has been identified and we are working on a fix.\nOct 25, 20:46 UTC\nUpdate - We are continuing to monitor for any further issues.\nOct 25, 20:22 UTC\nMonitoring - A fix has been implemented and we are monitoring the results.\nOct 25, 20:17 UTC\nIdentified - The issue has been identified and a fix is being implemented.\nOct 25, 20:14 UTC\nInvestigating - We are currently investigating this issue.",
          "link": "https://status.rippling.com/incidents/vnm5lc6f0b91",
          "publishedOn": "2023-10-25T21:10:01.000Z",
          "wordCount": 5089,
          "title": "Issues loading Rippling",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/248858/rippling_favicoon.png"
        }
      ]
    },
    {
      "title": "Google Workspace Status Dashboard Updates",
      "feedUrl": "https://www.google.com/appsstatus/dashboard/en/feed.atom",
      "siteUrl": "https://www.google.com/appsstatus/dashboard/",
      "articles": [
        {
          "id": "https://www.google.com/appsstatus/dashboard/incidents/xW79o92ggzV3QyUm7rDh",
          "author": null,
          "description": "<p> Incident began at <strong>2023-11-21 06:29</strong> and ended at <strong>2023-11-21 08:14</strong> <span>(times are in <strong>Coordinated Universal Time (UTC)</strong>).</span></p><div class=\"cBIRi14aVDP__status-update-text\"><p>The issue with Google Workspace Support has been resolved for all affected users as of Tuesday, 2023-11-21 00:14 US/Pacific. We thank you for your patience while we worked on resolving the issue.</p>\n</div><hr><p>Affected products: Google Workspace Support</p>",
          "link": "https://www.google.com/appsstatus/dashboard/incidents/xW79o92ggzV3QyUm7rDh",
          "publishedOn": "2023-11-22T05:50:58.000Z",
          "wordCount": 383,
          "title": "RESOLVED: We are experiencing an issue with Google Workspace Support beginning at Monday, 2023-11-20 22:29 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2023-11-21 02:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\n**Customer Symptoms:**\nCustomers impacted by this issue would not be able to attach files in the support chat within Google Workspace Admin consoles.",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "GitHub Status - Incident History",
      "feedUrl": "https://www.githubstatus.com/history.rss",
      "siteUrl": "https://www.githubstatus.com",
      "articles": [
        {
          "id": "https://www.githubstatus.com/incidents/x39xrr5m11b3",
          "author": null,
          "description": "Nov 21, 11:27 UTC\nResolved - On November 21, 2023, at 09:50 UTC GitHub Actions jobs encountered delays due to an incident in our background job service caused by excessive rebalancing in a Kafka consumer group. After a quick mitigation, we began to see recovery on the job queues by 10:02 UTC. During this time window 100% of Actions jobs were delayed in starting for up to 11 minutes.\nUnfortunately, the rapid queue recovery sent a thundering herd of jobs to Actions hosted runner pools, causing a database deadlock that resulted in some hosted runner pools having increased latency when accepting new jobs. This affected only a small percentage of overall jobs, around 2%. Configuration changes led to a resolution and the system was fully recovered by 11:27 UTC and all in progress jobs were processed.\nThe incident is now resolved.\nNov 21, 11:12 UTC\nUpdate - We've applied a mitigation to fix the issues with queuing and running Actions jobs. We are seeing improvements in telemetry and are monitoring for full recovery.\nNov 21, 10:24 UTC\nUpdate - We have recovery for the underlying issue but are waiting for Actions queues to catch up. We expect this to be completed in less than 1 hour(s).\nNov 21, 10:11 UTC\nInvestigating - We are investigating reports of degraded performance for Actions",
          "link": "https://www.githubstatus.com/incidents/x39xrr5m11b3",
          "publishedOn": "2023-11-21T11:27:43.000Z",
          "wordCount": 5201,
          "title": "Incident with Actions",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/mnv0g944fncw",
          "author": null,
          "description": "Nov 15, 11:34 UTC\nResolved - On 2023-11-15, from 09:44 to 10:42 UTC, some GitHub customers experienced increased latency or errors accessing repo data.\nHigh concurrent access to a specific git object exposed a bug that forced a backend service to perform excessive calculations, overloading the service. Access to this repo was paused while load was re-rerouted, mitigating the problem.\nThe conditions that triggered the expensive operations have been identified and refactored.\nNov 15, 11:33 UTC\nUpdate - Error rates and performance have returned to normal.\nNov 15, 11:21 UTC\nUpdate - We have identified the source of the issue and have removed the additional load from the service. Sporadic delays in pull request experiences and intermittent 500s are still occurring and impacting a very small percentage of traffic. Next update is expected within 30 minutes.\nNov 15, 11:04 UTC\nUpdate - We are seeing connectivity issues between some of our systems and git backend services. This is causing intermittent error responses and delays in pull request experiences for a very small percentage of traffic. We are investigating mitigations and expect to provide another update within 30 minutes.\nNov 15, 09:50 UTC\nInvestigating - We are currently investigating this issue.",
          "link": "https://www.githubstatus.com/incidents/mnv0g944fncw",
          "publishedOn": "2023-11-15T11:34:14.000Z",
          "wordCount": 5190,
          "title": "We are investigating reports of degraded performance.",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/knl5pxnx0byt",
          "author": null,
          "description": "Nov 13, 21:38 UTC\nResolved - Between 20:35 and 21:38 we experienced up to a 20 minute delay delivering around 30,000 notifications due to side effects of some planned maintenance on supporting systems. We have noted the unexpected user impact of this type of maintenance and will address it in future maintenance planning.\nNov 13, 21:38 UTC\nUpdate - An issue related to notifications has been resolved. Users should again be seeing their notifications.\nNov 13, 21:15 UTC\nUpdate - We're seeing issues related to notifications.\nNov 13, 21:13 UTC\nInvestigating - We are currently investigating this issue.",
          "link": "https://www.githubstatus.com/incidents/knl5pxnx0byt",
          "publishedOn": "2023-11-13T21:38:40.000Z",
          "wordCount": 5088,
          "title": "We are investigating reports of degraded performance.",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/wyk0ns67krlz",
          "author": null,
          "description": "Nov 11, 02:14 UTC\nResolved - On November 11, 2023, at 1:00 UTC, GitHub background jobs encountered delays lasting up to 50 minutes. This delay affected various services utilizing background jobs, including Actions, Webhooks, Pull Requests, and Pages. The impact persisted for approximately one hour until 2:10 UTC.\nDuring the incident, some customers experienced delays in starting Github Actions workflow runs and Pages builds. We estimate that about 10% of Actions workflow runs were delayed during the impact window and 99% of Pages builds failed from 1:00 UTC to 1:20 UTC. Users may have experienced a delay in seeing recent pushes reflected in pull request views. This delay averaged between 5 and 10 minutes and affected up to 30% of pull request page views during the incident. 1% of pull requ…",
          "link": "https://www.githubstatus.com/incidents/wyk0ns67krlz",
          "publishedOn": "2023-11-11T02:14:08.000Z",
          "wordCount": 5354,
          "title": "Incident with Pages, Webhooks and Actions",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/m61vxgn4kvh2",
          "author": null,
          "description": "Nov  7, 14:25 UTC\nResolved - Our internal search infrastructure experienced increased latency and timeouts between 13:15 and 14:05 UTC leading to some end user timeouts and slow responses for any requests that made use of that subsystem. This included but was not limited to: user search, repository search, releases, and audit logs.\nWe mitigated the issue by migrating traffic to an older version of our search clusters and are investigating what caused the performance issues in our new clusters.\nNov  7, 14:25 UTC\nUpdate - API Requests is operating normally.\nNov  7, 14:15 UTC\nUpdate - Response times stabilized back to normal at 13:58 UTC.  We are continuing to monitor the slow dependency to ensure it's stable before resolving this incident.\nNov  7, 14:03 UTC\nUpdate - We're seeing intermittent spikes in latency of API requests and page loads.  We are investigating but do not have an ETA at this time.\nNov  7, 13:50 UTC\nUpdate - We are investigating reports of issues with service(s): Issues, API Requests. We will continue to keep users updated on progress towards mitigation.\nNov  7, 13:46 UTC\nUpdate - Issues is experiencing degraded performance. We are continuing to investigate.\nNov  7, 13:44 UTC\nInvestigating - We are investigating reports of degraded performance for API Requests",
          "link": "https://www.githubstatus.com/incidents/m61vxgn4kvh2",
          "publishedOn": "2023-11-07T14:25:40.000Z",
          "wordCount": 5211,
          "title": "Incident with API Requests and Issues",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/xb30mby9fs5x",
          "author": null,
          "description": "Nov  3, 19:21 UTC\nResolved - A performance and resilience optimization to the authorization microservice contained a memory leak that was exposed under high traffic. This resulted in a number of pages returning 404’s that should not have. Testing the build in our canary ring did not expose the service to sufficient traffic to discover the leak, allowing it to graduate to production at 6:37 PM UTC.  The memory leak under high load caused pods to crash repeatedly starting at 6:42 PM UTC, failing authorization checks. These failures triggered alerts at 6:44 PM UTC. Rolling back the authorization service change was delayed as parts of the deployment infrastructure relied on the authorization service and required manual intervention to complete. Rollback completed at 7:08 PM UTC and all impacte…",
          "link": "https://www.githubstatus.com/incidents/xb30mby9fs5x",
          "publishedOn": "2023-11-03T19:21:48.000Z",
          "wordCount": 5723,
          "title": "Incident with Git Operations, Issues, Pull Requests, Actions, API Requests, Codespaces, Packages, Pages and Webhooks",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/sbjdwn6mvht7",
          "author": null,
          "description": "Oct 25, 22:15 UTC\nResolved - Copilot completions are currently hosted in 4 regions globally: Central US, France, Switzerland and Japan. Users are typically routed to the nearest geographic region, but may be routed to other regions when the nearest region is unhealthy.\nBeginning at 2023-10-25 09:13 UTC, Copilot began experiencing outages of individual regions, lasting 12 minutes per region. These outages were due to the nodes hosting the completion model getting unhealthy due to a recent upgrade. There were intermittent outages in multiple regions with a subset of Copilot users experiencing completion errors. The outages were partial and varied across the different regions.\nIn order to prevent similar incidents from occurring in the future, we are focusing on improving our global load balancing of completion traffic during regional failures, in addition to determining and preventing the root cause of these outages.\nOct 25, 21:37 UTC\nUpdate - The observed Copilot API error rate is around 5% of the requests. As a result, some of the Copilot code suggestions are skipped or not delivered on time.\nOct 25, 21:19 UTC\nUpdate - We are seeing an impact in the US region as well. We continue the investigation.\nOct 25, 20:53 UTC\nUpdate - Copilot is experiencing intermittent issues in our Japan region. Engineers are currently investigating.\nOct 25, 20:50 UTC\nInvestigating - We are investigating reports of degraded performance for Copilot",
          "link": "https://www.githubstatus.com/incidents/sbjdwn6mvht7",
          "publishedOn": "2023-10-25T22:15:54.000Z",
          "wordCount": 5213,
          "title": "Incident with Copilot",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/p351mbywbp0t",
          "author": null,
          "description": "Oct 25, 13:02 UTC\nResolved - Copilot completions are currently hosted in 4 regions globally: Central US, France, Switzerland and Japan. Users are typically routed to the nearest geographic region, but may be routed to other regions when the nearest region is unhealthy.\nBeginning at 2023-10-25 09:13 UTC, Copilot began experiencing outages of individual regions, lasting 12 minutes per region. These outages were due to the nodes hosting the completion model getting unhealthy due to a recent upgrade. There were intermittent outages in multiple regions with a subset of Copilot users experiencing completion errors. The outages were partial and varied across the different regions.\nIn order to prevent similar incidents from occurring in the future, we are focusing on improving our global load balancing of completion traffic during regional failures, in addition to determining and preventing the root cause of these outages.\nOct 25, 12:56 UTC\nUpdate - We have applied a fix to help with Copilot performance. Initial signals show good recovery. We will continue to monitor for the time being and resolve when confident the issue has been resolved.\nOct 25, 12:29 UTC\nUpdate - We are investigating degraded performance in Europe for Copilot. We will continue to keep users updated on progress towards mitigation.\nOct 25, 12:10 UTC\nInvestigating - We are investigating reports of degraded performance for Copilot",
          "link": "https://www.githubstatus.com/incidents/p351mbywbp0t",
          "publishedOn": "2023-10-25T13:02:51.000Z",
          "wordCount": 5202,
          "title": "Incident with Copilot",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        }
      ]
    },
    {
      "title": "Slack System Status",
      "feedUrl": "https://status.slack.com/feed/rss",
      "siteUrl": "https://status.slack.com/",
      "articles": [
        {
          "id": "https://status.slack.com//2023-11/2b97ec921a81988a",
          "author": null,
          "description": "Issue Summary:\n\r\nOn November 8, 2023 from 7:55 AM PT until 8:27 PM PT, a small number of users experienced errors when attempting to join or start huddles.\n\r\n\r\nWe traced this back to an unexpected spike in a database load for which we quickly saw recovery.\n\r\n\r\nWe monitored the situation closely and in an effort to prevent further unexpected error spikes, we implemented a strategic configuration adjustment to optimize the load on our database.\n\r\n\r\nAffected users should no longer experience issues with huddles.",
          "link": "https://status.slack.com//2023-11/2b97ec921a81988a",
          "publishedOn": "2023-11-17T21:42:44.000Z",
          "wordCount": 195,
          "title": "Incident: Some users may be experiencing issues with huddles",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-11/0e7bc0e7a7e7cd87",
          "author": null,
          "description": "Issue summary:\n\r\nFrom 3:15 PM PST on November 14, 2023 to around 4:13 PM PST, a small number of customers using the Slack desktop app were unable to connect to Slack. This may have manifested as a \"Something's gone awry\" error page.\n\r\n\r\nA recent code change inadvertently introduced a logic error that prevented the desktop app from connecting as expected. We reverted this code change as an immediate mitigation step, then rolled out a fix to correct the logic error. \n\r\n\r\nThe fix resolved the issue for all affected customers, restoring full access to Slack.",
          "link": "https://status.slack.com//2023-11/0e7bc0e7a7e7cd87",
          "publishedOn": "2023-11-15T03:01:39.000Z",
          "wordCount": 264,
          "title": "Incident: Slack not loading for some users",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-11/16fed44d7948cf49",
          "author": null,
          "description": "Issue Summary:\n\r\n\r\nFrom 4:00 PM PDT on October 31, 2023 to 2:00 PM PDT on November 9, 2023, user presence would unexpectedly change to away or inactive.\n\r\n\r\nWe determined that an error during a routine system optimization on connectivity state caused this issue. \n\r\n\r\nWe reverted the change which fixed the issue for all affected customers.\n\r\n\r\nThank you for your patience while we resolved this.",
          "link": "https://status.slack.com//2023-11/16fed44d7948cf49",
          "publishedOn": "2023-11-13T15:57:36.000Z",
          "wordCount": 253,
          "title": "Incident: User presence is unexpectedly changing",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-11/ea3a2a3e32e79902",
          "author": null,
          "description": "Issue summary:\n\r\nFrom 10:00 PM PST on November 7, 2023 to 1:15 PM PST on November 8, 2023, some users experienced issues with their user status not updating, removing previews, and being unable to mark channels as read. Some keyboard shortcuts were also affected and were unable to be used.\n\r\n\r\nWe determined that a recent code change was the root cause for the unexpected behaviour with these features.\n\r\n\r\nTo restore functionality, we reverted the related code. We then did some additional testing and monitoring to confirm all issues were fully resolved and Slack was operating as expected.",
          "link": "https://status.slack.com//2023-11/ea3a2a3e32e79902",
          "publishedOn": "2023-11-09T04:29:31.000Z",
          "wordCount": 413,
          "title": "Incident: Issues with user status, read state, and file previews",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-11/ef3e4b0ebcf16d8d",
          "author": null,
          "description": "Issue summary:\n\r\nOn November 4, 2023, between 5:09 PM PDT and 5:20 PM PDT, many customers were unable send messages or to connect to Slack.\n\r\n\r\nA routine code change introduced a database error that prevented cached data from being cleared correctly, resulting in severe performance issues.\n\r\n\r\nWe rolled back the code change and refreshed all affected servers, resolving the issue for all users.",
          "link": "https://status.slack.com//2023-11/ef3e4b0ebcf16d8d",
          "publishedOn": "2023-11-08T01:59:22.000Z",
          "wordCount": 176,
          "title": "Outage: Users unable to connect to Slack or send messages",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-10/8c886b57284762b6",
          "author": null,
          "description": "Issue summary:\n\r\n\r\nFrom 5:01 PM PDT on October 31, 2023 to around 5:54 PM PDT, customers with international data residency in the Paris, France region, experienced issues connecting to Slack and sending messages.\n\r\n\r\nA routine credential rotation caused database sync issues for the Paris, France data residency region. We reverted this code change and restarted the affected databases, resolving the issue for all impacted customers. \n\r\n\r\nOnce we had mitigated the immediate impact and restored connectivity for customers in the Paris, France data residency region, we reviewed the credential rotation for all other data residency regions to ensure the same issue would not occur anywhere else.\n\r\n\r\nPlease note that the start and end time of the incident have been edited for accuracy.",
          "link": "https://status.slack.com//2023-10/8c886b57284762b6",
          "publishedOn": "2023-11-02T03:45:50.000Z",
          "wordCount": 409,
          "title": "Outage: Issues for customers enrolled in the French data region",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        }
      ]
    },
    {
      "title": "Make Status - Incident History",
      "feedUrl": "https://status.make.com/history.rss",
      "siteUrl": "https://status.make.com",
      "articles": [
        {
          "id": "https://status.make.com/incidents/d82gd0vnvgz1",
          "author": null,
          "description": "Nov 16, 09:45 CET\nResolved - Due to a configuration error, some scenarios in the eu1.make.com, eu2.make.com and us1.make.com zones may have intermittently failed to execute and in case of multiple consecutive errors get disabled by the system. According to our telemetry, the number of impacted scenarios was very small. Customers may have experienced this behavior between 9:45am and 8:00pm CET. We have addressed the configuration problem and all executions are now stable. We will continue monitoring the situation.",
          "link": "https://status.make.com/incidents/d82gd0vnvgz1",
          "publishedOn": "2023-11-16T08:45:00.000Z",
          "wordCount": 3896,
          "title": "Intermittent scenario execution errors in eu1, eu2 and us1 zones",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.make.com/incidents/dzjb57y129qn",
          "author": null,
          "description": "Nov 14, 18:04 CET\nResolved - This incident has been resolved.\nNov 14, 13:53 CET\nUpdate - The current situation is stable, and after performing a series of checks, no issues were observed. We will maintain ongoing monitoring for the next 4 hours, and if everything remains stable during this period, we will proceed to resolve the incident.\nNov 13, 21:16 CET\nMonitoring - The issue is currently stable. We will continue careful monitoring of the situation and provide updates regularly.\nNov 13, 16:58 CET\nUpdate - Our team is continuing to investigate the technical difficulties affecting webhooks and mailhooks on eu2.make.com. At this time, we have not yet identified the root cause, and users may still experience sporadic delays in the processing of these services.\nNov 13, 14:54 CET\nInvestigating - We are currently experiencing technical difficulties with webhooks and mailhooks on eu2.make.com. Users may encounter delays in the processing of webhooks and mailhooks.\nWe will provide another update on this Statuspage within the next 2 hours or as soon as more information becomes available.",
          "link": "https://status.make.com/incidents/dzjb57y129qn",
          "publishedOn": "2023-11-14T17:04:00.000Z",
          "wordCount": 3991,
          "title": "EU2 hooks delayed processing",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.make.com/incidents/g6gklsv4shx6",
          "author": null,
          "description": "Nov  7, 12:43 CET\nResolved - This incident has been resolved.\nNov  6, 16:30 CET\nMonitoring - We have noticed a degradation of performance on eu1.make.celonis.com. A fix has been applied and the system is fully operational again.",
          "link": "https://status.make.com/incidents/g6gklsv4shx6",
          "publishedOn": "2023-11-07T11:43:11.000Z",
          "wordCount": 3844,
          "title": "Failing to execute scenarios",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    }
  ],
  "cliVersion": "1.15.1"
}