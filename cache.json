{
  "sources": [
    {
      "title": "BookingSync.com news",
      "feedUrl": "https://changelog.bookingsync.com/rss",
      "siteUrl": "https://changelog.bookingsync.com",
      "articles": [
        {
          "id": "276591",
          "author": "Maud , Partnership Manager",
          "description": "New!\n¬†¬†\nWe are delighted to announce our new partnership with Plum Guide. ü•≥\nPlum Guide is a curated online travel agency that showcases the world‚Äôs best homes - they're like the Michelin Guide, but for homes.\nThey do this by independently vetting every home and property manager in each market and selecting only the best to feature in our collection.\nThey were recently named ‚ÄòBest OTA‚Äô as the 2023 Shortyz awards. üèÜ\n\n\n\n\n\nüí° How can Plum Guide help you?\nIncremental revenue thanks to unique guests\nEditorial style listings built by their Merchandising team\nDedicated functions for individual Hosts & Property Management Companies\n\n\n\nü§© Benefits:\n2.1x longer stays than on Airbnb\nOver 50% of bookings occur outside of high season\nDedicated AM, Sales & Onboarding teams for both individual Hosts and Property Management Companies\nMajority of Plum Guide Guests have never booked on other OTAs\nHigh Quality Guests (avg. age is 45)\nGuest Cancellation Rate is <0.5%\n\n\n\nInterested in advertising your properties on Plum Guide?\nüëâ Install the app here\n\ndedicated manual page or book a call with your Account Manager here.  \nWe hope that this new channel will help you get more bookings from travelers around the world!\nDon‚Äôt hesitate to contact the Plum Guide team supply@plumguide.com or our support team for any questions.\n\n\nBest regards,",
          "link": "https://changelog.bookingsync.com/new-plum-guide-is-now-available-on-smily!-276591",
          "publishedOn": "2023-10-12T16:07:05.000Z",
          "wordCount": 464,
          "title": "NEW - Plum Guide is now available on Smily! üéâ",
          "imageUrl": "https://cloud.headwayapp.co/changelogs_images/images/big/000/116/376-84bdc4de7ba351ee521a89528433b6b6d5876cfd.png"
        }
      ]
    },
    {
      "title": "Security Bulletins on Tailscale",
      "feedUrl": "https://tailscale.com/security-bulletins/index.xml",
      "siteUrl": "https://tailscale.com/security-bulletins/",
      "articles": [
        {
          "id": "https://tailscale.com/security-bulletins/#ts-2023-007/",
          "author": null,
          "description": "Description: Microsoft Defender is flagging Tailscale 1.46.1 as malware.\nThese classifications are false positives, and we are working with Microsoft to\nresolve the situation.\nAs of 2023-10-27 1:05 AM UTC, we have confirmed that Microsoft have addressed\nthe false positive, meaning Defender no longer flags Tailscale 1.46.1 as\nmalware. A rescan of tailscaled.exe 1.46.1 on VirusTotal confirms this.\nWhat happened?\nMicrosoft Defender was flagging Tailscale 1.46.1 as malware. This caused\nDefender to quarantine the binaries, meaning they could not run.\nWe submitted Tailscale 1.46.1 to Microsoft to investigate the false positive,\nwho then updated Defender to avoid flagging this release as malware at\n2023-10-27 1:05 AM UTC.\nWho is affected?\nPeople using Defender and Tailscale 1.46.1.\nWhat is the impact?\nTailscale will not run on affected machines.\nWhat do I need to do?\nTo resolve this issue on your own tailnet, you can take either or both of 2\napproaches:\nUpdate to a newer version of Tailscale. Newer versions are not affected by this problem.\nCreate an exception in Microsoft Defender. Microsoft has published instructions explaining how to do this.\nUpdate Microsoft Defender.",
          "link": "https://tailscale.com/security-bulletins/#ts-2023-007/",
          "publishedOn": "2023-10-26T00:00:00.000Z",
          "wordCount": 4261,
          "title": "TS-2023-007",
          "imageUrl": "https://tailscale.com/files/images/og-image.png"
        }
      ]
    },
    {
      "title": "Airbnb API Status - Incident History",
      "feedUrl": "https://airbnbapi.statuspage.io/history.rss",
      "siteUrl": "https://airbnbapi.statuspage.io",
      "articles": [
        {
          "id": "https://airbnbapi.statuspage.io/incidents/875yz70rnb1p",
          "author": null,
          "description": "Oct 31, 10:00 PDT\nResolved - This incident has been resolved.\nOct 30, 18:14 PDT\nMonitoring - Today (Oct 30, 2023) between 1:00 PM and 3:00 PM PDT we encountered an incident that impacted our webhooks functionality. As a result, some reservations may have been missing webhooks during this time period. The issue has been resolved, and our team is actively monitoring the results to ensure the stability of our systems. If you have noticed any reservations missing webhooks, we recommend using the GET Reservations API to retrieve the details of those reservations. Alternatively, you can contact us with a list of affected reservations, and we will assist you in backfilling the missing information.\nWe apologize for any inconvenience this may have caused and appreciate your understanding.",
          "link": "https://airbnbapi.statuspage.io/incidents/875yz70rnb1p",
          "publishedOn": "2023-10-31T17:00:19.000Z",
          "wordCount": 3930,
          "title": "Issue Affecting Webhooks",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://airbnbapi.statuspage.io/incidents/kkvp54r30jdn",
          "author": null,
          "description": "Oct  4, 09:46 PDT\nResolved - This incident has been resolved.\nOct  3, 22:04 PDT\nMonitoring - There was an increased number of 500 errors on the GET Opportunities API endpoint. We've mitigated the issue and will continue to monitor it. The time window for these errors was between 9:00 PM and 9:50 PM (PDT) today (Oct 3, 2023)",
          "link": "https://airbnbapi.statuspage.io/incidents/kkvp54r30jdn",
          "publishedOn": "2023-10-04T16:46:35.000Z",
          "wordCount": 3872,
          "title": "500 Error on GET Opportunities API",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://airbnbapi.statuspage.io/incidents/rhkqlr25pfcs",
          "author": null,
          "description": "Oct  3, 10:21 PDT\nResolved - This incident has been resolved.\nOct  2, 10:44 PDT\nMonitoring - We're currently investigating an issue that's causing spikes in our delivery timelines for asynchronous webhook notifications. It began around 5PM PST on Friday, September 29, and briefly reoccured on both Saturday and Sunday afternoon. We've mitigated the issue for now, but will continue to monitor this over the next few days.",
          "link": "https://airbnbapi.statuspage.io/incidents/rhkqlr25pfcs",
          "publishedOn": "2023-10-03T17:21:45.000Z",
          "wordCount": 3875,
          "title": "Issue Delaying Webhook Deliveries",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://airbnbapi.statuspage.io/incidents/6zcksbcfmvsb",
          "author": null,
          "description": "Oct  3, 10:21 PDT\nResolved - This incident has been resolved.\nOct  2, 14:30 PDT\nMonitoring - There was an issue with the generation of Basic Auth headers for synchronous availability checks and asynchronous webhook notifications between 11:45 AM and 2:00 PM PDT today. This resulted in errors for both availability checks and webhooks.\nThe issue has been resolved, and our team will be monitoring any further errors.",
          "link": "https://airbnbapi.statuspage.io/incidents/6zcksbcfmvsb",
          "publishedOn": "2023-10-03T17:21:27.000Z",
          "wordCount": 3892,
          "title": "Basic Auth Errors for Synchronous Availability Checks and Webhook Notifications",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://airbnbapi.statuspage.io/incidents/7d87njvtk91g",
          "author": null,
          "description": "Oct  3, 10:20 PDT\nResolved - This incident has been resolved. Error rates have returned to normal levels. Please retry any failed requests.\nOct  2, 19:51 PDT\nMonitoring - We have mitigated the issue and will continue monitoring it. The time window for the errors was between 5:45 PM and 7:00 PM PDT.\nOct  2, 18:34 PDT\nInvestigating - We are currently investigating elevated error rates when processing the Async Calendars API update requests.",
          "link": "https://airbnbapi.statuspage.io/incidents/7d87njvtk91g",
          "publishedOn": "2023-10-03T17:20:56.000Z",
          "wordCount": 3895,
          "title": "Elevated Server Error Rates on Async Calendars API",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    },
    {
      "title": "Twilio Status - Incident History",
      "feedUrl": "https://status.twilio.com/history.rss",
      "siteUrl": "https://status.twilio.com",
      "articles": [
        {
          "id": "https://status.twilio.com/incidents/ft5xxtxvld67",
          "author": null,
          "description": "THIS IS A SCHEDULED EVENT Oct 31, 20:00 PDT ¬†-¬† Nov 1, 04:00 PDT\nOct 30, 18:22 PDT\nScheduled - The T-Mobile network in the US is conducting an emergency maintenance from 31 October 2023 at 20:00 PDT until 01 November 2023 at 04:00 PDT. During the maintenance window, there could be intermittent delays delivering SMS to and from T-Mobile US handsets.",
          "link": "https://status.twilio.com/incidents/ft5xxtxvld67",
          "publishedOn": "2023-11-01T03:00:00.000Z",
          "wordCount": 7258,
          "title": "US SMS Carrier Maintenance - T-Mobile",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/76fn1xd3zmxf",
          "author": null,
          "description": "THIS IS A SCHEDULED EVENT Oct 31, 17:30 - 21:30 PDT\nOct 18, 03:57 PDT\nScheduled - Our Voice carrier partner in the UK is conducting a planned maintenance from 31 October 2023 at 17:30 PDT until 31 October 2023 at 21:30 PDT. During the maintenance window, there could be call failures from a subset of UK phone numbers.",
          "link": "https://status.twilio.com/incidents/76fn1xd3zmxf",
          "publishedOn": "2023-11-01T00:30:00.000Z",
          "wordCount": 7243,
          "title": "United Kingdom Voice Carrier Partner Maintenance",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/lx1xv4bnlm0f",
          "author": null,
          "description": "Oct 31, 17:21 PDT\nInvestigating - Our monitoring systems have detected a potential issue SMS Delivery Delays when sending to the Telenor Network in Serbia via pre-registered sender-IDs. Our engineering team has been alerted and is actively investigating. We will update as soon as we have more information.",
          "link": "https://status.twilio.com/incidents/lx1xv4bnlm0f",
          "publishedOn": "2023-11-01T00:21:18.000Z",
          "wordCount": 7234,
          "title": "On Call Engineers are Investigating an issue",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/bj4t6qzzcyb3",
          "author": null,
          "description": "Oct 31, 17:10 PDT\nUpdate - We are continuing to investigate the issue causing SMS Delivery Delays when sending to the Surf Telecom Network in Brazil. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 2 hours or as soon as more information becomes available.\nOct 31, 16:13 PDT\nUpdate - We are experiencing SMS Delivery Delays to Surf Telecom Network in Brazil. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 1 hours or as soon as more information becomes available.\nOct 31, 16:07 PDT\nInvestigating - Our monitoring systems have detected a potential issue with SMS delivery delays when sending to the Surf Telecom network in Brazil. Our engineering team has been alerted and is actively investigating. We will update as soon as we have more information.",
          "link": "https://status.twilio.com/incidents/bj4t6qzzcyb3",
          "publishedOn": "2023-11-01T00:10:08.000Z",
          "wordCount": 7366,
          "title": "SMS Delivery Delays to Surf Network in Brazil for a Subset of Short Codes",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/sljkmg32xfj2",
          "author": null,
          "description": "Oct 31, 16:00 PDT\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nOct 27, 16:47 PDT\nScheduled - Our carrier partner Vodafone UK is conducting a planned maintenance from 31 October 2023 at 16:00 PDT until 31 October 2023 at 22:40 PDT. During the maintenance window, there could be intermittent API request failures for Vodafone UK customers.\nImpacted Products: \nLookup Identity Match \nLegacy Identity MatchAndAttributes",
          "link": "https://status.twilio.com/incidents/sljkmg32xfj2",
          "publishedOn": "2023-10-31T23:00:26.000Z",
          "wordCount": 7278,
          "title": "United Kingdom Account Security Carrier Partner Maintenance - Vodafone",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/bf0rlj4jn2lj",
          "author": null,
          "description": "Oct 31, 14:50 PDT\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nOct 30, 15:16 PDT\nScheduled - Our carrier partner EE UK is conducting an emergency maintenance from 31 October 2023 at 14:50 PDT until 01 November 2023 at 00:06 PDT. During the maintenance window, there could be intermittent API request failures for EE UK customers.\n\n\nImpacted Products: Verify Silent Network Auth, Lookup SIM Swap, Lookup Identity Match.",
          "link": "https://status.twilio.com/incidents/bf0rlj4jn2lj",
          "publishedOn": "2023-10-31T21:50:03.000Z",
          "wordCount": 7286,
          "title": "United Kingdom Account Security Carrier Partner Maintenance - EE",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/vh0wdktmql2k",
          "author": null,
          "description": "Oct 31, 14:25 PDT\nResolved - We are no longer experiencing SMS delivery delays when sending messages to the Vinaphone Network in Vietnam. This incident has been resolved.\nOct 31, 12:27 PDT\nMonitoring - We are observing recovery in SMS delivery delays when sending messages to the Vinaphone Network in Vietnam. We will continue monitoring the service to ensure a full recovery. We will provide another update in 2 hours or as soon as more information becomes available.\nOct 31, 09:55 PDT\nUpdate - We are experiencing SMS delivery delays when sending messages to Vinaphone Network in Vietnam. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 4 hours or as soon as more information becomes available.\nOct 31, 08:09 PDT\nUpdate - We are experiencing SMS delivery delays when sending messages to Vinaphone Network in Vietnam. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 2 hours or as soon as more information becomes available.\nOct 31, 07:35 PDT\nInvestigating - We are experiencing SMS delivery delays when sending messages to Vinaphone Network in Vietnam. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 1 hour or as soon as more information becomes available.",
          "link": "https://status.twilio.com/incidents/vh0wdktmql2k",
          "publishedOn": "2023-10-31T21:25:44.000Z",
          "wordCount": 7422,
          "title": "SMS Delivery Delays to Vinaphone Network in Vietnam",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    },
    {
      "title": "DigitalOcean Status - Incident History",
      "feedUrl": "https://status.digitalocean.com/history.rss",
      "siteUrl": "http://status.digitalocean.com",
      "articles": [
        {
          "id": "https://status.digitalocean.com/incidents/nwm1sn0gjfc3",
          "author": null,
          "description": "Oct 27, 14:47 UTC\nResolved - As of 14:30 UTC, our Engineering team has resolved the issue impacting Spaces in our SGP1 and SFO3 regions. Users should no longer experience slowness or timeouts when trying to create or access their Spaces resources in the SGP1 and SFO3 regions. \nIf you continue to experience problems, please open a ticket with our support team. We apologize for any inconvenience.\nOct 27, 14:03 UTC\nMonitoring - Our Engineering team has implemented a fix to resolve the issue impacting Spaces in our SGP1 and SFO3 regions and is monitoring the situation closely. We will post an update as soon as the issue is fully resolved.\nOct 27, 12:04 UTC\nUpdate - Our Engineering team is continuing to investigate an issue impacting Object Storage in our SGP1 region. Additionally, we have become aware that this issue has also impacted Object Storage in the SFO3 region. During this time, users may encounter difficulties accessing Spaces, creating new buckets, and uploading files to and from Spaces buckets. Our Engineers are actively working on isolating the root cause of the issue. While we don't have an exact timeframe for a resolution yet however we will be providing updates as developments occur.\nWe apologize for the inconvenience and thank you for your patience and continued support.\nOct 27, 11:25 UTC\nInvestigating - As of 10:22 UTC, our Engineering team is investigating an issue with Object Storage in our SGP1 region. During this time, users may encounter difficulties accessing Spaces, creating new buckets, and uploading files to and from Spaces buckets. \nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/nwm1sn0gjfc3",
          "publishedOn": "2023-10-27T14:47:58.000Z",
          "wordCount": 6209,
          "title": "Object Storage - SGP1 and SFO3",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/1zckjwhpq1xy",
          "author": null,
          "description": "Oct 26, 15:52 UTC\nResolved - As of 15:45 UTC, our Engineering team has confirmed the full resolution of the issue that impacted network reachability in the LON1 region. All services and resources should now be fully reachable.\nIf you continue to experience problems, please open a ticket with our support team from within your Cloud Control Panel. \nThank you for your patience and we apologize for any inconvenience.\nOct 26, 15:18 UTC\nMonitoring - The network issues affecting our LON1 region have been mitigated. Users should no longer experience packet loss/latency, timeouts, and related issues with Droplet-based services in this region, including Droplets, Managed Kubernetes, and Managed Database. \nWe will continue to monitor network conditions for a period of time to establish a return to pre-incident conditions.\nOct 26, 14:25 UTC\nIdentified - Our Engineering team has identified the cause of the issue impacting the networking in the LON1 region and is actively working on a fix. During this time, users may still experience packet loss/latency, timeouts, and related issues with Droplet-based services in these regions, including Droplets, Managed Kubernetes, and Managed Database. \nWe will post an update as soon as additional information is available.\nOct 26, 12:50 UTC\nInvestigating - As of 11:40 UTC, our Engineering team is investigating an issue impacting the networking in the LON1 region. During this time, a subset of users may experience packet loss/latency, timeouts, and related issues with Droplet-based services in this region, including Droplets, Managed Kubernetes, and Managed Database. \nWe will share an update once we have further information.",
          "link": "https://status.digitalocean.com/incidents/1zckjwhpq1xy",
          "publishedOn": "2023-10-26T15:52:41.000Z",
          "wordCount": 6179,
          "title": "Network Connectivity in LON1",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/y5rwfhsl0gqw",
          "author": null,
          "description": "Oct 24, 23:00 UTC\nCompleted - The scheduled maintenance has been completed.\nOct 24, 21:00 UTC\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nOct 20, 19:40 UTC\nUpdate - After a thorough review by the team performing this maintenance, we have determined that our initial messaging does not convey the complete scope and potential impact of this event. Existing infrastructure will continue running without issue during this maintenance window. However, users may experience increased latency with some platform operations, including: \nCloud Control Panel and API operations\nEvent processing\nDroplet creates, resizes, rebuilds, and power events\nManaged Kubernetes reconciliation and scaling\nLoad Balancer operations\nContainer Registry operations\nApp ‚Ä¶",
          "link": "https://status.digitalocean.com/incidents/y5rwfhsl0gqw",
          "publishedOn": "2023-10-24T23:00:07.000Z",
          "wordCount": 6222,
          "title": "Core Infrastructure Maintenance",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/gp9bzm1hnlk4",
          "author": null,
          "description": "Oct 24, 09:15 UTC\nResolved - Our Engineering team has confirmed the full resolution of the issue impacting network connectivity in multiple regions. The impact has been completely subsided and the network connectivity is back to normal for all the impacted services.\nIf you continue to experience problems, please open a ticket with our support team from your Cloud Control Panel.\nThank you for your patience and we apologize for any inconvenience.\nOct 24, 09:03 UTC\nMonitoring - Our Engineering team has received communication from the upstream provider that a fix to resolve the networking issue has been implemented. We are currently monitoring the situation closely and will share an update as soon as the issue is fully resolved.\nOct 24, 07:41 UTC\nIdentified - Our Engineering team has identified the cause of issues impacting networking in multiple regions. The issues are a direct result of traffic congestion from our upstream providers, which is in the process of being repaired.\nAt this time, a subset of users will continue to experience intermittent packet loss or increased latency while interacting with the resources in the affected regions.\nWe apologize for the inconvenience and will share an update once we have more information.\nOct 24, 06:11 UTC\nInvestigating - As of 05:30 UTC, our Engineering team is investigating an issue impacting the networking in multiple regions. During this time, users may experience intermittent packet loss or increased latency while interacting with the resources in the affected regions.\nAt the moment, all the droplet-based services appear to be impacted and the users can expect to see brief connectivity issues and interrupted traffic flows. \nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/gp9bzm1hnlk4",
          "publishedOn": "2023-10-24T09:15:10.000Z",
          "wordCount": 6208,
          "title": "Networking in multiple regions.",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/f38zfs58jkl8",
          "author": null,
          "description": "Oct 17, 17:33 UTC\nResolved - As of 16:10 UTC, our Engineering team has confirmed the full resolution of the issue impacting our App platform service where users were not able to access their Apps via Cloud Panel. Apps should be loading fine https://cloud.digitalocean.com/apps without any errors. \nWe appreciate your patience during the process and if you continue to experience any issues  please open a ticket with our support team.\nOct 17, 16:51 UTC\nMonitoring - Our Engineering team has deployed a fix to resolve the ongoing issue with accessing Apps list via Cloud panel for our App platform service. As of 16:10 UTC the situation started to improve and the users should be able to access their apps via Cloud panel UI without any issues. \nWe are monitoring the situation closely and will post an update once the issue is completely resolved.\nOct 17, 16:19 UTC\nIdentified - Our Engineering team has identified an issue impacting App platform service in all regions. During this time users may experience issues while loading apps via https://cloud.digitalocean.com/apps and the requests appear to be timing out. New App deployments via API or doctl and the existing deployed apps are not impacted by this incident.  \nOur team is working to mitigate the issue and we will provide an update as soon as possible.",
          "link": "https://status.digitalocean.com/incidents/f38zfs58jkl8",
          "publishedOn": "2023-10-17T17:33:44.000Z",
          "wordCount": 6143,
          "title": "App Platform Accessibility via Cloud",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/7548dwrnthz8",
          "author": null,
          "description": "Oct 17, 06:48 UTC\nResolved - As of 06:25 UTC, our Engineering team has confirmed that the issue impacting the newly created Managed Database Clusters has been fully resolved. \nUsers will no longer experience issues with the newly created Managed Database Cluster.\nIf you continue to experience any issues with Managed Database Clusters please open a ticket with our support team. Thank you for your patience.\nOct 17, 06:24 UTC\nMonitoring - As of 06:15 UTC, our Engineering team has identified the issue impacting our Managed Database product and a fix has been implemented to mitigate the issue. Currently, new users may no longer experience issues with the newly created Managed Database Cluster due to hostname resolution.\nUsers who already have a Managed Database cluster are not impacted by this incident.\nThank you for your patience and we apologize for the inconvenience caused. We are monitoring the situation and will post an update once the incident is completely resolved.\nOct 17, 04:22 UTC\nInvestigating - Our Engineering team is currently investigating reports of issues impacting a subset of users using our Managed Database Clusters. \nDuring this time, hostnames for the newly created Managed Database Cluster are not resolving. However, previously created Clusters are not impacted due to the same.\nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/7548dwrnthz8",
          "publishedOn": "2023-10-17T06:48:06.000Z",
          "wordCount": 6149,
          "title": "Managed Database Cluster",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/yxfmyjl0kmpr",
          "author": null,
          "description": "Oct 16, 23:14 UTC\nResolved - From 22:45 to 23:00 UTC, our Engineering team has reported an issue with DigitalOcean Control Panel and API.\n During that time, Customers may have experienced intermittent timeout errors while using DigitalOcean Control Panel and API. \nIf you continue to experience problems, please open a ticket with our support team. Thank you for your patience and we apologize for any inconvenience.",
          "link": "https://status.digitalocean.com/incidents/yxfmyjl0kmpr",
          "publishedOn": "2023-10-16T23:14:32.000Z",
          "wordCount": 5980,
          "title": "DigitalOcean Control Panel and API",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/k58m2k4qcchf",
          "author": null,
          "description": "Oct 15, 01:04 UTC\nResolved - Our Engineering team has confirmed the full resolution of the networking issue in the SFO regions. If you continue to see issues with latency or packet loss in the SFO region please reach out directly to our support team for assistance.\nOct 14, 20:30 UTC\nUpdate - Our Engineering team is continuing to monitor the networking issue in the SFO regions. So far, we haven't observed any major spike in latency or packet loss with network connections going in or out of the SFO regions. However, we will post an update as soon as the issue is fully resolved.\nWe apologize for the inconvenience and thank you for your patience and continued support.\nOct 14, 15:25 UTC\nMonitoring - Our Engineering team has detected a recurrence of the networking issue identified in a previous incident today: \nhttps://status.digitalocean.com/incidents/bhpslzd37517\nOur team is actively monitoring the situation and has implemented traffic routing changes where applicable to alleviate the latency. Some users may still experience packet loss or increased latency accessing the resources in the SFO region from certain ISPs.\nWe apologize for any inconvenience caused and will provide updates as the situation progresses.",
          "link": "https://status.digitalocean.com/incidents/k58m2k4qcchf",
          "publishedOn": "2023-10-15T01:04:23.000Z",
          "wordCount": 6118,
          "title": "Network Latency in SFO Region",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/bhpslzd37517",
          "author": null,
          "description": "Oct 14, 11:46 UTC\nResolved - Our Engineering team has confirmed full resolution of the issue with networking in affected regions. Users should no longer experience timeouts or delays when connecting to or from these regions. \nIf you continue to experience problems, please open a ticket with our support team.\nThank you for your patience and we apologize for any inconvenience.\nOct 14, 11:10 UTC\nMonitoring - As of 10:55 UTC, our Engineering team has implemented a fix to address the networking problem in the affected regions and is currently monitoring the situation. Users should no longer face timeouts or encounter delays when connecting to or from these regions. We will post an update as soon as the issue is fully resolved.\nOct 14, 10:30 UTC\nUpdate - As of 10:27 UTC, our Engineering team is continuing to investigate an issue with networking in our SFO regions. Additionally, it has come to our attention that this issue has affected other regions, specifically SGP1, SYD1, and NYC3. Users may encounter timeouts or experience delays in network connections going in and out of these regions. Our Engineers are actively working on isolating the root cause of the issue. While we don't have an exact timeframe for a resolution yet however we will be providing updates as developments occur.\nWe apologize for the inconvenience and thank you for your patience and continued support.\nOct 14, 09:47 UTC\nUpdate - We are continuing to investigate this issue.\nOct 14, 09:12 UTC\nInvestigating - As of 8:30 UTC, our Engineering team is investigating an issue with networking in our SFO regions. During this time, users may experience timeouts or latency with network connections going in or out of the SFO regions. We apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/bhpslzd37517",
          "publishedOn": "2023-10-14T11:46:50.000Z",
          "wordCount": 6231,
          "title": "Network Latency in Multiple Regions",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/lh3j71zp57hx",
          "author": null,
          "description": "Oct 12, 19:17 UTC\nResolved - Our Engineering team has confirmed the resolution of the issue that impacted the Spaces CDN. Objects should be accessible over the CDN endpoint without any issues. However, HTTP/2 is temporarily unavailable due to upstream issues, and due to this HTTP/2 requests should automatically be re-negotiated to 1.1, but in case you experience failures please open a ticket with our support team.\nThank you for your patience and we apologize for any inconvenience.\nOct 12, 16:10 UTC\nUpdate - After our upstream provider implemented a remediation step to resolve the issue with the Spaces CDN, the Spaces CDN is serving the objects stored in the Spaces bucket without any errors or performance issues. However, we are still monitoring the situation closely and we'll share more in‚Ä¶",
          "link": "https://status.digitalocean.com/incidents/lh3j71zp57hx",
          "publishedOn": "2023-10-12T19:17:29.000Z",
          "wordCount": 6454,
          "title": "Spaces CDN in Multiple Regions",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/fsfsv9fj43w7",
          "author": null,
          "description": "Oct 11, 07:26 UTC\nResolved - Our Engineering team has resolved the issue with the Managed Kubernetes Service. A daemonset has been released to all existing clusters eliminating the auto-update process and it will be removed again going forward. If you find worker nodes that could still be affected by a prior occurrence of this incident, please replace them for permanent mitigation.\nIf you continue to experience problems, please open a ticket with our support team. We apologize for any inconvenience.\nOct 11, 04:06 UTC\nMonitoring - Our Engineering team has completed the work for both items. New images have been released that eliminate the auto-update process and the daemonset has been applied to all existing clusters. \nGiven this, the team is not expecting to see a recurrence of this inciden‚Ä¶",
          "link": "https://status.digitalocean.com/incidents/fsfsv9fj43w7",
          "publishedOn": "2023-10-11T07:26:53.000Z",
          "wordCount": 7715,
          "title": "Managed Kubernetes Service",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/08q0d3g8dtp3",
          "author": null,
          "description": "Oct  7, 20:01 UTC\nResolved - As of 19:52 UTC, our Engineering team has confirmed the full resolution of the issue impacting the listing of Spaces buckets in the FRA1 region via the Cloud Control Panel. \nIf you continue to experience problems, please open a ticket with our support team. Thank you for your patience and we apologize for any inconvenience.\nOct  7, 19:38 UTC\nMonitoring - Our engineering team has implemented a fix to resolve the issue with listing Spaces in our FRA1 region via the Cloud Panel and is monitoring the situation. We will post an update as soon as the issue is fully resolved.\nOct  7, 19:15 UTC\nInvestigating - Our Engineering team is investigating an issue with Spaces in our FRA1 region. As of 13:40 UTC, users may experience issues listing the Spaces created in the FRA1 region via the Cloud Panel. We apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/08q0d3g8dtp3",
          "publishedOn": "2023-10-07T20:01:58.000Z",
          "wordCount": 6081,
          "title": "Spaces listing in FRA1",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    },
    {
      "title": "Notion Status - Incident History",
      "feedUrl": "https://status.notion.so/history.rss",
      "siteUrl": "https://status.notion.so",
      "articles": [
        {
          "id": "https://status.notion.so/incidents/d38fkw0dxb29",
          "author": null,
          "description": "Oct 17, 11:59 PDT\nResolved - Notification health should be back to normal. Engineering will continue to monitor system health.\nOct 17, 11:40 PDT\nInvestigating - We are experiencing service degradation related to notifications. Notifications may be delayed, and notification badge counts may not be accurate.",
          "link": "https://status.notion.so/incidents/d38fkw0dxb29",
          "publishedOn": "2023-10-17T18:59:19.000Z",
          "wordCount": 3365,
          "title": "Notion is experiencing service degradation related to notifications",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/55frj2c42yvq",
          "author": null,
          "description": "Oct 12, 11:14 PDT\nResolved - Users were unable to log in using the Notion mobile and desktop apps to enterprise workspaces requiring SAML SSO login. This issue is resolved now.\nOct 12, 11:10 PDT\nUpdate - We are experiencing an issue with SAML SSO login in the Notion mobile and desktop apps, and we are investigating the cause.\nOct 12, 11:05 PDT\nInvestigating - We are experiencing an issue with SAML SSO and we are investigating the cause.",
          "link": "https://status.notion.so/incidents/55frj2c42yvq",
          "publishedOn": "2023-10-12T18:14:45.000Z",
          "wordCount": 3403,
          "title": "Notion is experiencing an issue with SAML SSO login",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/18rxsrdk6zkz",
          "author": null,
          "description": "Oct  4, 10:52 PDT\nResolved - The issue has been resolved. Notion app and API performance is back to Normal.\nOct  4, 09:28 PDT\nMonitoring - We've rolling out a fix and will continue monitoring.\nOct  4, 09:04 PDT\nIdentified - We have implemented a fix and rolling out.\nOct  4, 08:32 PDT\nInvestigating - We are experiencing some performance degradation and are investigating the cause.",
          "link": "https://status.notion.so/incidents/18rxsrdk6zkz",
          "publishedOn": "2023-10-04T17:52:33.000Z",
          "wordCount": 3383,
          "title": "Notion is experiencing degraded performance",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/dknkp34qzxg0",
          "author": null,
          "description": "Oct  4, 06:49 PDT\nResolved - The issue has been resolved. Notion app and API performance is back to Normal.\nOct  4, 05:31 PDT\nMonitoring - We're rolling out a fix and will continue monitoring.\nOct  4, 05:12 PDT\nUpdate - We have implemented a fix and rolling out soon.\nOct  4, 04:58 PDT\nIdentified - We have identified the issue and are working on a fix.\nOct  4, 04:46 PDT\nInvestigating - We are experiencing some performance degradation and are investigating the cause.",
          "link": "https://status.notion.so/incidents/dknkp34qzxg0",
          "publishedOn": "2023-10-04T13:49:09.000Z",
          "wordCount": 3403,
          "title": "Notion is experiencing degraded performance",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/gxjt1jbwqs7m",
          "author": null,
          "description": "Oct  2, 17:13 PDT\nResolved - The issue has been resolved. Notion app and API performance is back to Normal.\nOct  2, 16:54 PDT\nIdentified - We are experiencing some performance degradation and are investigating the cause.",
          "link": "https://status.notion.so/incidents/gxjt1jbwqs7m",
          "publishedOn": "2023-10-03T00:13:08.000Z",
          "wordCount": 3350,
          "title": "Notion is experiencing degraded performance",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/b3g5shlj6hhl",
          "author": null,
          "description": "Oct  2, 16:03 PDT\nResolved - The issue has been resolved. Notion app and API performance is back to Normal.\nOct  2, 14:28 PDT\nUpdate - We're continuing to monitor the impact of the fix we implemented. We expect it may take a few hours to fully complete.\nOct  2, 13:54 PDT\nMonitoring - We're rolling out a fix and will continue monitoring.\nOct  2, 13:02 PDT\nUpdate - We have developed a fix and will be implementing soon.\nOct  2, 06:40 PDT\nIdentified - We have identified the issue and are working on a fix.\nOct  2, 06:24 PDT\nInvestigating - We are experiencing some performance degradation and are investigating the cause.",
          "link": "https://status.notion.so/incidents/b3g5shlj6hhl",
          "publishedOn": "2023-10-02T23:03:47.000Z",
          "wordCount": 3434,
          "title": "Notion is experiencing degraded performance",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    },
    {
      "title": "Rippling Status - Incident History",
      "feedUrl": "https://status.rippling.com/history.rss",
      "siteUrl": "https://status.rippling.com",
      "articles": [
        {
          "id": "https://status.rippling.com/incidents/fjw9lbztvc7f",
          "author": null,
          "description": "Oct 27, 15:51 UTC\nResolved - The issue has now been resolved. All admins are able to access their Admin Account view as expected.\nOct 27, 14:50 UTC\nIdentified - We are aware of an issue where 'Admin Account' is not visible in the account dropdown for Super Admins. After they navigate to their 'Employee Account' view they can't navigate back to their admin view. \nThe root cause has been identified and the issue should be resolved in the next hour.",
          "link": "https://status.rippling.com/incidents/fjw9lbztvc7f",
          "publishedOn": "2023-10-27T15:51:44.000Z",
          "wordCount": 5077,
          "title": "Admin account not visible in the account dropdown for Super Admins",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/248858/rippling_favicoon.png"
        },
        {
          "id": "https://status.rippling.com/incidents/vnm5lc6f0b91",
          "author": null,
          "description": "Oct 25, 21:10 UTC\nResolved - This incident has been resolved.\nOct 25, 21:02 UTC\nMonitoring - A fix has been implemented and we are monitoring the results.\nOct 25, 20:52 UTC\nIdentified - An issue has been identified and we are working on a fix.\nOct 25, 20:46 UTC\nUpdate - We are continuing to monitor for any further issues.\nOct 25, 20:22 UTC\nMonitoring - A fix has been implemented and we are monitoring the results.\nOct 25, 20:17 UTC\nIdentified - The issue has been identified and a fix is being implemented.\nOct 25, 20:14 UTC\nInvestigating - We are currently investigating this issue.",
          "link": "https://status.rippling.com/incidents/vnm5lc6f0b91",
          "publishedOn": "2023-10-25T21:10:01.000Z",
          "wordCount": 5089,
          "title": "Issues loading Rippling",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/248858/rippling_favicoon.png"
        },
        {
          "id": "https://status.rippling.com/incidents/vlnmlxcw85r8",
          "author": null,
          "description": "Oct 24, 22:51 UTC\nResolved - This incident has been resolved.\nOct 24, 22:08 UTC\nUpdate - We are continuing to monitor for any further issues.\nOct 24, 22:07 UTC\nMonitoring - A fix has been implemented and we are monitoring the results.\nOct 24, 21:58 UTC\nIdentified - The issue has been identified and a fix is being implemented.\nOct 24, 21:57 UTC\nInvestigating - Customers are experiencing intermittent issues using single sign-on from Rippling (IdP-initiated SAML) to third-party applications. We are investigating this issue.",
          "link": "https://status.rippling.com/incidents/vlnmlxcw85r8",
          "publishedOn": "2023-10-24T22:51:30.000Z",
          "wordCount": 5090,
          "title": "Issues with single sign-on from Rippling to third-party applications",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/248858/rippling_favicoon.png"
        }
      ]
    },
    {
      "title": "Google Workspace Status Dashboard Updates",
      "feedUrl": "https://www.google.com/appsstatus/dashboard/en/feed.atom",
      "siteUrl": "https://www.google.com/appsstatus/dashboard/",
      "articles": [
        {
          "id": "https://www.google.com/appsstatus/dashboard/incidents/BhdnzdJaE1T5JstM2CjM",
          "author": null,
          "description": "<p> Incident began at <strong>2023-09-28 07:00</strong> and ended at <strong>2023-10-04 18:22</strong> <span>(times are in <strong>Coordinated Universal Time (UTC)</strong>).</span></p><div class=\"cBIRi14aVDP__status-update-text\"><h1>Mini Incident Report</h1>\n<p>We apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced an impact outside of what is listed below, please reach out to Google Workspace Support using the help article <a href=\"https://support.google.com/a/answer/1047213\">https://support.google.com/a/answer/1047213</a>.</p>\n<p>(All Times US/Pacific)</p>\n<p><strong>Incident Start:</strong> 28 Sept 2023 00:00</p>\n<p><strong>Incident End:</strong> 4 Oct 2023 11:22</p>\n<p><strong>Duration:</strong>  6 days, 11 hours, 22 minutes</p>\n<p><strong>Affected Services and Features:</strong></p>\n<p>Google Keep - Email notifications</p>\n<p><strong>Regions/Zones:</strong> Global</p>\n<p><strong>Description:</strong></p>\n<p>Google Keep experienced an issue where notification emails about note sharing ended up in the receiver&#39;s Spam folder for a duration of 6 days, 11 hours and 22 minutes. From preliminary analysis, the root cause is an unexpected increase in notifications.</p>\n<p><strong>Customer Impact:</strong></p>\n<p>Google Keep users incorrectly received email notifications in their spam folder.</p>\n</div><hr><p>Affected products: Google Keep</p>",
          "link": "https://www.google.com/appsstatus/dashboard/incidents/BhdnzdJaE1T5JstM2CjM",
          "publishedOn": "2023-10-09T11:49:19.000Z",
          "wordCount": 656,
          "title": "RESOLVED: **Summary**\nGoogle Keep users are experiencing issues with notification emails when a note is shared.\n**Description:**\nWe are experiencing an issue with Google Keep beginning on Wednesday, 2023-09-27. Mitigation work is underway by our engineering team. We do not have an ETA for mitigation at this point. We will provide more information by Wednesday, 2023-10-04 10:00 US/Pacific.\n**Diagnosis**\nGoogle Keep users are experiencing an issue where notification emails about note sharing are ending up in receiver's Spam folder\n**Workaround**\nNone at this time",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "GitHub Status - Incident History",
      "feedUrl": "https://www.githubstatus.com/history.rss",
      "siteUrl": "https://www.githubstatus.com",
      "articles": [
        {
          "id": "https://www.githubstatus.com/incidents/sbjdwn6mvht7",
          "author": null,
          "description": "Oct 25, 22:15 UTC\nResolved - This incident has been resolved.\nOct 25, 21:37 UTC\nUpdate - The observed Copilot API error rate is around 5% of the requests. As a result, some of the Copilot code suggestions are skipped or not delivered on time.\nOct 25, 21:19 UTC\nUpdate - We are seeing an impact in the US region as well. We continue the investigation.\nOct 25, 20:53 UTC\nUpdate - Copilot is experiencing intermittent issues in our Japan region. Engineers are currently investigating.\nOct 25, 20:50 UTC\nInvestigating - We are investigating reports of degraded performance for Copilot",
          "link": "https://www.githubstatus.com/incidents/sbjdwn6mvht7",
          "publishedOn": "2023-10-25T22:15:54.000Z",
          "wordCount": 5084,
          "title": "Incident with Copilot",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/p351mbywbp0t",
          "author": null,
          "description": "Oct 25, 13:02 UTC\nResolved - This incident has been resolved.\nOct 25, 12:56 UTC\nUpdate - We have applied a fix to help with Copilot performance. Initial signals show good recovery. We will continue to monitor for the time being and resolve when confident the issue has been resolved.\nOct 25, 12:29 UTC\nUpdate - We are investigating degraded performance in Europe for Copilot. We will continue to keep users updated on progress towards mitigation.\nOct 25, 12:10 UTC\nInvestigating - We are investigating reports of degraded performance for Copilot",
          "link": "https://www.githubstatus.com/incidents/p351mbywbp0t",
          "publishedOn": "2023-10-25T13:02:51.000Z",
          "wordCount": 5073,
          "title": "Incident with Copilot",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/lw4dvwltm025",
          "author": null,
          "description": "Oct 22, 16:07 UTC\nResolved - This incident has been resolved.\nFrom 11:21 to 16:07 UTC some GitHub customers experienced errors cloning via workflows or via the command line.\nA third-party configuration change resulted in an unexpected behavior to our systems that resulted in Git clone failures. Once we detected the change we were able to disable it, and our systems started operating normally.\nWith the incident mitigated, we are working with our third-party provider to improve subsequent configuration change rollouts.\nOct 22, 15:58 UTC\nUpdate - We have mitigated the cause of the issue and are awaiting positive confirmation from impacted customers that the issue is fully resolved.\nOct 22, 15:34 UTC\nUpdate - We are currently investigating reports from some customers encountering errors when cloning repositories via workflows or via the command line. We do not currently have an ETA for resolution. Next update in 30 minutes.\nOct 22, 15:16 UTC\nInvestigating - We are investigating reports of degraded performance for Git Operations",
          "link": "https://www.githubstatus.com/incidents/lw4dvwltm025",
          "publishedOn": "2023-10-22T16:07:58.000Z",
          "wordCount": 5148,
          "title": "Incident with Git Operations",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/gkrfrz6r7flc",
          "author": null,
          "description": "Oct 17, 13:49 UTC\nResolved - From 10:59 UTC to 13:48 UTC, GitHub Codespaces service was down or degraded due to an outage in our authentication service.This issue impacted 67% of users over this time period.\nOur service auth layer experienced throttling with our third party dependencies due to higher load. This impacted all user facing scenarios for Codespaces service. Our automated regional failover kicked in, but it failed to mitigate as this issue impacted the service globally. We mitigated manually by reducing load on external dependency.\nWith the incident mitigated, we are working to assess and implement scaling improvements to make our service more resilient with increasing load.\nOct 17, 13:46 UTC\nUpdate - Codespaces is experiencing degraded performance. We are continuing to investigate.\nOct 17, 13:24 UTC\nUpdate - We are continuing with efforts to mitigate Codespaces issues   and are beginning to see some Codespace creations succeed.\nOct 17, 12:18 UTC\nUpdate - We have identified an issue impacting most Codespaces operations and are working on a mitigation.\nOct 17, 11:18 UTC\nUpdate - Codespaces is experiencing degraded availability. We are continuing to investigate.\nOct 17, 11:14 UTC\nInvestigating - We are investigating reports of degraded performance for Codespaces",
          "link": "https://www.githubstatus.com/incidents/gkrfrz6r7flc",
          "publishedOn": "2023-10-17T13:49:00.000Z",
          "wordCount": 5185,
          "title": "Incident with Codespaces",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/gtsz1l2jc96n",
          "author": null,
          "description": "Oct  9, 15:18 UTC\nResolved - On October 9, 2023 at 14:24 UTC, a noticeable delay in commits appearing in pull requests was detected.  During the incident, approximately 9% of pull requests (less than the 20% first reported) experienced staleness of up to 7m. The root cause was identified to be an increase in the latency of a downstream dependency causing pull request workers to saturate their available capacity, resulting in delayed updates to PRs - no data was lost during this incident.\n\tWe mitigated this by adding additional capacity to the affected worker pool at 15:02 UTC. This allowed our background jobs to catch up with the backlog of updates and provide relief to our customers. Additionally, we have significantly increased the performance of the downstream service to prevent recurrence\nOct  9, 14:52 UTC\nUpdate - We are investigating delays for commits showing up on Pull Requests page loads in the web UI. As a result of this,  about 20% of pull requests are currently showing stale data of up-to 7m. We are currently investigating contributing factors right now.\nOct  9, 14:51 UTC\nInvestigating - We are investigating reports of degraded performance for Pull Requests",
          "link": "https://www.githubstatus.com/incidents/gtsz1l2jc96n",
          "publishedOn": "2023-10-09T15:18:49.000Z",
          "wordCount": 5180,
          "title": "Incident with Pull Requests",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/w554d74dv18j",
          "author": null,
          "description": "Oct  6, 02:59 UTC\nResolved - We deployed a new configuration to improve our network availability. This resulted in a small percentage of user traffic getting incorrectly blocked, but missed by our automated detections. We mitigated this with a change to the configuration, rolled out slowly over the last hour of this incident time for safe deployment. Beyond the learnings related to the config, we are analyzing how we can more quickly detect this kind of impact as part of future configuration rollouts.\nOct  6, 02:42 UTC\nUpdate - We have confirmed that the fix has resolved the issue in the subset of regions where it has been deployed. We are now continuing the deployment to the remaining regions.\nOct  6, 02:03 UTC\nUpdate - We are monitoring the rollout of the fix and are beginning to see signs of improvement. We will send another update shortly.\nOct  6, 01:31 UTC\nUpdate - A small number of customers are experiencing 403 errors when attempting to access repository data via the API. We have found what we believe to be the cause of the issue and are deploying a fix.\nOct  6, 01:12 UTC\nInvestigating - We are investigating reports of degraded performance for API Requests",
          "link": "https://www.githubstatus.com/incidents/w554d74dv18j",
          "publishedOn": "2023-10-06T02:59:36.000Z",
          "wordCount": 5193,
          "title": "Incident with API Requests",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/9fk4c2w43clz",
          "author": null,
          "description": "Oct  5, 16:42 UTC\nResolved - On October 5, 2023 at 13:40 UTC, our monitoring systems observed an increase in the time it was taking for Git pushes to become visible when viewing commits in Pull Requests. Under normal operating conditions, a series of asynchronous jobs runs in response to every push and within a few seconds applies a number of side-effects in Pull Requests such as requesting reviews, marking Pull Requests as merged, and showing new commits. During the incident, jobs were entering the queue faster than we could process them, resulting in processing delays as high as 75 seconds on average, and as much as 15 minutes in the worst case. About 10% of all Pull Request page loads were showing out-of-date data during this time.\nWe had recently created a dedicated worker pool for pro‚Ä¶",
          "link": "https://www.githubstatus.com/incidents/9fk4c2w43clz",
          "publishedOn": "2023-10-05T16:42:15.000Z",
          "wordCount": 5358,
          "title": "Incident with Pull Requests",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        }
      ]
    },
    {
      "title": "Slack System Status",
      "feedUrl": "https://status.slack.com/feed/rss",
      "siteUrl": "https://status.slack.com/",
      "articles": [
        {
          "id": "https://status.slack.com//2023-10/2ef86432e31615ea",
          "author": null,
          "description": "Customers should no longer be experiencing any connection issues with Slack. Apologies for the trouble today and thank you for your patience.",
          "link": "https://status.slack.com//2023-10/2ef86432e31615ea",
          "publishedOn": "2023-10-24T21:08:02.000Z",
          "wordCount": 195,
          "title": "Incident: A small number of users are having problems loading Slack.",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-10/ad8f0e62516e8812",
          "author": null,
          "description": "Issue summary:\n\r\n\r\nOn Friday, October 6 2023, from 1:52 AM PDT to 2:12 AM PDT, some users were unable to load Slack. This was caused by an issue where certain backend Slack processes were pulling data from our database rather than their cache which caused strain on our servers.\n\r\n\r\nWe rolled out a change to how these processes load data, and the issue was resolved for all users.",
          "link": "https://status.slack.com//2023-10/ad8f0e62516e8812",
          "publishedOn": "2023-10-06T15:28:47.000Z",
          "wordCount": 232,
          "title": "Outage: Users are having trouble connecting to Slack",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-10/6d592537eb7bd98e",
          "author": null,
          "description": "Issue Summary:\n\r\n\r\nOn Oct 4, 2023 from 11:15 PM PDT to around 11:58 PM PDT a small subset of users experienced trouble connecting to Slack and sending and receiving messages.\n\r\n\r\nA code change optimizing resource usage caused a core service to restart causing brief connectivity issues for a few users.\n\r\n\r\nThe service recovered automatically and we‚Äôve put measures in place to prevent this from happening in the future.",
          "link": "https://status.slack.com//2023-10/6d592537eb7bd98e",
          "publishedOn": "2023-10-05T13:53:12.000Z",
          "wordCount": 160,
          "title": "Incident: Trouble connecting to Slack",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-10/ee32d13012fb29d5",
          "author": null,
          "description": "Issue Summary:\n\r\n\r\nOn October 3, 2023 from 4:00 PM PDT to 4:20 PM PDT, some customers had trouble loading threads, mentions, reactions and search results in Slack.\n\r\n\r\nWe determined that this was caused during the process of changing our database hosts on our backend. To mitigate the issue, we stopped the change which fixed the issue for affected customers.\n\r\n\r\nWe're sorry for any disruption this may have caused and thank you for your patience while we looked into this",
          "link": "https://status.slack.com//2023-10/ee32d13012fb29d5",
          "publishedOn": "2023-10-04T18:53:01.000Z",
          "wordCount": 229,
          "title": "Incident: Issues with loading some items on Slack",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-10/101eb09455dcaa9a",
          "author": null,
          "description": "Issue Summary:\n\r\n\r\nOn October 2, 2023 from 12:18PM PDT to 12:26PM PDT, some users noticed that threads were not loading correctly.\n\r\n\r\nWe identified a database issue on our backend that was causing the threads to not load. The issue was mitigated and users should no longer experience trouble loading threads.\n\r\n\r\nWe are investigating the cause of the database issue so we can ensure this does not happen again.\n\r\n\r\nWe apologize for any interruption to your work day!",
          "link": "https://status.slack.com//2023-10/101eb09455dcaa9a",
          "publishedOn": "2023-10-02T20:16:28.000Z",
          "wordCount": 109,
          "title": "Incident: Threads were not loading for some users",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        }
      ]
    },
    {
      "title": "Make Status - Incident History",
      "feedUrl": "https://status.make.com/history.rss",
      "siteUrl": "https://status.make.com",
      "articles": [
        {
          "id": "https://status.make.com/incidents/2c52p236t4rp",
          "author": null,
          "description": "Oct 12, 17:40 CEST\nResolved - This incident has been resolved.\nOct 12, 16:21 CEST\nMonitoring - We implemented workaround and we are currently monitoring the issue.\nOct 12, 16:09 CEST\nInvestigating - We are experiencing issues within our scenario features i.e. users cannot clone scenario nor move it to a folder inside list of scenarios. This is still possible when user open particular scenario.\nWe are currently working on implementing a quick workaround, we should publish the relevant steps within the next 30 minutes.",
          "link": "https://status.make.com/incidents/2c52p236t4rp",
          "publishedOn": "2023-10-12T15:40:47.000Z",
          "wordCount": 3903,
          "title": "Users cannot clone nor move scenarios",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.make.com/incidents/jjzrxzv3vfj5",
          "author": null,
          "description": "Oct  5, 18:58 CEST\nResolved - This incident has been resolved.\nOct  5, 13:23 CEST\nMonitoring - We have identified that cause of the issue, users should no longer experience unexpected session drops. We will be monitoring the situation for the next few hours.\nOct  5, 12:05 CEST\nInvestigating - We encountered issues related to user sessions, so users may experience that their session might be disconnected after a few minutes. We are currently investigating the issue and we will provide a new update in the next hour.",
          "link": "https://status.make.com/incidents/jjzrxzv3vfj5",
          "publishedOn": "2023-10-05T16:58:09.000Z",
          "wordCount": 3898,
          "title": "Session expiration issues",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    }
  ],
  "cliVersion": "1.15.1"
}