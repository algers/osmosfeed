{
  "sources": [
    {
      "title": "BookingSync.com news",
      "feedUrl": "https://changelog.bookingsync.com/rss",
      "siteUrl": "https://changelog.bookingsync.com",
      "articles": []
    },
    {
      "title": "Security Bulletins on Tailscale",
      "feedUrl": "https://tailscale.com/security-bulletins/index.xml",
      "siteUrl": "https://tailscale.com/security-bulletins/",
      "articles": []
    },
    {
      "title": "Airbnb API Status - Incident History",
      "feedUrl": "https://airbnbapi.statuspage.io/history.rss",
      "siteUrl": "https://airbnbapi.statuspage.io",
      "articles": [
        {
          "id": "https://airbnbapi.statuspage.io/incidents/kkvp54r30jdn",
          "author": null,
          "description": "Oct  4, 09:46 PDT\nResolved - This incident has been resolved.\nOct  3, 22:04 PDT\nMonitoring - There was an increased number of 500 errors on the GET Opportunities API endpoint. We've mitigated the issue and will continue to monitor it. The time window for these errors was between 9:00 PM and 9:50 PM (PDT) today (Oct 3, 2023)",
          "link": "https://airbnbapi.statuspage.io/incidents/kkvp54r30jdn",
          "publishedOn": "2023-10-04T16:46:35.000Z",
          "wordCount": 3872,
          "title": "500 Error on GET Opportunities API",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://airbnbapi.statuspage.io/incidents/rhkqlr25pfcs",
          "author": null,
          "description": "Oct  3, 10:21 PDT\nResolved - This incident has been resolved.\nOct  2, 10:44 PDT\nMonitoring - We're currently investigating an issue that's causing spikes in our delivery timelines for asynchronous webhook notifications. It began around 5PM PST on Friday, September 29, and briefly reoccured on both Saturday and Sunday afternoon. We've mitigated the issue for now, but will continue to monitor this over the next few days.",
          "link": "https://airbnbapi.statuspage.io/incidents/rhkqlr25pfcs",
          "publishedOn": "2023-10-03T17:21:45.000Z",
          "wordCount": 3875,
          "title": "Issue Delaying Webhook Deliveries",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://airbnbapi.statuspage.io/incidents/6zcksbcfmvsb",
          "author": null,
          "description": "Oct  3, 10:21 PDT\nResolved - This incident has been resolved.\nOct  2, 14:30 PDT\nMonitoring - There was an issue with the generation of Basic Auth headers for synchronous availability checks and asynchronous webhook notifications between 11:45 AM and 2:00 PM PDT today. This resulted in errors for both availability checks and webhooks.\nThe issue has been resolved, and our team will be monitoring any further errors.",
          "link": "https://airbnbapi.statuspage.io/incidents/6zcksbcfmvsb",
          "publishedOn": "2023-10-03T17:21:27.000Z",
          "wordCount": 3892,
          "title": "Basic Auth Errors for Synchronous Availability Checks and Webhook Notifications",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://airbnbapi.statuspage.io/incidents/7d87njvtk91g",
          "author": null,
          "description": "Oct  3, 10:20 PDT\nResolved - This incident has been resolved. Error rates have returned to normal levels. Please retry any failed requests.\nOct  2, 19:51 PDT\nMonitoring - We have mitigated the issue and will continue monitoring it. The time window for the errors was between 5:45 PM and 7:00 PM PDT.\nOct  2, 18:34 PDT\nInvestigating - We are currently investigating elevated error rates when processing the Async Calendars API update requests.",
          "link": "https://airbnbapi.statuspage.io/incidents/7d87njvtk91g",
          "publishedOn": "2023-10-03T17:20:56.000Z",
          "wordCount": 3895,
          "title": "Elevated Server Error Rates on Async Calendars API",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://airbnbapi.statuspage.io/incidents/lpxzhxccln48",
          "author": null,
          "description": "Sep 24, 20:22 PDT\nResolved - This incident has been resolved.\nError rates have returned to normal levels. Please retry any failed requests.\nWe apologize for the inconvenience caused and thank you for your patience and understanding.\nSep 22, 10:43 PDT\nMonitoring - The issue has been mitigated at 10:30AM PDT. Please apply any failed requests during the incident.\nSep 22, 10:10 PDT\nInvestigating - We are actively investigating an increased number of 500 errors across multiple endpoints. These errors started today (Sept 22, 2023) around 09:45 AM PDT. Our engineering teams are working to get everything up and running again and we will update you with the latest information as soon as possible.",
          "link": "https://airbnbapi.statuspage.io/incidents/lpxzhxccln48",
          "publishedOn": "2023-09-25T03:22:05.000Z",
          "wordCount": 3924,
          "title": "500 Errors Across Multiple Endpoints",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    },
    {
      "title": "Twilio Status - Incident History",
      "feedUrl": "https://status.twilio.com/history.rss",
      "siteUrl": "https://status.twilio.com",
      "articles": [
        {
          "id": "https://status.twilio.com/incidents/jbps1cfprl36",
          "author": null,
          "description": "THIS IS A SCHEDULED EVENT Oct 19, 03:00 - 07:00 PDT\nOct 16, 17:08 PDT\nScheduled - The AT&T network in Mexico is conducting an emergency maintenance from 19 October 2023 at 03:00 PDT until 19 October 2023 at 07:00 PDT. During the maintenance window, there could be intermittent delays delivering SMS to and from AT&T Mexico handsets.",
          "link": "https://status.twilio.com/incidents/jbps1cfprl36",
          "publishedOn": "2023-10-19T10:00:00.000Z",
          "wordCount": 7254,
          "title": "Mexico SMS Carrier Maintenance - AT&T",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/qk1bff2q95qb",
          "author": null,
          "description": "THIS IS A SCHEDULED EVENT Oct 18, 21:00 PDT  -  Oct 19, 03:00 PDT\nOct 17, 16:03 PDT\nScheduled - The Verizon network in the US is conducting an emergency maintenance from 18 October 2023 at 21:00 PDT until 19 October 2023 at 03:00 PDT. During the maintenance window, there could be intermittent delays delivering MMS to and from Verizon US handsets.",
          "link": "https://status.twilio.com/incidents/qk1bff2q95qb",
          "publishedOn": "2023-10-19T04:00:00.000Z",
          "wordCount": 7258,
          "title": "US MMS Carrier Maintenance - Verizon",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/864tcl9gd6v2",
          "author": null,
          "description": "THIS IS A SCHEDULED EVENT Oct 18, 20:30 PDT  -  Oct 19, 01:30 PDT\nOct 13, 15:33 PDT\nScheduled - A subset of small networks in the US are conducting a planned maintenance from 18 October 2023 at 20:30 PDT until 19 October 2023 at 01:30 PDT. During the maintenance window, there could be intermittent delays delivering SMS to and from small US carrier networks.",
          "link": "https://status.twilio.com/incidents/864tcl9gd6v2",
          "publishedOn": "2023-10-19T03:30:00.000Z",
          "wordCount": 7263,
          "title": "US SMS Carrier Maintenance - Small US Networks",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/kgnxwr0mzyf6",
          "author": null,
          "description": "THIS IS A SCHEDULED EVENT Oct 18, 20:00 - 21:00 PDT\nOct  2, 08:15 PDT\nScheduled - Our Voice carrier partner in France is conducting a planned maintenance from 18 October 2023 at 20:00 PDT until 18 October 2023 at 21:00 PDT. During the maintenance window, there could be intermittent call failures to and from a subset of Twilio's France phone numbers.",
          "link": "https://status.twilio.com/incidents/kgnxwr0mzyf6",
          "publishedOn": "2023-10-19T03:00:00.000Z",
          "wordCount": 7243,
          "title": "France Voice Carrier Partner Maintenance",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/n42p79dkwzjr",
          "author": null,
          "description": "Oct 18, 16:57 PDT\nResolved - We are no longer experiencing MMS/SMS delivery delays when sending messages to To Multiple Networks in US and Canada via subset Toll-free, Long code, and Short code. This incident has been resolved.\nOct 18, 16:03 PDT\nMonitoring - We are observing recovery in MMS/SMS delivery delays when sending messages to Multiple Networks in the US and Canada for a subset of Long Codes and Toll-Free Numbers. We will continue monitoring the service to ensure a full recovery. We will provide another update in 2 hours or as soon as more information becomes available.\nOct 18, 15:02 PDT\nUpdate - We are experiencing MMS/SMS delivery delays when sending messages to Multiple Networks in the US and Canada for a subset of Long Codes and Toll-Free Numbers. Our engineers are working with our carrier partners to resolve the issue. We will provide another update in 1 hour or as soon as more information becomes available.\nOct 18, 14:57 PDT\nInvestigating - Our monitoring systems have detected a potential issue SMS/MMS Delivery Delays To Multiple Networks in US and Canada via subset Toll-free, Long code, and Short code. Our engineering team has been alerted and is actively investigating. We will update as soon as we have more information.",
          "link": "https://status.twilio.com/incidents/n42p79dkwzjr",
          "publishedOn": "2023-10-18T23:57:48.000Z",
          "wordCount": 7467,
          "title": "SMS and MMS Delivery Delays to Multiple Networks in the US and Canada for a subset of Long Codes and Toll-Free Numbers",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/rllk1434ybb0",
          "author": null,
          "description": "Oct 18, 16:29 PDT\nResolved - After investigation with our carrier partner, we found that although the carrier partner did experience SMS delivery delays when sending messages to Jersey Telecom Network in Jersey, this had no impact on Twilio's customers. We have identified ways to further avoid any impact to customers. This incident has been resolved.\nOct 18, 16:01 PDT\nUpdate - We are continuing to experience SMS delivery delays when sending messages to Jersey Telecom Network in Jersey. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 8 hours or as soon as more information becomes available.\nOct 18, 12:01 PDT\nUpdate - We are continuing to experience SMS delivery delays when sending messages to Jersey Telecom Network in Jersey. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 4 hours or as soon as more information becomes available.\nOct 18, 10:05 PDT\nUpdate - We are continuing to experience SMS delivery delays when sending messages to Jersey Telecom Network in Jersey. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 2 hours or as soon as more information becomes available.\nOct 18, 09:01 PDT\nInvestigating - We are experiencing SMS delivery delays when sending messages to Jersey Telecom Network in Jersey. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 1 hour or as soon as more information becomes available.",
          "link": "https://status.twilio.com/incidents/rllk1434ybb0",
          "publishedOn": "2023-10-18T23:29:03.000Z",
          "wordCount": 7461,
          "title": "SMS Delivery Delays to Jersey Telecom Network in Jersey",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/3dfrvljdm4rp",
          "author": null,
          "description": "Oct 18, 16:24 PDT\nUpdate - We are continuing to investigate SMS delivery delays when sending messages to Millicom Network in Chad. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 4 hours or as soon as more information becomes available.\nOct 18, 14:34 PDT\nUpdate - We are continuing to investigate SMS delivery delays when sending messages to Millicom Network in Chad. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 2 hours or as soon as more information becomes available.\nOct 18, 13:34 PDT\nUpdate - We are experiencing SMS delivery delays when sending messages to Millicom Network in Chad. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 1 hour or as soon as more information becomes available.\nOct 18, 13:22 PDT\nUpdate - Our monitoring systems have detected a potential issue with SMS Delivery Delays to Millicom Network in Chad. Our engineering team has been alerted and is actively investigating. We will update as soon as we have more information.\nOct 18, 13:21 PDT\nInvestigating - Our monitoring systems have detected a potential issue {Product}. Our engineering team has been alerted and is actively investigating. We will update as soon as we have more information.",
          "link": "https://status.twilio.com/incidents/3dfrvljdm4rp",
          "publishedOn": "2023-10-18T23:24:53.000Z",
          "wordCount": 7433,
          "title": "SMS Delivery Delays to Millicom Network in Chad",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/66857rlpgvn7",
          "author": null,
          "description": "Oct 18, 13:01 PDT\nIn progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.\nOct 17, 06:31 PDT\nScheduled - The A1, MTS and Life networks in Belarus are conducting a planned maintenance from 18 October 2023 at 15:00 PDT until 18 October 2023 at 20:00 PDT. During the maintenance window, there could be intermittent delays delivering SMS to A1, MTS, Life Belarus handsets",
          "link": "https://status.twilio.com/incidents/66857rlpgvn7",
          "publishedOn": "2023-10-18T20:01:27.000Z",
          "wordCount": 7272,
          "title": "Belarus SMS Carrier Maintenance - A1, MTS and Life",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.twilio.com/incidents/4ztn267w6nln",
          "author": null,
          "description": "Oct 18, 07:25 PDT\nResolved - Usage and billing report issue have been resolved and Programmable Wireless and Super SIM are operating normally at this time.\nOct 18, 07:14 PDT\nUpdate - We are continuing to observe recovery with the multiple KORE systems impacting user experiences on the KORE Console, and Billing. The issue has no impact on connectivity. We will be monitoring all services to ensure a full recovery and provide another update in 30 minutes or as soon as more information becomes available.\nOct 18, 06:44 PDT\nUpdate - We are observing recovery with the multiple KORE systems impacting user experiences on the KORE Console, and Billing. The issue has no impact on connectivity. We will be monitoring all services to ensure a full recovery and provide another update in 30 minutes or as …",
          "link": "https://status.twilio.com/incidents/4ztn267w6nln",
          "publishedOn": "2023-10-18T14:25:36.000Z",
          "wordCount": 7957,
          "title": "Usage and Billing Report Delays for Super SIM and Programmable Wireless",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    },
    {
      "title": "DigitalOcean Status - Incident History",
      "feedUrl": "https://status.digitalocean.com/history.rss",
      "siteUrl": "http://status.digitalocean.com",
      "articles": [
        {
          "id": "https://status.digitalocean.com/incidents/f38zfs58jkl8",
          "author": null,
          "description": "Oct 17, 17:33 UTC\nResolved - As of 16:10 UTC, our Engineering team has confirmed the full resolution of the issue impacting our App platform service where users were not able to access their Apps via Cloud Panel. Apps should be loading fine https://cloud.digitalocean.com/apps without any errors. \nWe appreciate your patience during the process and if you continue to experience any issues  please open a ticket with our support team.\nOct 17, 16:51 UTC\nMonitoring - Our Engineering team has deployed a fix to resolve the ongoing issue with accessing Apps list via Cloud panel for our App platform service. As of 16:10 UTC the situation started to improve and the users should be able to access their apps via Cloud panel UI without any issues. \nWe are monitoring the situation closely and will post an update once the issue is completely resolved.\nOct 17, 16:19 UTC\nIdentified - Our Engineering team has identified an issue impacting App platform service in all regions. During this time users may experience issues while loading apps via https://cloud.digitalocean.com/apps and the requests appear to be timing out. New App deployments via API or doctl and the existing deployed apps are not impacted by this incident.  \nOur team is working to mitigate the issue and we will provide an update as soon as possible.",
          "link": "https://status.digitalocean.com/incidents/f38zfs58jkl8",
          "publishedOn": "2023-10-17T17:33:44.000Z",
          "wordCount": 6143,
          "title": "App Platform Accessibility via Cloud",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/7548dwrnthz8",
          "author": null,
          "description": "Oct 17, 06:48 UTC\nResolved - As of 06:25 UTC, our Engineering team has confirmed that the issue impacting the newly created Managed Database Clusters has been fully resolved. \nUsers will no longer experience issues with the newly created Managed Database Cluster.\nIf you continue to experience any issues with Managed Database Clusters please open a ticket with our support team. Thank you for your patience.\nOct 17, 06:24 UTC\nMonitoring - As of 06:15 UTC, our Engineering team has identified the issue impacting our Managed Database product and a fix has been implemented to mitigate the issue. Currently, new users may no longer experience issues with the newly created Managed Database Cluster due to hostname resolution.\nUsers who already have a Managed Database cluster are not impacted by this incident.\nThank you for your patience and we apologize for the inconvenience caused. We are monitoring the situation and will post an update once the incident is completely resolved.\nOct 17, 04:22 UTC\nInvestigating - Our Engineering team is currently investigating reports of issues impacting a subset of users using our Managed Database Clusters. \nDuring this time, hostnames for the newly created Managed Database Cluster are not resolving. However, previously created Clusters are not impacted due to the same.\nWe apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/7548dwrnthz8",
          "publishedOn": "2023-10-17T06:48:06.000Z",
          "wordCount": 6149,
          "title": "Managed Database Cluster",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/yxfmyjl0kmpr",
          "author": null,
          "description": "Oct 16, 23:14 UTC\nResolved - From 22:45 to 23:00 UTC, our Engineering team has reported an issue with DigitalOcean Control Panel and API.\n During that time, Customers may have experienced intermittent timeout errors while using DigitalOcean Control Panel and API. \nIf you continue to experience problems, please open a ticket with our support team. Thank you for your patience and we apologize for any inconvenience.",
          "link": "https://status.digitalocean.com/incidents/yxfmyjl0kmpr",
          "publishedOn": "2023-10-16T23:14:32.000Z",
          "wordCount": 5980,
          "title": "DigitalOcean Control Panel and API",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/k58m2k4qcchf",
          "author": null,
          "description": "Oct 15, 01:04 UTC\nResolved - Our Engineering team has confirmed the full resolution of the networking issue in the SFO regions. If you continue to see issues with latency or packet loss in the SFO region please reach out directly to our support team for assistance.\nOct 14, 20:30 UTC\nUpdate - Our Engineering team is continuing to monitor the networking issue in the SFO regions. So far, we haven't observed any major spike in latency or packet loss with network connections going in or out of the SFO regions. However, we will post an update as soon as the issue is fully resolved.\nWe apologize for the inconvenience and thank you for your patience and continued support.\nOct 14, 15:25 UTC\nMonitoring - Our Engineering team has detected a recurrence of the networking issue identified in a previous incident today: \nhttps://status.digitalocean.com/incidents/bhpslzd37517\nOur team is actively monitoring the situation and has implemented traffic routing changes where applicable to alleviate the latency. Some users may still experience packet loss or increased latency accessing the resources in the SFO region from certain ISPs.\nWe apologize for any inconvenience caused and will provide updates as the situation progresses.",
          "link": "https://status.digitalocean.com/incidents/k58m2k4qcchf",
          "publishedOn": "2023-10-15T01:04:23.000Z",
          "wordCount": 6118,
          "title": "Network Latency in SFO Region",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/bhpslzd37517",
          "author": null,
          "description": "Oct 14, 11:46 UTC\nResolved - Our Engineering team has confirmed full resolution of the issue with networking in affected regions. Users should no longer experience timeouts or delays when connecting to or from these regions. \nIf you continue to experience problems, please open a ticket with our support team.\nThank you for your patience and we apologize for any inconvenience.\nOct 14, 11:10 UTC\nMonitoring - As of 10:55 UTC, our Engineering team has implemented a fix to address the networking problem in the affected regions and is currently monitoring the situation. Users should no longer face timeouts or encounter delays when connecting to or from these regions. We will post an update as soon as the issue is fully resolved.\nOct 14, 10:30 UTC\nUpdate - As of 10:27 UTC, our Engineering team is continuing to investigate an issue with networking in our SFO regions. Additionally, it has come to our attention that this issue has affected other regions, specifically SGP1, SYD1, and NYC3. Users may encounter timeouts or experience delays in network connections going in and out of these regions. Our Engineers are actively working on isolating the root cause of the issue. While we don't have an exact timeframe for a resolution yet however we will be providing updates as developments occur.\nWe apologize for the inconvenience and thank you for your patience and continued support.\nOct 14, 09:47 UTC\nUpdate - We are continuing to investigate this issue.\nOct 14, 09:12 UTC\nInvestigating - As of 8:30 UTC, our Engineering team is investigating an issue with networking in our SFO regions. During this time, users may experience timeouts or latency with network connections going in or out of the SFO regions. We apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/bhpslzd37517",
          "publishedOn": "2023-10-14T11:46:50.000Z",
          "wordCount": 6231,
          "title": "Network Latency in Multiple Regions",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/lh3j71zp57hx",
          "author": null,
          "description": "Oct 12, 19:17 UTC\nResolved - Our Engineering team has confirmed the resolution of the issue that impacted the Spaces CDN. Objects should be accessible over the CDN endpoint without any issues. However, HTTP/2 is temporarily unavailable due to upstream issues, and due to this HTTP/2 requests should automatically be re-negotiated to 1.1, but in case you experience failures please open a ticket with our support team.\nThank you for your patience and we apologize for any inconvenience.\nOct 12, 16:10 UTC\nUpdate - After our upstream provider implemented a remediation step to resolve the issue with the Spaces CDN, the Spaces CDN is serving the objects stored in the Spaces bucket without any errors or performance issues. However, we are still monitoring the situation closely and we'll share more in…",
          "link": "https://status.digitalocean.com/incidents/lh3j71zp57hx",
          "publishedOn": "2023-10-12T19:17:29.000Z",
          "wordCount": 6454,
          "title": "Spaces CDN in Multiple Regions",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/fsfsv9fj43w7",
          "author": null,
          "description": "Oct 11, 07:26 UTC\nResolved - Our Engineering team has resolved the issue with the Managed Kubernetes Service. A daemonset has been released to all existing clusters eliminating the auto-update process and it will be removed again going forward. If you find worker nodes that could still be affected by a prior occurrence of this incident, please replace them for permanent mitigation.\nIf you continue to experience problems, please open a ticket with our support team. We apologize for any inconvenience.\nOct 11, 04:06 UTC\nMonitoring - Our Engineering team has completed the work for both items. New images have been released that eliminate the auto-update process and the daemonset has been applied to all existing clusters. \nGiven this, the team is not expecting to see a recurrence of this inciden…",
          "link": "https://status.digitalocean.com/incidents/fsfsv9fj43w7",
          "publishedOn": "2023-10-11T07:26:53.000Z",
          "wordCount": 7715,
          "title": "Managed Kubernetes Service",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/08q0d3g8dtp3",
          "author": null,
          "description": "Oct  7, 20:01 UTC\nResolved - As of 19:52 UTC, our Engineering team has confirmed the full resolution of the issue impacting the listing of Spaces buckets in the FRA1 region via the Cloud Control Panel. \nIf you continue to experience problems, please open a ticket with our support team. Thank you for your patience and we apologize for any inconvenience.\nOct  7, 19:38 UTC\nMonitoring - Our engineering team has implemented a fix to resolve the issue with listing Spaces in our FRA1 region via the Cloud Panel and is monitoring the situation. We will post an update as soon as the issue is fully resolved.\nOct  7, 19:15 UTC\nInvestigating - Our Engineering team is investigating an issue with Spaces in our FRA1 region. As of 13:40 UTC, users may experience issues listing the Spaces created in the FRA1 region via the Cloud Panel. We apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/08q0d3g8dtp3",
          "publishedOn": "2023-10-07T20:01:58.000Z",
          "wordCount": 6081,
          "title": "Spaces listing in FRA1",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/bm43bydmrmbl",
          "author": null,
          "description": "Oct  1, 18:39 UTC\nResolved - From 14:44 UTC to 18:04 UTC we experienced another issue with our App Platform service related to CDN Insights for Apps in all regions. During this window, users might have observed blank graphs or no data for the CDN metrics including request counts, cache hit rates etc. Our engineering team was able to identify the problem and resolve it fully and as of 18:04 UTC all the metrics are displaying properly. \nThe connectivity issue with the Apps for which we updated the status page earlier was only faced by a subset of users in FRA1 region, only between 12:45 UTC to 14:15 UTC. The normal functionality of apps was entirely restored around 14:15 UTC.\nThank you for your patience on this and if you continue to face issues then please open a support ticket from within the cloud control panel.",
          "link": "https://status.digitalocean.com/incidents/bm43bydmrmbl",
          "publishedOn": "2023-10-01T18:39:16.000Z",
          "wordCount": 6059,
          "title": "CDN Insights for App Platform",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/hzsrymxjyvys",
          "author": null,
          "description": "Oct  1, 15:24 UTC\nResolved - Between 12:45 UTC and 14:15 UTC, we experienced an issue impacting the App platform apps in the FRA1 region. During this time, a subset of users might have experienced degraded performance or errors while accessing their apps in the region.\nOur engineering team was able to take quick action to mitigate the impact and resolve the issue, and as of 14:15 UTC all services are now functioning normally. Thank you for your patience, and we apologize for any inconvenience. \nIf you continue to experience any issues, please open a Support ticket right away for further review.",
          "link": "https://status.digitalocean.com/incidents/hzsrymxjyvys",
          "publishedOn": "2023-10-01T15:24:05.000Z",
          "wordCount": 6012,
          "title": "App Platform in FRA1",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/vjypl8576bp3",
          "author": null,
          "description": "Sep 30, 14:08 UTC\nResolved - Our engineering team has resolved the issue impacting Spaces in our SGP1 region. From approximately 11:47 UTC - 13:35 UTC, users may have encountered errors with API or object requests, experienced difficulties in creating new buckets in SGP1, or faced issues with loading Spaces in the Cloud Control Panel. Spaces should now be operating normally. \nIf you continue to experience problems, please open a ticket with our support team. Thank you for your patience and we apologize for any inconvenience.\nSep 30, 13:51 UTC\nMonitoring - Our engineering team has implemented a fix to resolve the issue with Spaces in our SGP1 region and is monitoring the situation. We will post an update as soon as the issue is fully resolved.\nSep 30, 13:43 UTC\nIdentified - As of 13:31 UTC, our engineering team has identified the cause of the issue with Spaces availability in our SGP1 region and is actively working on a fix. We will post an update as soon as additional information is available.\nSep 30, 12:29 UTC\nInvestigating - Our Engineering team is investigating an issue with Spaces in our SGP1 region. As of 11:47 UTC, users may experience issues with accessing Spaces and see request errors. We apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/vjypl8576bp3",
          "publishedOn": "2023-09-30T14:08:21.000Z",
          "wordCount": 6141,
          "title": "Spaces in SGP1",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/5khjfm2dbz08",
          "author": null,
          "description": "Sep 29, 15:45 UTC\nResolved - As of 03:24 PM UTC, Our engineering team has resolved the issue impacting our App Platform builds. Everything should be functioning normally. We appreciate your patience throughout the process and if you continue to experience problems, please open a ticket with our support team for further review.\nSep 29, 14:21 UTC\nMonitoring - As of 02:18 PM UTC, our Engineering team has implemented a fix to resolve the issue impacting App platform builds. We are actively monitoring the situation to ensure stability and will provide an update once the incident has been fully resolved. Thank you for your patience and we apologize for the inconvenience.\nSep 29, 12:12 UTC\nInvestigating - As of 9:00UTC, our Engineering team is investigating an issue with slow App Platform builds across all regions. During this time users may encounter delays in app builds and could potentially experience timeout errors in builds as a result. We apologize for the inconvenience and will share an update once we have more information.",
          "link": "https://status.digitalocean.com/incidents/5khjfm2dbz08",
          "publishedOn": "2023-09-29T15:45:14.000Z",
          "wordCount": 6103,
          "title": "Slow App Platform Builds",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/7bjzfp9n2df6",
          "author": null,
          "description": "Sep 28, 19:29 UTC\nResolved - Our Engineering team has confirmed that the issue with Static Site components for the App Platform in our NYC3 region has been fully resolved.\nWe apologize for the inconvenience. If you continue to experience any issues related to this incident, please open a ticket with our support team from within your Cloud Control Panel.\nSep 28, 19:00 UTC\nMonitoring - Our Engineering team identified an issue with Static Site components for the App Platform in our NYC3 region. From 17:28 UTC to 18:45 UTC, some users experienced 404 errors for their static sites after deploying a new app, or after redeploying an existing app. \nA fix has now been implemented and all Apps should be functioning as expected. We're monitoring the situation and will post a final update once we confirm this is fully resolved.",
          "link": "https://status.digitalocean.com/incidents/7bjzfp9n2df6",
          "publishedOn": "2023-09-28T19:29:46.000Z",
          "wordCount": 6078,
          "title": "Static Site components for the App Platform in NYC3 region",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/ygpk1jjf2pb7",
          "author": null,
          "description": "Sep 27, 19:42 UTC\nResolved - From 17:37 - 18:30 UTC, Spaces bucket creation in our NYC3 region failed. \nOur Engineering team has confirmed full resolution of the issue and all services are now operating normally. If you continue to experience any issues, please open a Support ticket from within your account. Thank you.\nSep 27, 19:02 UTC\nMonitoring - Our Engineering team has completed a rollback of a recent change to resolve the issue with Spaces bucket creations in NYC3. Users should now be able to create buckets normally. \nWe are monitoring the situation and will post an update as soon as we confirm the issue is fully resolved.\nSep 27, 18:49 UTC\nIdentified - Our Engineering team has identified an issue with creating Spaces buckets in our NYC3 region and is currently working on a fix to mitigate the issue. At this time, users will see 500 errors when attempting to create buckets in NYC3. \nWe'll provide an update as soon as possible.",
          "link": "https://status.digitalocean.com/incidents/ygpk1jjf2pb7",
          "publishedOn": "2023-09-27T19:42:00.000Z",
          "wordCount": 6085,
          "title": "Spaces Creation in NYC3",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/s9wqn2fztjly",
          "author": null,
          "description": "Sep 27, 16:05 UTC\nResolved - Our Engineering team has confirmed full resolution of the issue with creating and deleting uptime checks. If you continue to face any errors, please open a support ticket from within your account. Thank you!\nSep 27, 15:33 UTC\nMonitoring - Our Engineering team identified the root cause of the issue with creating and deleting uptime checks and has implemented a fix. At this time, users should be able to create and delete checks normally. \nWe're monitoring the implemented fix and will post a final update once we confirm this issue is fully resolved.\nSep 27, 14:55 UTC\nInvestigating - Our Engineering team is investigating an issue with creating uptime checks. At this time, users may experience failures when creating or deleting checks. \nWe'll provide an update with further information as soon as possible.",
          "link": "https://status.digitalocean.com/incidents/s9wqn2fztjly",
          "publishedOn": "2023-09-27T16:05:43.000Z",
          "wordCount": 6062,
          "title": "Creation/Deletion of Uptime Checks (Monitoring)",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/4wyj77ll2bxl",
          "author": null,
          "description": "Sep 26, 23:45 UTC\nResolved - Our Engineering team has confirmed that the issue with our Container Registry services in the NYC3 region has been fully resolved. \nAll operations should now be operating normally with our Container Registry services. If you continue to experience any trouble with these services please open a ticket with our support team. \nThank you for your patience and we apologize for the inconvenience.\nSep 26, 17:15 UTC\nIdentified - While monitoring the implemented fix, our Engineering team identified additional customer impact and are working on an additional fix. At this time, users may still experience authorization issues and errors when interacting with registries.\nWe will provide an additional update as soon as we have more information.\nSep 26, 16:13 UTC\nMonitoring - …",
          "link": "https://status.digitalocean.com/incidents/4wyj77ll2bxl",
          "publishedOn": "2023-09-26T23:45:29.000Z",
          "wordCount": 6379,
          "title": "Container Registry in NYC3",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/nf42p0nw61c4",
          "author": null,
          "description": "Sep 23, 13:45 UTC\nResolved - Our engineering team has confirmed that the issues affecting the new signups have been fully resolved. We appreciate your patience throughout the process and if you continue to experience problems, please open a ticket with our support team for further review.\nSep 23, 09:53 UTC\nMonitoring - Our Engineering team has implemented a fix to resolve the issue impacting new account signups and monitoring the situation. We will post an update as soon as the issue is fully resolved.\nSep 23, 09:40 UTC\nIdentified - Our Engineering team has identified the issue impacting new account signups and is actively working on a fix. We will post an update as soon as additional information is available.\nSep 23, 09:13 UTC\nInvestigating - As of 08.45 UTC, our Engineering team is investigating an issue with new customer signups. During this time, some new customers are unable to finish the signup process, as the submit button for the initial questionnaire does not proceed further.\nWe apologize for the inconvenience and will provide an update as soon as possible.",
          "link": "https://status.digitalocean.com/incidents/nf42p0nw61c4",
          "publishedOn": "2023-09-23T13:45:35.000Z",
          "wordCount": 6100,
          "title": "New customer signups",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/99c30sdym613",
          "author": null,
          "description": "Sep 22, 18:32 UTC\nResolved - Our Engineering team has confirmed full resolution of the issue with creation of Managed Database clusters.\nIf you continue to experience problems, please open a ticket with our support team.\nSep 22, 17:58 UTC\nMonitoring - Our Engineering team is continuing to investigate the root cause of this incident, but creation of Managed Database clusters has remained stable. \nWe will continue to monitor this incident to ensure the issue does not recur and will provide an update when we have more information, or we are confident this is resolved. Thank you.\nSep 22, 17:04 UTC\nUpdate - Our Engineering team continues to investigate the root cause of this issue, but we are now seeing previously created clusters coming online and creations going through correctly. At this time, users should be able to access clusters previously stuck in the creation state and create new clusters.\nSep 22, 16:40 UTC\nInvestigating - Our Engineering team is investigating an issue with creation of Managed Database clusters not completing. At this time, users may see cluster creation for Postgres, MySQL, Redis, and Kafka clusters taking a long time and/or not completing. \nWe will provide another update as soon as we have further information.",
          "link": "https://status.digitalocean.com/incidents/99c30sdym613",
          "publishedOn": "2023-09-22T18:32:09.000Z",
          "wordCount": 6135,
          "title": "Managed Databases Creation",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/wnx731vkk630",
          "author": null,
          "description": "Sep 21, 12:59 UTC\nResolved - As of 12:46 UTC, our Engineering team confirmed that the mitigation applied has successfully resolved the issue impacting the App Platform in the FRA1 region. If you continue to experience problems, please open a ticket with our support team from within your Cloud Control Panel.\nThank you for your patience and we apologize for the inconvenience.\nSep 21, 12:52 UTC\nMonitoring - As of 12:30 UTC, our Engineering team has identified the issue impacting the App Platform in the FRA1 region and has put mitigations in place to fix the issue. We are actively monitoring the situation to ensure stability and will provide an update once the incident has been fully resolved. In the meantime, if you experience any issues with your APP, please redeploy the App.\nThank you for your patience and we apologize for the inconvenience.\nSep 21, 12:29 UTC\nInvestigating - As of 12:05 UTC, our Engineering team is investigating reports of an issue with our App Platform service in the FRA1 region. At this time the HTTP traffic to the existing Apps might be affected. Currently, traffic to two clusters in this region is closed. If your App resides in one of these clusters, we request you to redeploy the App so that it will land on a new cluster.\nWe will provide an update as soon as we have additional information.",
          "link": "https://status.digitalocean.com/incidents/wnx731vkk630",
          "publishedOn": "2023-09-21T12:59:45.000Z",
          "wordCount": 6159,
          "title": "HTTP traffic to App Platform in FRA1",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.digitalocean.com/incidents/p931kzltztmb",
          "author": null,
          "description": "Sep 21, 07:14 UTC\nResolved - From 04:30 - 05:10 UTC, our Engineering team observed an issue with network connectivity in the NYC region. During this time, users might have experienced high latency or errors while connecting to services, including Droplets and Droplet-based products like Managed Kubernetes, Managed Database, and App Platform Apps. \nAs of 05:10 UTC, the impact has been subsided and users should no longer be facing network connectivity issues. We apologize for the inconvenience and if you are still experiencing issues or have any additional questions then please open a support ticket from within your account.",
          "link": "https://status.digitalocean.com/incidents/p931kzltztmb",
          "publishedOn": "2023-09-21T07:14:44.000Z",
          "wordCount": 6037,
          "title": "Network Connectivity in NYC region",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    },
    {
      "title": "Notion Status - Incident History",
      "feedUrl": "https://status.notion.so/history.rss",
      "siteUrl": "https://status.notion.so",
      "articles": [
        {
          "id": "https://status.notion.so/incidents/d38fkw0dxb29",
          "author": null,
          "description": "Oct 17, 11:59 PDT\nResolved - Notification health should be back to normal. Engineering will continue to monitor system health.\nOct 17, 11:40 PDT\nInvestigating - We are experiencing service degradation related to notifications. Notifications may be delayed, and notification badge counts may not be accurate.",
          "link": "https://status.notion.so/incidents/d38fkw0dxb29",
          "publishedOn": "2023-10-17T18:59:19.000Z",
          "wordCount": 3365,
          "title": "Notion is experiencing service degradation related to notifications",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/55frj2c42yvq",
          "author": null,
          "description": "Oct 12, 11:14 PDT\nResolved - Users were unable to log in using the Notion mobile and desktop apps to enterprise workspaces requiring SAML SSO login. This issue is resolved now.\nOct 12, 11:10 PDT\nUpdate - We are experiencing an issue with SAML SSO login in the Notion mobile and desktop apps, and we are investigating the cause.\nOct 12, 11:05 PDT\nInvestigating - We are experiencing an issue with SAML SSO and we are investigating the cause.",
          "link": "https://status.notion.so/incidents/55frj2c42yvq",
          "publishedOn": "2023-10-12T18:14:45.000Z",
          "wordCount": 3403,
          "title": "Notion is experiencing an issue with SAML SSO login",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/18rxsrdk6zkz",
          "author": null,
          "description": "Oct  4, 10:52 PDT\nResolved - The issue has been resolved. Notion app and API performance is back to Normal.\nOct  4, 09:28 PDT\nMonitoring - We've rolling out a fix and will continue monitoring.\nOct  4, 09:04 PDT\nIdentified - We have implemented a fix and rolling out.\nOct  4, 08:32 PDT\nInvestigating - We are experiencing some performance degradation and are investigating the cause.",
          "link": "https://status.notion.so/incidents/18rxsrdk6zkz",
          "publishedOn": "2023-10-04T17:52:33.000Z",
          "wordCount": 3383,
          "title": "Notion is experiencing degraded performance",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/dknkp34qzxg0",
          "author": null,
          "description": "Oct  4, 06:49 PDT\nResolved - The issue has been resolved. Notion app and API performance is back to Normal.\nOct  4, 05:31 PDT\nMonitoring - We're rolling out a fix and will continue monitoring.\nOct  4, 05:12 PDT\nUpdate - We have implemented a fix and rolling out soon.\nOct  4, 04:58 PDT\nIdentified - We have identified the issue and are working on a fix.\nOct  4, 04:46 PDT\nInvestigating - We are experiencing some performance degradation and are investigating the cause.",
          "link": "https://status.notion.so/incidents/dknkp34qzxg0",
          "publishedOn": "2023-10-04T13:49:09.000Z",
          "wordCount": 3403,
          "title": "Notion is experiencing degraded performance",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/gxjt1jbwqs7m",
          "author": null,
          "description": "Oct  2, 17:13 PDT\nResolved - The issue has been resolved. Notion app and API performance is back to Normal.\nOct  2, 16:54 PDT\nIdentified - We are experiencing some performance degradation and are investigating the cause.",
          "link": "https://status.notion.so/incidents/gxjt1jbwqs7m",
          "publishedOn": "2023-10-03T00:13:08.000Z",
          "wordCount": 3350,
          "title": "Notion is experiencing degraded performance",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/b3g5shlj6hhl",
          "author": null,
          "description": "Oct  2, 16:03 PDT\nResolved - The issue has been resolved. Notion app and API performance is back to Normal.\nOct  2, 14:28 PDT\nUpdate - We're continuing to monitor the impact of the fix we implemented. We expect it may take a few hours to fully complete.\nOct  2, 13:54 PDT\nMonitoring - We're rolling out a fix and will continue monitoring.\nOct  2, 13:02 PDT\nUpdate - We have developed a fix and will be implementing soon.\nOct  2, 06:40 PDT\nIdentified - We have identified the issue and are working on a fix.\nOct  2, 06:24 PDT\nInvestigating - We are experiencing some performance degradation and are investigating the cause.",
          "link": "https://status.notion.so/incidents/b3g5shlj6hhl",
          "publishedOn": "2023-10-02T23:03:47.000Z",
          "wordCount": 3434,
          "title": "Notion is experiencing degraded performance",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/b782prxr5jw8",
          "author": null,
          "description": "Sep 29, 15:23 PDT\nResolved - The issue has been resolved.\nSep 29, 14:53 PDT\nMonitoring - We have rolled out a fix and are seeing error rates and latencies back to normal levels. We will continue to monitor before resolving.\nSep 29, 13:08 PDT\nUpdate - We are seeing reduced latencies and error rates, and continue our work to bring them down to normal levels.\nSep 29, 11:36 PDT\nIdentified - We have identified the issue and are working towards a fix.\nSep 29, 10:59 PDT\nInvestigating - We're seeing increased latency and some degraded performance with the public API. We've partially identified the issue, and are still investigating.",
          "link": "https://status.notion.so/incidents/b782prxr5jw8",
          "publishedOn": "2023-09-29T22:23:14.000Z",
          "wordCount": 3426,
          "title": "Degraded performance for public API",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/gg738l5v2yyn",
          "author": null,
          "description": "Sep 27, 16:20 PDT\nResolved - The issue has been resolved, and Notion is available for all users.\nSep 27, 15:39 PDT\nUpdate - Notion should be back online for most users; we are confirming.\nSep 27, 15:35 PDT\nUpdate - We are continuing to investigate this issue.\nSep 27, 15:14 PDT\nInvestigating - The Notion App and API are experiencing some degraded performance. We are currently investigating.",
          "link": "https://status.notion.so/incidents/gg738l5v2yyn",
          "publishedOn": "2023-09-27T23:20:28.000Z",
          "wordCount": 3388,
          "title": "Notion app & API are down",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/lmy95r4d97sq",
          "author": null,
          "description": "Sep 24, 18:04 PDT\nResolved - The issue has been resolved, and notion.so is available to all users.\nSep 24, 18:03 PDT\nUpdate - The issue has been resolved, and notion.so is available to all users.\nSep 24, 17:56 PDT\nInvestigating - Notion.so is currently down for some users. We are actively investigating.",
          "link": "https://status.notion.so/incidents/lmy95r4d97sq",
          "publishedOn": "2023-09-25T01:04:53.000Z",
          "wordCount": 3368,
          "title": "Sep 24 2023 Notion is down",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.notion.so/incidents/sj01vbq7vgb4",
          "author": null,
          "description": "Sep 20, 14:03 PDT\nResolved - This incident has been resolved. Users are not able to change their payment method.\nSep 20, 13:52 PDT\nIdentified - The issue has been identified and a fix is being implemented",
          "link": "https://status.notion.so/incidents/sj01vbq7vgb4",
          "publishedOn": "2023-09-20T21:03:28.000Z",
          "wordCount": 3356,
          "title": "Users are unable to change their payment method",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    },
    {
      "title": "Rippling Status - Incident History",
      "feedUrl": "https://status.rippling.com/history.rss",
      "siteUrl": "https://status.rippling.com",
      "articles": [
        {
          "id": "https://status.rippling.com/incidents/hqbr4jpwf48y",
          "author": null,
          "description": "Sep 27, 19:48 UTC\nResolved - This incident has been resolved.\nSep 27, 19:29 UTC\nMonitoring - A fix has been implemented and we are monitoring the results.\nSep 27, 18:31 UTC\nInvestigating - We are currently investigating this issue.",
          "link": "https://status.rippling.com/incidents/hqbr4jpwf48y",
          "publishedOn": "2023-09-27T19:48:47.000Z",
          "wordCount": 5042,
          "title": "macOS Sonoma update is shown as a minor update in Rippling",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/248858/rippling_favicoon.png"
        },
        {
          "id": "https://status.rippling.com/incidents/262wf83cx2t3",
          "author": null,
          "description": "Sep 21, 17:04 UTC\nResolved - This incident has been resolved.\nSep 21, 14:11 UTC\nUpdate - We are continuing to monitor for any further issues.\nSep 21, 13:54 UTC\nMonitoring - A fix has been implemented and we are monitoring the results.\nSep 21, 13:26 UTC\nIdentified - The issue has been identified and a fix is being implemented.\nSep 21, 13:22 UTC\nInvestigating - Users asked to complete an MFA challenge are unable to advance past the page. We are investigating this issue",
          "link": "https://status.rippling.com/incidents/262wf83cx2t3",
          "publishedOn": "2023-09-21T17:04:12.000Z",
          "wordCount": 5072,
          "title": "Issues completing an MFA authentication challenge",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/248858/rippling_favicoon.png"
        }
      ]
    },
    {
      "title": "Google Workspace Status Dashboard Updates",
      "feedUrl": "https://www.google.com/appsstatus/dashboard/en/feed.atom",
      "siteUrl": "https://www.google.com/appsstatus/dashboard/",
      "articles": [
        {
          "id": "https://www.google.com/appsstatus/dashboard/incidents/BhdnzdJaE1T5JstM2CjM",
          "author": null,
          "description": "<p> Incident began at <strong>2023-09-28 07:00</strong> and ended at <strong>2023-10-04 18:22</strong> <span>(times are in <strong>Coordinated Universal Time (UTC)</strong>).</span></p><div class=\"cBIRi14aVDP__status-update-text\"><h1>Mini Incident Report</h1>\n<p>We apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced an impact outside of what is listed below, please reach out to Google Workspace Support using the help article <a href=\"https://support.google.com/a/answer/1047213\">https://support.google.com/a/answer/1047213</a>.</p>\n<p>(All Times US/Pacific)</p>\n<p><strong>Incident Start:</strong> 28 Sept 2023 00:00</p>\n<p><strong>Incident End:</strong> 4 Oct 2023 11:22</p>\n<p><strong>Duration:</strong>  6 days, 11 hours, 22 minutes</p>\n<p><strong>Affected Services and Features:</strong></p>\n<p>Google Keep - Email notifications</p>\n<p><strong>Regions/Zones:</strong> Global</p>\n<p><strong>Description:</strong></p>\n<p>Google Keep experienced an issue where notification emails about note sharing ended up in the receiver&#39;s Spam folder for a duration of 6 days, 11 hours and 22 minutes. From preliminary analysis, the root cause is an unexpected increase in notifications.</p>\n<p><strong>Customer Impact:</strong></p>\n<p>Google Keep users incorrectly received email notifications in their spam folder.</p>\n</div><hr><p>Affected products: Google Keep</p>",
          "link": "https://www.google.com/appsstatus/dashboard/incidents/BhdnzdJaE1T5JstM2CjM",
          "publishedOn": "2023-10-09T11:49:19.000Z",
          "wordCount": 656,
          "title": "RESOLVED: **Summary**\nGoogle Keep users are experiencing issues with notification emails when a note is shared.\n**Description:**\nWe are experiencing an issue with Google Keep beginning on Wednesday, 2023-09-27. Mitigation work is underway by our engineering team. We do not have an ETA for mitigation at this point. We will provide more information by Wednesday, 2023-10-04 10:00 US/Pacific.\n**Diagnosis**\nGoogle Keep users are experiencing an issue where notification emails about note sharing are ending up in receiver's Spam folder\n**Workaround**\nNone at this time",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "GitHub Status - Incident History",
      "feedUrl": "https://www.githubstatus.com/history.rss",
      "siteUrl": "https://www.githubstatus.com",
      "articles": [
        {
          "id": "https://www.githubstatus.com/incidents/gkrfrz6r7flc",
          "author": null,
          "description": "Oct 17, 13:49 UTC\nResolved - This incident has been resolved.\nOct 17, 13:46 UTC\nUpdate - Codespaces is experiencing degraded performance. We are continuing to investigate.\nOct 17, 13:24 UTC\nUpdate - We are continuing with efforts to mitigate Codespaces issues   and are beginning to see some Codespace creations succeed.\nOct 17, 12:18 UTC\nUpdate - We have identified an issue impacting most Codespaces operations and are working on a mitigation.\nOct 17, 11:18 UTC\nUpdate - Codespaces is experiencing degraded availability. We are continuing to investigate.\nOct 17, 11:14 UTC\nInvestigating - We are investigating reports of degraded performance for Codespaces",
          "link": "https://www.githubstatus.com/incidents/gkrfrz6r7flc",
          "publishedOn": "2023-10-17T13:49:00.000Z",
          "wordCount": 5089,
          "title": "Incident with Codespaces",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/gtsz1l2jc96n",
          "author": null,
          "description": "Oct  9, 15:18 UTC\nResolved - On October 9, 2023 at 14:24 UTC, a noticeable delay in commits appearing in pull requests was detected.  During the incident, approximately 9% of pull requests (less than the 20% first reported) experienced staleness of up to 7m. The root cause was identified to be an increase in the latency of a downstream dependency causing pull request workers to saturate their available capacity, resulting in delayed updates to PRs - no data was lost during this incident.\n\tWe mitigated this by adding additional capacity to the affected worker pool at 15:02 UTC. This allowed our background jobs to catch up with the backlog of updates and provide relief to our customers. Additionally, we have significantly increased the performance of the downstream service to prevent recurrence\nOct  9, 14:52 UTC\nUpdate - We are investigating delays for commits showing up on Pull Requests page loads in the web UI. As a result of this,  about 20% of pull requests are currently showing stale data of up-to 7m. We are currently investigating contributing factors right now.\nOct  9, 14:51 UTC\nInvestigating - We are investigating reports of degraded performance for Pull Requests",
          "link": "https://www.githubstatus.com/incidents/gtsz1l2jc96n",
          "publishedOn": "2023-10-09T15:18:49.000Z",
          "wordCount": 5180,
          "title": "Incident with Pull Requests",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/w554d74dv18j",
          "author": null,
          "description": "Oct  6, 02:59 UTC\nResolved - We deployed a new configuration to improve our network availability. This resulted in a small percentage of user traffic getting incorrectly blocked, but missed by our automated detections. We mitigated this with a change to the configuration, rolled out slowly over the last hour of this incident time for safe deployment. Beyond the learnings related to the config, we are analyzing how we can more quickly detect this kind of impact as part of future configuration rollouts.\nOct  6, 02:42 UTC\nUpdate - We have confirmed that the fix has resolved the issue in the subset of regions where it has been deployed. We are now continuing the deployment to the remaining regions.\nOct  6, 02:03 UTC\nUpdate - We are monitoring the rollout of the fix and are beginning to see signs of improvement. We will send another update shortly.\nOct  6, 01:31 UTC\nUpdate - A small number of customers are experiencing 403 errors when attempting to access repository data via the API. We have found what we believe to be the cause of the issue and are deploying a fix.\nOct  6, 01:12 UTC\nInvestigating - We are investigating reports of degraded performance for API Requests",
          "link": "https://www.githubstatus.com/incidents/w554d74dv18j",
          "publishedOn": "2023-10-06T02:59:36.000Z",
          "wordCount": 5193,
          "title": "Incident with API Requests",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/9fk4c2w43clz",
          "author": null,
          "description": "Oct  5, 16:42 UTC\nResolved - On October 5, 2023 at 13:40 UTC, our monitoring systems observed an increase in the time it was taking for Git pushes to become visible when viewing commits in Pull Requests. Under normal operating conditions, a series of asynchronous jobs runs in response to every push and within a few seconds applies a number of side-effects in Pull Requests such as requesting reviews, marking Pull Requests as merged, and showing new commits. During the incident, jobs were entering the queue faster than we could process them, resulting in processing delays as high as 75 seconds on average, and as much as 15 minutes in the worst case. About 10% of all Pull Request page loads were showing out-of-date data during this time.\nWe had recently created a dedicated worker pool for pro…",
          "link": "https://www.githubstatus.com/incidents/9fk4c2w43clz",
          "publishedOn": "2023-10-05T16:42:15.000Z",
          "wordCount": 5358,
          "title": "Incident with Pull Requests",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/tpykx175y6jt",
          "author": null,
          "description": "Sep 27, 00:58 UTC\nResolved - On September 27, 2023 at 00:12 UTC, our alerting systems detected an increase in the time it took GitHub Actions workflow runs to start. During the incident, some customers experienced delays in starting Github Actions workflow runs and receiving status updates for in-progress runs. The root cause was identified to be a change that was deployed to an internal distributed event streaming platform which resulted in several worker nodes to go over a misconfigured memory limit. This caused these nodes to restart leading to a reduced job processing throughput. Github Actions relies on events delivered through this event streaming platform to start workflow runs and update their status. Delays in receiving these events led to run delays for about 40% of the Actions workflows.\n\tWe mitigated this through a rollback of the offending change at 00:18 UTC. This allowed our event streaming platform to catch up with the backlog of workflow runs that were queued during the incident. The backlog was processed by 00:44 UTC. We have additional repair items in place to prevent a recurrence in the future.\nSep 27, 00:23 UTC\nInvestigating - We are investigating reports of degraded performance for Actions",
          "link": "https://www.githubstatus.com/incidents/tpykx175y6jt",
          "publishedOn": "2023-09-27T00:58:42.000Z",
          "wordCount": 5178,
          "title": "Incident with Actions",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/4ypqyv8zbrck",
          "author": null,
          "description": "Sep 22, 17:39 UTC\nResolved - This incident has been resolved.\nSep 22, 17:27 UTC\nUpdate - We have identified the issue with Pages deploys and are actively working to mitigate the issue.\nSep 22, 17:10 UTC\nInvestigating - We are investigating reports of degraded performance for Pages",
          "link": "https://www.githubstatus.com/incidents/4ypqyv8zbrck",
          "publishedOn": "2023-09-22T17:39:54.000Z",
          "wordCount": 5028,
          "title": "Incident with Pages",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/c85syxc7gnbx",
          "author": null,
          "description": "Sep 20, 21:05 UTC\nResolved - This incident has been resolved.\nSep 20, 21:05 UTC\nUpdate - Creates and resumes in US West are working normally\nSep 20, 20:47 UTC\nUpdate - Codespace resumes in US West are currently impacted. New Codespaces are working normally.\nSep 20, 20:21 UTC\nInvestigating - We are investigating reports of degraded performance for Codespaces",
          "link": "https://www.githubstatus.com/incidents/c85syxc7gnbx",
          "publishedOn": "2023-09-20T21:05:57.000Z",
          "wordCount": 5042,
          "title": "Incident with Codespaces",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/ctr28sphxc4c",
          "author": null,
          "description": "Sep 20, 09:33 UTC\nResolved - This incident has been resolved.\nSep 20, 09:31 UTC\nUpdate - We have mitigated the Actions notifications and the service is recovering.\nSep 20, 09:21 UTC\nUpdate - Actions notifications are experiencing degraded performance. We are currently investigating.\nSep 20, 09:20 UTC\nInvestigating - We are investigating reports of degraded performance for Actions",
          "link": "https://www.githubstatus.com/incidents/ctr28sphxc4c",
          "publishedOn": "2023-09-20T09:33:57.000Z",
          "wordCount": 5041,
          "title": "Incident with Actions",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/zjchv3zvfg50",
          "author": null,
          "description": "Sep 20, 04:28 UTC\nResolved - On 2023-09-19 at 20:36 UTC, while migrating the primary datastore for Projects, we caused an outage that led to Projects data becoming unavailable for approximately four hours. \nWhile working to restore Projects data, we also experienced a data replication interruption which affected Git Operations, APIs, and Issues. We first resolved the data replication issue, which returned Git Operations, APIs, and Issues to normal operation. We then restored Projects data to its pre-migration state, and re-inserted data that was added during the period of partial availability. The incident was resolved on 2023-09-20 at 00:06 UTC.\nAs a result of this incident, we have improved validation of data migrations in test and during rollout.  We have also identified improvements to…",
          "link": "https://www.githubstatus.com/incidents/zjchv3zvfg50",
          "publishedOn": "2023-09-20T04:28:09.000Z",
          "wordCount": 5657,
          "title": "Incident with Issues, API Requests and Git Operations",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        },
        {
          "id": "https://www.githubstatus.com/incidents/00lscqwb6ht5",
          "author": null,
          "description": "Sep 19, 14:04 UTC\nResolved - This incident has been resolved.\nSep 19, 13:53 UTC\nUpdate - Pull Requests is operating normally.\nSep 19, 13:52 UTC\nUpdate - Push event processing has caught up and there should be no further delays experienced for pull request updates. There will be a tail of delayed notifications being delivered as part of the recovery, and we expect this to be fully caught up in the near future.\nSep 19, 13:29 UTC\nUpdate - We are experiencing a delay in processing for repository push events, which may result in delayed updates to pull requests. We have identified the issue and are seeing recovery, and will provide another update shortly.\nSep 19, 13:21 UTC\nInvestigating - We are investigating reports of degraded performance for Pull Requests",
          "link": "https://www.githubstatus.com/incidents/00lscqwb6ht5",
          "publishedOn": "2023-09-19T14:04:05.000Z",
          "wordCount": 5119,
          "title": "Incident with Pull Requests",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/pages-twitter_logos/original/36420/GitHub-Mark-120px-plus.png"
        }
      ]
    },
    {
      "title": "Slack System Status",
      "feedUrl": "https://status.slack.com/feed/rss",
      "siteUrl": "https://status.slack.com/",
      "articles": [
        {
          "id": "https://status.slack.com//2023-10/ad8f0e62516e8812",
          "author": null,
          "description": "Issue summary:\n\r\n\r\nOn Friday, October 6 2023, from 1:52 AM PDT to 2:12 AM PDT, some users were unable to load Slack. This was caused by an issue where certain backend Slack processes were pulling data from our database rather than their cache which caused strain on our servers.\n\r\n\r\nWe rolled out a change to how these processes load data, and the issue was resolved for all users.",
          "link": "https://status.slack.com//2023-10/ad8f0e62516e8812",
          "publishedOn": "2023-10-06T15:28:47.000Z",
          "wordCount": 232,
          "title": "Outage: Users are having trouble connecting to Slack",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-10/6d592537eb7bd98e",
          "author": null,
          "description": "Issue Summary:\n\r\n\r\nOn Oct 4, 2023 from 11:15 PM PDT to around 11:58 PM PDT a small subset of users experienced trouble connecting to Slack and sending and receiving messages.\n\r\n\r\nA code change optimizing resource usage caused a core service to restart causing brief connectivity issues for a few users.\n\r\n\r\nThe service recovered automatically and we’ve put measures in place to prevent this from happening in the future.",
          "link": "https://status.slack.com//2023-10/6d592537eb7bd98e",
          "publishedOn": "2023-10-05T13:53:12.000Z",
          "wordCount": 160,
          "title": "Incident: Trouble connecting to Slack",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-10/ee32d13012fb29d5",
          "author": null,
          "description": "Issue Summary:\n\r\n\r\nOn October 3, 2023 from 4:00 PM PDT to 4:20 PM PDT, some customers had trouble loading threads, mentions, reactions and search results in Slack.\n\r\n\r\nWe determined that this was caused during the process of changing our database hosts on our backend. To mitigate the issue, we stopped the change which fixed the issue for affected customers.\n\r\n\r\nWe're sorry for any disruption this may have caused and thank you for your patience while we looked into this",
          "link": "https://status.slack.com//2023-10/ee32d13012fb29d5",
          "publishedOn": "2023-10-04T18:53:01.000Z",
          "wordCount": 229,
          "title": "Incident: Issues with loading some items on Slack",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-10/101eb09455dcaa9a",
          "author": null,
          "description": "Issue Summary:\n\r\n\r\nOn October 2, 2023 from 12:18PM PDT to 12:26PM PDT, some users noticed that threads were not loading correctly.\n\r\n\r\nWe identified a database issue on our backend that was causing the threads to not load. The issue was mitigated and users should no longer experience trouble loading threads.\n\r\n\r\nWe are investigating the cause of the database issue so we can ensure this does not happen again.\n\r\n\r\nWe apologize for any interruption to your work day!",
          "link": "https://status.slack.com//2023-10/101eb09455dcaa9a",
          "publishedOn": "2023-10-02T20:16:28.000Z",
          "wordCount": 109,
          "title": "Incident: Threads were not loading for some users",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-09/7e84b360042dd07b",
          "author": null,
          "description": "Issue summary:\n\r\nOn September 28, 2023 from approximately 11:54 AM PDT to 3:15 PM PDT, some Slack users experienced trouble receiving two-factor authentication (2FA) codes and therefore were unable to sign into Slack.\n\r\n\r\nWe determined this was caused by an upstream 2FA provider issue impacting code deliveries to US-based AT&T and Verizon devices. We monitored communications from the provider and confirmed Slack users could successfully sign in once the upstream issue was resolved.",
          "link": "https://status.slack.com//2023-09/7e84b360042dd07b",
          "publishedOn": "2023-09-29T22:55:29.000Z",
          "wordCount": 242,
          "title": "Incident: Issues with receiving 2FA code",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-09/94046787b0ca9008",
          "author": null,
          "description": "Issue summary:\n\r\nFrom 8:00 AM PDT to 11:00 AM PDT on Thursday, September 28, 2023, a small number of users experienced delays in Slack, including sending and editing messages, and loading channels.\n\r\n\r\nUpon investigation, we determined that a specific task in our backend was producing too many file deletion events and overloading our servers, resulting in these delays.\n\r\n\r\nWe implemented a fix to reduce the load on our servers and this resolved the issue for all affected users.",
          "link": "https://status.slack.com//2023-09/94046787b0ca9008",
          "publishedOn": "2023-09-29T00:49:59.000Z",
          "wordCount": 265,
          "title": "Incident: A small number of users experience latency with Slack",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-09/054c6ac24cb629dd",
          "author": null,
          "description": "Issue summary:\n\r\nOn September 27, 2023 from 9:01 AM PDT to 12:32 PM PDT, some users experienced issues when attempting to create or edit custom apps on https://api.slack.com/apps, including seeing a \"404 error\" on this website.\n\r\n\r\nWe traced this back to a recent change that removed a function necessary for rendering a documentation page associated with the website. \n\r\n\r\nWe reverted the change, restoring the documentation page rendering component on https://api.slack.com/apps. Users should no longer have issues creating or editing custom apps and accessing this website.\n\r\n\r\nNote: Due to an internal tooling error, we initially reported the times in this summary in UTC, but labeled with PDT. We have corrected this mistake and apologize for any confusion caused.",
          "link": "https://status.slack.com//2023-09/054c6ac24cb629dd",
          "publishedOn": "2023-09-28T21:54:37.000Z",
          "wordCount": 200,
          "title": "Incident: Create app on api.slack.com/apps not working",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-09/badc5543a21e1fa7",
          "author": null,
          "description": "Issue summary:\n\r\nOn September 26, 2023 from 10:00 AM PDT to 12:00 PM PDT, some users on our new interface design couldn't dismiss an information prompt that read \"You now have Later\". \n\r\n\r\nThese users also experienced their UI locking, and were unable to click anything in the Slack app. For some, the sparkle animation fixed over the Later icon in the sidebar also persisted longer than intended. \n\r\n\r\nWe identified the root cause as a missing detail in a recent code change. We reverted the change to mitigate the immediate issue, then deployed a fix to fully resolve the problem for all impacted users.\n\r\n\r\nNote: Due to an internal tooling error, we initially reported the times in this summary in UTC, but labeled with PDT. We have corrected this mistake and apologize for any confusion caused.",
          "link": "https://status.slack.com//2023-09/badc5543a21e1fa7",
          "publishedOn": "2023-09-27T17:24:03.000Z",
          "wordCount": 404,
          "title": "Incident: Can't dismiss Now you've got Later",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-09/8315491ac04ad325",
          "author": null,
          "description": "Issue summary: \n\r\nFrom 12:54 PM PDT on September 22, 2023 to 09:13 AM PDT on September 25, 2023, custom emoji rendered as text for a small number of Enterprise Grid users.\n\r\n\r\nWe made a code change that inadvertently introduced unnecessary logging for routine emoji events. This unexpected logging increased traffic to the custom emoji infrastructure, impacting its performance. \n\r\n\r\nWe deployed a fix to remove the unnecessary logging, which reduced traffic to the custom emoji systems and restored normal emoji rendering. \n\r\n\r\nA small fraction of the affected customers may have experienced lingering issues as the fix was gradually rolled out to everyone.\n\r\n\r\nNote: Due to an internal tooling error, we initially reported the times in this summary in UTC, but labeled with PDT. We have corrected this mistake and apologize for any confusion caused.",
          "link": "https://status.slack.com//2023-09/8315491ac04ad325",
          "publishedOn": "2023-09-26T20:28:49.000Z",
          "wordCount": 468,
          "title": "Incident: Trouble with custom emoji",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        },
        {
          "id": "https://status.slack.com//2023-09/798ffab066d9a5d6",
          "author": null,
          "description": "Issue summary:\n\r\nOn September 21, 2023 from 8:00 PM PDT to 1:30 PM PDT, some users encountered a message stating \"Something went wrong\" when accessing the Slack Connect invites page.\n\r\n\r\nWe determined that rate limits set for querying invites were the cause of the \"Something went wrong\" message. These limits were set prior to the  product decision to include these in the Activity view. Because use of this view has increased, the limits are reached much sooner than originally expected.\n\r\n\r\nThese limits were lifted for the invites page, resolving the issue for users. We appreciate your patience while we sorted this out and apologize for any inconvenience this may have caused.\n\r\n\r\nNote: Due to an internal tooling error, we initially reported the times in this summary in UTC, but labeled with PDT. We have corrected this mistake and apologize for any confusion caused.",
          "link": "https://status.slack.com//2023-09/798ffab066d9a5d6",
          "publishedOn": "2023-09-22T17:48:18.000Z",
          "wordCount": 232,
          "title": "Incident: Slack Connect invitations page not loading",
          "imageUrl": "https://status.slack.com/img/v2_rebrand/slack_hash_256.png"
        }
      ]
    },
    {
      "title": "Make Status - Incident History",
      "feedUrl": "https://status.make.com/history.rss",
      "siteUrl": "https://status.make.com",
      "articles": [
        {
          "id": "https://status.make.com/incidents/2c52p236t4rp",
          "author": null,
          "description": "Oct 12, 17:40 CEST\nResolved - This incident has been resolved.\nOct 12, 16:21 CEST\nMonitoring - We implemented workaround and we are currently monitoring the issue.\nOct 12, 16:09 CEST\nInvestigating - We are experiencing issues within our scenario features i.e. users cannot clone scenario nor move it to a folder inside list of scenarios. This is still possible when user open particular scenario.\nWe are currently working on implementing a quick workaround, we should publish the relevant steps within the next 30 minutes.",
          "link": "https://status.make.com/incidents/2c52p236t4rp",
          "publishedOn": "2023-10-12T15:40:47.000Z",
          "wordCount": 3903,
          "title": "Users cannot clone nor move scenarios",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.make.com/incidents/jjzrxzv3vfj5",
          "author": null,
          "description": "Oct  5, 18:58 CEST\nResolved - This incident has been resolved.\nOct  5, 13:23 CEST\nMonitoring - We have identified that cause of the issue, users should no longer experience unexpected session drops. We will be monitoring the situation for the next few hours.\nOct  5, 12:05 CEST\nInvestigating - We encountered issues related to user sessions, so users may experience that their session might be disconnected after a few minutes. We are currently investigating the issue and we will provide a new update in the next hour.",
          "link": "https://status.make.com/incidents/jjzrxzv3vfj5",
          "publishedOn": "2023-10-05T16:58:09.000Z",
          "wordCount": 3898,
          "title": "Session expiration issues",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        },
        {
          "id": "https://status.make.com/incidents/5r55sspmpx14",
          "author": null,
          "description": "Sep 25, 14:26 CEST\nResolved - This incident has been resolved.\nSep 21, 18:13 CEST\nMonitoring - We have now contacted all customers that were affected by the Data Store issue. We will continue working with them directly to fix any discrepancies that have arisen in their Data Stores. If we have not contacted you, you were not impacted by the issue.\nSep 20, 18:40 CEST\nUpdate - We have now completed our investigation and identified that the issue affected a small percentage of Make users and their organizations. We are preparing to update all impacted customers with information about the scenarios and particular executions that may have produced incorrect data in the Data Store. We expect to update all impacted customers in the next 24 hours.\nSep 20, 14:50 CEST\nUpdate - We have confirmed that …",
          "link": "https://status.make.com/incidents/5r55sspmpx14",
          "publishedOn": "2023-09-25T12:26:20.000Z",
          "wordCount": 4212,
          "title": "Data Store application Issue",
          "imageUrl": "https://dka575ofm4ao0.cloudfront.net/assets/logos/favicon-2b86ed00cfa6258307d4a3d0c482fd733c7973f82de213143b24fc062c540367.png"
        }
      ]
    }
  ],
  "cliVersion": "1.15.1"
}