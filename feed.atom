<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>urn:2023-06-23T00:27:56.390Z</id>
    <title>osmos::feed</title>
    <updated>2023-06-23T00:27:56.390Z</updated>
    <generator>osmosfeed 1.15.1</generator>
    <link rel="alternate" href="index.html"/>
    <entry>
        <title type="html"><![CDATA[Mexico SMS Carrier Maintenance - AT&T Mexico]]></title>
        <id>https://status.twilio.com/incidents/vn2c1vhp9t19</id>
        <link href="https://status.twilio.com/incidents/vn2c1vhp9t19"/>
        <updated>2023-06-23T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[THIS IS A SCHEDULED EVENT Jun 22, 23:00 PDT  -  Jun 23, 05:00 PDT
Jun 21, 01:15 PDT
Scheduled - The AT&T network in Mexico is conducting a planned maintenance from 22 June 2023 at 23:00 PDT until 23 June 2023 at 05:00 PDT. During the maintenance window, there could be intermittent delays delivering SMS to and from AT&T Mexico handsets.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mexico SMS Carrier Maintenance - Telcel]]></title>
        <id>https://status.twilio.com/incidents/6y0bbhfqbwhq</id>
        <link href="https://status.twilio.com/incidents/6y0bbhfqbwhq"/>
        <updated>2023-06-23T04:00:00.000Z</updated>
        <summary type="html"><![CDATA[THIS IS A SCHEDULED EVENT Jun 22, 21:00 - 23:00 PDT
Jun 19, 11:02 PDT
Scheduled - The Telcel network in Mexico is conducting a planned maintenance from 22 June 2023 at 21:00 PDT until 22 June 2023 at 23:00 PDT. During the maintenance window, there could be intermittent delays delivering SMS to and from Telcel Mexico handsets]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[United States Account Security Carrier Partner Maintenance]]></title>
        <id>https://status.twilio.com/incidents/8jjrzrx3dqv2</id>
        <link href="https://status.twilio.com/incidents/8jjrzrx3dqv2"/>
        <updated>2023-06-23T02:00:00.000Z</updated>
        <summary type="html"><![CDATA[THIS IS A SCHEDULED EVENT Jun 22, 19:00 - 23:00 PDT
Jun 22, 08:05 PDT
Scheduled - Our Carrier Partner Verizon Wireless US is conducting an emergency maintenance from 22 June 2023 at 19:00 PDT until 22 June 2023 at 23:00 PDT. During the maintenance window, there could be intermittent API request failures for Verizon Wireless US customers.
Impacted Products: SNA, Lookup SIM Swap and Identity Match.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Flex Queue Stats Not Refreshing Properly]]></title>
        <id>https://status.twilio.com/incidents/snxz0bj2fw50</id>
        <link href="https://status.twilio.com/incidents/snxz0bj2fw50"/>
        <updated>2023-06-23T00:12:00.000Z</updated>
        <summary type="html"><![CDATA[Jun 22, 17:12 PDT
Identified - Our engineers have identified the issue causing the Flex Queue Stats to not refresh properly, and have deployed a fix. New task queues will now report correct statistics. However, task queues that were already affected may continue to show incorrect statistics. Our engineering team is actively working to fix the corrupted data. We expect to provide another update in 4 hours or as soon as more information becomes available.
Jun 22, 14:34 PDT
Update - We are still investigating an issue with Flex Queue Stats. The Waiting Task counter is not refreshing properly, therefore, customers may experience piling up with tasks that are no longer waiting. We expect to provide another update in 4 hours or as soon as more information becomes available.
Jun 22, 12:37 PDT
Update - We continue investigating an issue with Flex Queue Stats. The Waiting Task counter is not refreshing properly, therefore, customers may experience piling up with tasks that are no longer waiting. We expect to provide another update in 2 hours or as soon as more information becomes available.
Jun 22, 11:32 PDT
Update - We are investigating an issue with Flex Queue Stats. The Waiting Task counter is not refreshing properly, therefore, customers may experience piling up with tasks that are no longer waiting. We expect to provide another update in 1 hour or as soon as more information becomes available.
Jun 22, 11:18 PDT
Investigating - Our monitoring systems have detected a potential issue with Flex Insights. Our engineering team has been alerted and is actively investigating. We will update as soon as we have more information.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SMS Delivery Delays to Glo Mobile Network]]></title>
        <id>https://status.twilio.com/incidents/d5r39t3hlx0t</id>
        <link href="https://status.twilio.com/incidents/d5r39t3hlx0t"/>
        <updated>2023-06-22T23:42:03.000Z</updated>
        <summary type="html"><![CDATA[Jun 22, 16:42 PDT
Resolved - We are no longer experiencing SMS delivery delays when sending messages to Glo Mobile Network in Nigeria. This incident has been resolved.
Jun 22, 14:42 PDT
Monitoring - We are observing recovery in SMS delivery delays when sending messages to Glo Mobile Network in Nigeria. We will continue monitoring the service to ensure a full recovery. We will provide another update in 2 hours or as soon as more information becomes available.
Jun 22, 11:14 PDT
Update - We continue experiencing SMS delivery delays when sending messages to Glo Mobile Network in Nigeria. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 4 hours or as soon as more information becomes available.
Jun 22, 09:17 PDT
Update - We are still experiencing SMS delivery delays when sending messages to Glo Mobile Network in Nigeria. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 2 hours or as soon as more information becomes available.
Jun 22, 08:17 PDT
Investigating - We are experiencing SMS delivery delays when sending messages to Glo Mobile Network in Nigeria. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 1 hour or as soon as more information becomes available.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Devices Using Super SIM May Experience Issues Receiving OTA Updates]]></title>
        <id>https://status.twilio.com/incidents/rrdnqybl0ryn</id>
        <link href="https://status.twilio.com/incidents/rrdnqybl0ryn"/>
        <updated>2023-06-22T23:06:32.000Z</updated>
        <summary type="html"><![CDATA[Jun 22, 16:06 PDT
Resolved - The issue causing devices using Super SIM to experience missing OTA updates has been resolved, and it is operating normally at this time.
Jun 22, 15:06 PDT
Update - We are now seeing recovery of the issue causing devices using Super SIM to experience missing OTA updates. We are continuing to monitor for service stability. We will provide another update in 1 hour or as soon as more information becomes available.
Jun 22, 12:58 PDT
Monitoring - We are now seeing recovery of the issue causing devices using Super SIM to experience missing OTA updates. We are continuing to monitor for service stability. We will provide another update in 2 hours or as soon as more information becomes available.
Jun 22, 12:42 PDT
Update - The issue causing devices using Super SIM to experience missing OTA updates has been identified. The affected service on the partner’s side has been restarted. We are checking if the missing events could be replayed. We will provide another update in 2 hours or sooner once more information becomes available.
Jun 22, 10:56 PDT
Identified - The issue causing a small set of devices (less than 1%) using Super SIM has been identified. We are working with our partners to investigate the root cause. We will provide another update in 2 hours or as soon as more information becomes available.
Jun 22, 09:52 PDT
Update - We have identified that since 13th of June there could be an issue where a small set of devices using Super SIM won’t receive any OTA updates. We are actively working to identify and resolve the issue. Likewise, we will provide another update in 1 hour or sooner once more information becomes available.
Jun 22, 09:45 PDT
Investigating - Our monitoring systems have detected a potential issue with Super SIM. Our engineering team has been alerted and is actively investigating. We will update as soon as we have more information.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Links in a Subset of Messages Were not Shortened]]></title>
        <id>https://status.twilio.com/incidents/f4g44v8ktf3z</id>
        <link href="https://status.twilio.com/incidents/f4g44v8ktf3z"/>
        <updated>2023-06-22T23:02:04.000Z</updated>
        <summary type="html"><![CDATA[Jun 22, 16:02 PDT
Resolved - Programmable Messaging Link Shortening was degraded for 10 hours between 12:00 AM and 10:00 AM Pacific Time. During this period of time, customers may have experienced issues with shortening links as part of sending messages. The issue has now been resolved.
Jun 22, 15:19 PDT
Investigating - Our monitoring systems have detected a potential issue with Link Shortener. Our engineering team has been alerted and is actively investigating. We will update as soon as we have more information.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[500 Errors Across Multiple Endpoints]]></title>
        <id>https://airbnbapi.statuspage.io/incidents/tx6z0zm2rfmg</id>
        <link href="https://airbnbapi.statuspage.io/incidents/tx6z0zm2rfmg"/>
        <updated>2023-06-22T22:09:15.000Z</updated>
        <summary type="html"><![CDATA[Jun 22, 15:09 PDT
Resolved - This incident has been mitigated. Please apply any failed requests that were made during the incident time.
Jun 22, 13:26 PDT
Investigating - We are actively investigating an increased number of 500 errors across multiple endpoints. These errors started today (June 22, 2023) around 12:30 PM PDT. Our engineering teams are working to get everything up and running again and we will update you with the latest information as soon as possible.]]></summary>
        <author>
            <name>Airbnb API Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SMS Delivery Delays to Airtel Network in India]]></title>
        <id>https://status.twilio.com/incidents/ndk65s38fy3q</id>
        <link href="https://status.twilio.com/incidents/ndk65s38fy3q"/>
        <updated>2023-06-22T20:37:45.000Z</updated>
        <summary type="html"><![CDATA[Jun 22, 13:37 PDT
Update - We still continue experiencing SMS delivery delays when sending messages to Airtel network in India. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 4 hours or as soon as more information becomes available.
Jun 22, 11:44 PDT
Update - We continue experiencing SMS delivery delays when sending messages to Airtel network in India. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 2 hours or as soon as more information becomes available.
Jun 22, 10:45 PDT
Investigating - We are experiencing SMS delivery delays when sending messages to Airtel network in India. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 1 hour or as soon as more information becomes available.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Delivery Failures to Etisalat and DU Networks in United Arab Emirates Using Domestic Sender ID's]]></title>
        <id>https://status.twilio.com/incidents/sm2bpxs38k37</id>
        <link href="https://status.twilio.com/incidents/sm2bpxs38k37"/>
        <updated>2023-06-22T18:47:11.000Z</updated>
        <summary type="html"><![CDATA[Jun 22, 11:47 PDT
Monitoring - We are observing successful SMS delivery to Etisalat and DU networks in the United Arab Emirates, using Domestic Sender ID’s. We will continue to monitor to ensure full service recovery. We expect to provide another update in 12 hours or as soon as more information becomes available.
Jun 22, 11:01 PDT
Update - We are still experiencing SMS delivery failures when sending messages to Etisalat and DU networks in the United Arab Emirates, using Domestic Sender ID’s. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 1 hour or as soon as more information becomes available.
Jun 22, 09:03 PDT
Update - We are experiencing SMS delivery failures when sending messages to Etisalat and DU networks in the United Arab …]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Undelivered SMS Traffic Towards Etisalat UAE With Authy/Verify]]></title>
        <id>https://status.twilio.com/incidents/n7wbrxftxkfj</id>
        <link href="https://status.twilio.com/incidents/n7wbrxftxkfj"/>
        <updated>2023-06-22T16:27:58.000Z</updated>
        <summary type="html"><![CDATA[Jun 22, 09:27 PDT
Resolved - The issue with undelivered SMS traffic towards Etisalat UAE with Authy/Verify has been resolved, and the service is functioning normally at this time.
Jun 22, 08:56 PDT
Monitoring - We have started seeing recovery for undelivered SMS traffic towards Etisalat UAE with Authy/Verify. We will continue to monitor to ensure a full recovery. We expect to provide another update in 30 minutes or as soon as more information becomes available.
Jun 22, 04:50 PDT
Update - We are currently investigating an issue with undelivered SMS traffic towards Etisalat UAE with Authy/Verify. We expect to provide another update in 4 hours or as soon as more information becomes available.
Jun 22, 02:51 PDT
Update - We are investigating an issue with undelivered SMS traffic towards Etisalat UAE with Authy/Verify. We expect to provide another update in 2 hours or as soon as more information becomes available.
Jun 22, 02:04 PDT
Investigating - We are investigating an issue with undelivered SMS traffic towards Etisalat UAE with Authy/Verify. We expect to provide another update in 1 hour or as soon as more information becomes available]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[US SMS/MMS Carrier Maintenance - AT&T]]></title>
        <id>https://status.twilio.com/incidents/wx0mbs6yd2rg</id>
        <link href="https://status.twilio.com/incidents/wx0mbs6yd2rg"/>
        <updated>2023-06-22T11:00:10.000Z</updated>
        <summary type="html"><![CDATA[Jun 22, 04:00 PDT
Completed - The scheduled maintenance has been completed.
Jun 21, 21:00 PDT
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
Jun 16, 16:04 PDT
Scheduled - The AT&T network in the US is conducting a planned maintenance from 21 June 2023 at 21:00 PDT until 22 June 2023 at 04:00 PDT. During the maintenance window, there could be intermittent delays delivering SMS and MMS to and from AT&T US handsets.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Global Account Security Carrier Partner Maintenance -Three UK]]></title>
        <id>https://status.twilio.com/incidents/dfxqcdrpylwn</id>
        <link href="https://status.twilio.com/incidents/dfxqcdrpylwn"/>
        <updated>2023-06-22T06:00:20.000Z</updated>
        <summary type="html"><![CDATA[Jun 21, 23:00 PDT
Completed - The scheduled maintenance has been completed.
Jun 21, 22:00 PDT
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
Jun 16, 09:37 PDT
Scheduled - Our Global Carrier Partner Three UK is conducting a planned maintenance from 21 June 2023 at 22:00 PDT until 21 June 2023 at 23:00 PDT. During the maintenance window, there could be intermittent API request failures for the following destinations: Austria, Indonesia, Italy, UK
Impacted Products - Carrier
Silent Network Authentication (SNA) - 3 Indonesia, Wind (Tre) Italy, Three UK
Lookup SIM Swap - 3 Austria, Wind (Tre) Italy, Three UK
Identity Match - Wind (Tre) Italy, Three UK]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ireland SMS Carrier Partner Maintenance]]></title>
        <id>https://status.twilio.com/incidents/s5zy5qgllk7w</id>
        <link href="https://status.twilio.com/incidents/s5zy5qgllk7w"/>
        <updated>2023-06-22T05:00:43.000Z</updated>
        <summary type="html"><![CDATA[Jun 21, 22:00 PDT
Completed - The scheduled maintenance has been completed.
Jun 21, 14:00 PDT
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
Jun 21, 13:05 PDT
Scheduled - Our SMS carrier partner in Ireland is conducting an emergency maintenance from 21 June 2023 at 14:00 PDT until 21 June 2023 at 22:00 PDT. During the maintenance window, there could be intermittent delays delivering SMS to and from Ireland handsets via short codes.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Degraded Functions Service]]></title>
        <id>https://status.digitalocean.com/incidents/9hwth0p75c6y</id>
        <link href="https://status.digitalocean.com/incidents/9hwth0p75c6y"/>
        <updated>2023-06-21T18:05:27.000Z</updated>
        <summary type="html"><![CDATA[Jun 21, 18:05 UTC
Resolved - Our Engineering team has confirmed that the issue impacting our Functions service has been fully resolved. If you continue to experience any issues in relation to this incident please open a ticket with our support team. Thank you for your patience.
Jun 21, 17:11 UTC
Monitoring - Functions in BLR1 region are now restored to normal service. As of 17:00 UTC, all impact has been mitigated and users should no longer experience any issues with the Functions. We are monitoring the situation and will post an update once the incident is completely resolved.
Thank you for your patience and we apologize for the inconvenience.
Jun 21, 16:50 UTC
Update - Functions in FRA1 and LON1 are now restored to normal service. We continue work to remediate BLR1.
Our Engineering team has discovered that some Function invocations were duplicated, so a subset of users may have experienced that during the course of this incident.
We will post an update once the last region has returned to normal service.
Jun 21, 16:01 UTC
Identified - Our Engineering team has been working in order to restore the Functions service. At this time, normal service has been restored in most of the regions including AMS3, SGP1, TOR1, and SYD1.
We’re now working to fully remediate the remaining regions: BLR1, FRA1, and LON1. We will post an update as soon as that has completed. Thank you for your patience!
Jun 21, 15:43 UTC
Investigating - Beginning 14:37 UTC, our Engineering team has identified an issue impacting Functions in AMS3, BLR1, FRA1, LON1, SGP1, SYD1, and TOR1. During this time, users with standalone Functions or Functions deployed through Apps may experience performance degradation, leading to delays in Functions invocations and/or Functions working more slowly than normal.
Our team is working to mitigate the issue and we will provide an update as soon as possible.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Network Connectivity in European Regions]]></title>
        <id>https://status.digitalocean.com/incidents/bclmy32d12p0</id>
        <link href="https://status.digitalocean.com/incidents/bclmy32d12p0"/>
        <updated>2023-06-21T14:31:05.000Z</updated>
        <summary type="html"><![CDATA[Jun 21, 14:31 UTC
Resolved - From 12:00 - 13:40 UTC our Engineering team observed an issue with network connectivity to US-EAST-1 and US-EAST-2 (AWS) from European datacenter regions including DigitalOcean's AMS, FRA & LON datatancers. During this time, a subset of users might have experienced high latency or errors while connecting to  services, including Droplets and Droplet-based products. We also received reports of issues in pushing/pulling images to and from DigitalOcean Container Registries. 
As of 13:40 UTC the impact has been subsided and users should no longer be facing network connectivity issues. We apologize for the inconcenience and if you are still experiencing issues or have any additional questions then please open a support ticket from within your account.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Issue affecting listings bedrooms, bathrooms and beds]]></title>
        <id>https://airbnbapi.statuspage.io/incidents/620bns7c4y3p</id>
        <link href="https://airbnbapi.statuspage.io/incidents/620bns7c4y3p"/>
        <updated>2023-06-20T21:10:48.000Z</updated>
        <summary type="html"><![CDATA[Jun 20, 14:10 PDT
Resolved - This incident has been resolved. We have restored the correct bedroom, bathroom and bed count on the Listings API.
Jun 15, 20:37 PDT
Update - We have implemented a fix to restore the correct bedrooms, bathrooms and bed values on the Listings API and will continue to monitor this incident.
We apologize for any inconvenience this may cause and appreciate your understanding as we resolve this issue.
Jun 15, 14:38 PDT
Monitoring - We are currently addressing a bug that affects the bedroom, bathroom, and bed count on our Listings API. Due to a change in behavior of how bedrooms, bathrooms and beds interact with the Listing Rooms API, you might come across the following issues:
* On the Listings API, some listings might have the fields `bedrooms`,`bathrooms` and/or `beds` set to 0.
* On the Listings Rooms API, some rooms might have been created/deleted.
As of today, we have reverted the problematic behavior and are working diligently to restore the correct bedrooms, bathrooms, and beds values on the Listings API. To ensure that your Listing Rooms are accurately set, we kindly ask you to re-sync your data.
We apologize for any inconvenience this may cause and appreciate your understanding as we resolve this issue.]]></summary>
        <author>
            <name>Airbnb API Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Actions]]></title>
        <id>https://www.githubstatus.com/incidents/22qm4j1kvn0h</id>
        <link href="https://www.githubstatus.com/incidents/22qm4j1kvn0h"/>
        <updated>2023-06-19T23:09:51.000Z</updated>
        <summary type="html"><![CDATA[Jun 19, 23:09 UTC
Resolved - This incident has been resolved.
Jun 19, 22:47 UTC
Investigating - We are investigating reports of degraded performance for Actions.]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Issues Affecting Guest Name Parameters in Webhooks]]></title>
        <id>https://airbnbapi.statuspage.io/incidents/qn4kgtck381x</id>
        <link href="https://airbnbapi.statuspage.io/incidents/qn4kgtck381x"/>
        <updated>2023-06-19T14:46:01.000Z</updated>
        <summary type="html"><![CDATA[Jun 19, 07:46 PDT
Resolved - This incident has been resolved. However, there remains a minor possibility that reservation acceptance confirmation webhooks may be sent without the guest's last name due to an Airbnb race condition. In case you encounter this issue, please  you can retrieve the missing information with the GET Reservations API.
We apologize for the inconvenience this may have caused and don't hesitate to reach out if you have any questions, or require further assistance.
Jun 14, 16:46 PDT
Identified - Unfortunately, the mitigation did not resolve the issue and we are still seeing reservation acceptance confirmation webhooks missing the guest last name. Please know our engineering teams are working to get this issue resolved, and we will update you with the latest information as soon as possible. Meanwhile, please use the GET reservations API for any reservations that did not include the guest last name within the webhooks. We apologize for the inconvenience.
Jun 12, 08:41 PDT
Monitoring - We have implemented a fix for this issue and are monitoring the results. Apologies for the inconvenience caused.
Jun  9, 00:12 PDT
Identified - The issue has been identified and we are working on a fix.
Meanwhile, please attempt GET reservations requests for any reservations that did not include the guest names in full within the webhooks.
Jun  8, 19:36 PDT
Investigating - We are currently investigating an issue where guest names are not returned in full within webhooks - namely the reservation acceptance confirmation webhooks. This is not a widespread issue and is only affecting a small percentage of webhooks.
Alternatively, you may be able to retrieve the details with GET reservations requests.
We will post updates as soon as we know more.
Apologies for the inconvenience caused and thank you for your understanding.]]></summary>
        <author>
            <name>Airbnb API Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[v2021.12.31 Webhook Migration Enforcement - Phase 2]]></title>
        <id>https://airbnbapi.statuspage.io/incidents/vl5ppdvchsjb</id>
        <link href="https://airbnbapi.statuspage.io/incidents/vl5ppdvchsjb"/>
        <updated>2023-06-19T07:00:37.000Z</updated>
        <summary type="html"><![CDATA[Jun 19, 00:00 PDT
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
Jun 16, 14:55 PDT
Scheduled - The deprecation date for API Webhook Version 2021.12.31 was May 31, 2023. Any applications that have not fully migrated webhooks will be automatically migrated to a newer version, which can result in application breakage.
Automatic webhook migration will occur in phases as detailed in https://developer.airbnb.com/docs/versioning-enforcement
Phase 2 will occur during the week of June 19th, 2023 and will automatically migrate all Messaging, Reviews, and Reservations webhooks.]]></summary>
        <author>
            <name>Airbnb API Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[v2021.12.31 Webhook Migration Enforcement - Phase 1]]></title>
        <id>https://airbnbapi.statuspage.io/incidents/bf02v30139sd</id>
        <link href="https://airbnbapi.statuspage.io/incidents/bf02v30139sd"/>
        <updated>2023-06-17T07:00:20.000Z</updated>
        <summary type="html"><![CDATA[Jun 17, 00:00 PDT
Completed - The scheduled maintenance has been completed.
Jun 13, 00:00 PDT
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
Jun 12, 11:00 PDT
Scheduled - The deprecation date for API Webhook Version 2021.12.31 was May 31, 2023. Any applications that have not fully migrated webhooks will be automatically migrated to a newer version, which can result in application breakage.
Automatic webhook migration will occur in phases as detailed in https://developer.airbnb.com/docs/versioning-enforcement
Phase 1 will occur during the week of June 12th, 2023 and will automatically migrate all async webhooks (except Messaging, Reviews and Reservations).]]></summary>
        <author>
            <name>Airbnb API Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[500 Errors Across Multiple Endpoints]]></title>
        <id>https://airbnbapi.statuspage.io/incidents/l4t3crp7lr61</id>
        <link href="https://airbnbapi.statuspage.io/incidents/l4t3crp7lr61"/>
        <updated>2023-06-17T01:52:37.000Z</updated>
        <summary type="html"><![CDATA[Jun 16, 18:52 PDT
Resolved - This incident has now been resolved.
Jun 16, 16:38 PDT
Monitoring - An issue has been deployed and we are monitoring the results - the 500 error rate has significantly dropped.
Jun 16, 15:44 PDT
Identified - We are actively investigating an increased number of 500 errors and an increase in latency across multiple endpoints. These errors started today (June 16, 2023) around 14:20 PDT. If your API requests fail with a 500, please retry them. Our engineering teams are working to get everything up and running again and we will update you with the latest information as soon as possible.]]></summary>
        <author>
            <name>Airbnb API Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Investigating reports of degraded performance.]]></title>
        <id>https://www.githubstatus.com/incidents/psdymfgt6p7q</id>
        <link href="https://www.githubstatus.com/incidents/psdymfgt6p7q"/>
        <updated>2023-06-16T23:59:23.000Z</updated>
        <summary type="html"><![CDATA[Jun 16, 23:59 UTC
Resolved - This incident has been resolved.
Jun 16, 23:46 UTC
Update - Users may be unable to access org-owned resources in GitHub-owned client apps such as VS Code, GitHub Desktop, GitHub Mobile, and the CLI. We are working on reverting a change that is causing this
Jun 16, 23:46 UTC
Investigating - We are currently investigating this issue.]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Elevated Error Rate for Volumes and Snapshots]]></title>
        <id>https://status.digitalocean.com/incidents/7dgq9yz9ch1n</id>
        <link href="https://status.digitalocean.com/incidents/7dgq9yz9ch1n"/>
        <updated>2023-06-16T19:00:00.000Z</updated>
        <summary type="html"><![CDATA[Jun 16, 19:00 UTC
Resolved - From 19:12 - 19:40 UTC, we experienced an issue with Volumes and Snapshots endpoints. During that time, we saw elevated 500 errors and a subset of users experienced latency or errors while loading the Volumes or Images tab in the Cloud Control Panel. A subset of users also experienced errors in both the Cloud Control Panel and the API for CRUD (create, read, update, and delete) operations on Volumes and Snapshots. 
Our Engineering team was able to identify the root cause and quickly deployed a configuration fix to resolve the situation.  
We apologize for the inconvenience. If you are still experiencing any problems or have additional questions, please open a support ticket within your account.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Trouble with Google Calendar and Outlook Calendar App]]></title>
        <id>https://status.slack.com//2023-06/4edd40b2f4290679</id>
        <link href="https://status.slack.com//2023-06/4edd40b2f4290679"/>
        <updated>2023-06-16T12:00:18.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:

From June 13, 2023 at 12:30 PM PDT until June 15, 2023 at 2:30 AM PDT, some users may have experienced issues with statuses, reminders and agendas failing to sync from their Google Calendar and Outlook Calendar apps.


These issues were due to an outage from an upstream service provider which affected many services. The provider actively worked to remediate those issues, which then fully resolved the reported failures for impacted Slack users.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Some users may notice slow performance throughout Slack]]></title>
        <id>https://status.slack.com//2023-06/7363f55dbcde89c1</id>
        <link href="https://status.slack.com//2023-06/7363f55dbcde89c1"/>
        <updated>2023-06-15T23:28:00.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:


On June 15, 2023 from 8:10 AM PDT to around 8:20 AM PDT, some users may have experienced slow performance and errors while loading conversations, sending messages and taking other actions in Slack.


We traced the issue to a recent code change which caused connection failures. We reverted this change and all affected functionality should be restored for users. Thank you for your patience while we resolved this issue.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[RESOLVED: We're aware of a problem with Admin Console affecting a subset of Google Workspace Administrators. Some Google Workspace Administrators may experience issues when performing List, Create, Update, or Delete operations for OrgUnits using the Admin Console or Directory APIs. Attempting to navigate to the admin.google.com/ac/users/]]></title>
        <id>https://www.google.com/appsstatus/dashboard/incidents/1jNfhkFKus49vEyaUQLm</id>
        <link href="https://www.google.com/appsstatus/dashboard/incidents/1jNfhkFKus49vEyaUQLm"/>
        <updated>2023-06-15T21:23:03.000Z</updated>
        <summary type="html"><![CDATA[<p> Incident began at <strong>2023-06-02 19:25</strong> and ended at <strong>2023-06-03 11:57</strong> <span>(times are in <strong>Coordinated Universal Time (UTC)</strong>).</span></p><div class="cBIRi14aVDP__status-update-text"><h1>Incident Report</h1>
<h2>Summary</h2>
<p>From Friday, 2 June 2023 to Saturday, 3 June 2023, some Google Workspace Administrators experienced issues performing List, Create, Update, or Delete operations for users and organizational units (OU) when using the Admin Console or Directory APIs. The total outage duration was 16 hours and 32 minutes. We have conducted an internal investigation and are taking steps to improve our service.</p>
<h2>Root Cause</h2>
<p>The Google Workspace Admin Console and Directory APIs use a backend service to authorize requests to create/update/delete/read user and OU resources. A workflow synchronizes user and OU resources to that backend authorization service.</p>
<p>On Friday, 2 June 2023 at 12:25 PDT, engineers rolled out a configuration change that inadvertently caused the workflow to stop synchronizing resources to the authorization service. Because the authorization service was not aware of the new resources (those created during the outage), it was unable to authorize requests and returned a 403 Unauthorized error. The incorrect configuration went undetected before being deployed to production because the automatic pre-submit checks had been suppressed because engineers incorrectly believed the change was safe.</p>
<h2>Remediation and Prevention</h2>
<p>Google engineers were alerted to the outage via a support case on 2 June 2023 at 19:33 PDT and immediately started an investigation. Engineers identified that the roll out of the configuration change aligned with the start of 403 Unauthorized errors and initiated a rollback on 3 June 2023 at 00:14 PDT. The rollback completed at 00:57 PDT, mitigating the issue for new users and OU resources created after that time. Engineers performed a backfill to synchronize the impacted users and OU resources that were created after the start of the issue, fully mitigating the issue at 04:57 PDT.</p>
<p>Google is committed preventing a repeat of this issue in the future and is completing the following actions:</p>
<ul>
<li>We will be updating the pre-submit checks for workflow configuration changes to better identify potential issues before rolling out to production.</li>
<li>We will be adding a requirement to have a designated reviewer approve workflow configuration changes to ensure that automated presubmit checks are being run before rolling out to production.</li>
</ul>
<h2>Detailed Description of Impact</h2>
<p>From 2 June 2023 at 12:25 PDT to 3 June 2023 at 04:57, Google Workspace Administrators may have experienced 403 Unauthorized errors when attempting to perform actions for user and OU resources via Admin Console or Directory APIs. This issue affected Create, Fetch, Update, Delete and other related operations for user and OU resources created between 2 June 2023 at 12:25 PDT and 3 June 2023 at 00:57 PDT.</p>
</div><hr><p>Affected products: Admin Console</p>]]></summary>
        <author>
            <name>Google Workspace Status Dashboard Updates</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Copilot]]></title>
        <id>https://www.githubstatus.com/incidents/6tfr2b2s2073</id>
        <link href="https://www.githubstatus.com/incidents/6tfr2b2s2073"/>
        <updated>2023-06-15T19:36:17.000Z</updated>
        <summary type="html"><![CDATA[Jun 15, 19:36 UTC
Resolved - This incident has been resolved.
Jun 15, 19:22 UTC
Investigating - We are investigating reports of degraded performance for Copilot.]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Trouble with workflows, loading channels and accessing Slack]]></title>
        <id>https://status.slack.com//2023-06/20df18536cc9524b</id>
        <link href="https://status.slack.com//2023-06/20df18536cc9524b"/>
        <updated>2023-06-15T18:31:06.000Z</updated>
        <summary type="html"><![CDATA[Issue Summary:

From June 14, 2023 at 3:44 PM PDT until June 15, 2023 at 4:30 AM PDT, some customers may have been unable to send messages, join Huddles, run workflows, and access Slack.


A recent code change caused some resources on our backend web hosting service to be temporarily exhausted. Due to this, users experienced errors when joining Huddles, sending messages, and may have had their connection to Slack reset. We identified the issue and reverted the change restoring full functionality to these features.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Pages]]></title>
        <id>https://www.githubstatus.com/incidents/h3vqt1fvp9tc</id>
        <link href="https://www.githubstatus.com/incidents/h3vqt1fvp9tc"/>
        <updated>2023-06-15T16:57:15.000Z</updated>
        <summary type="html"><![CDATA[Jun 15, 16:57 UTC
Resolved - This incident has been resolved.
Jun 15, 16:47 UTC
Update - Due to an issue with Let's Encrypt, obtaining a new HTTPS certificate for Pages sites is delayed.
Jun 15, 16:34 UTC
Investigating - We are investigating reports of degraded performance for Pages.]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Networking in Europe Datacenters (AMS, FRA, LON)]]></title>
        <id>https://status.digitalocean.com/incidents/1d5qv6pmsv6b</id>
        <link href="https://status.digitalocean.com/incidents/1d5qv6pmsv6b"/>
        <updated>2023-06-15T03:37:51.000Z</updated>
        <summary type="html"><![CDATA[Jun 15, 03:37 UTC
Resolved - Our Engineering team has confirmed the full resolution of the issue impacting networking in our European regions.
From 16:40 UTC to 02:10 UTC, Users may have experienced network timeouts, packet loss, and/or increased latency interacting with the resources in these regions (AMS2/3, FRA1 & LON1).
If you continue to experience problems, please open a ticket with our Support team. Thank you for your patience and we apologize for the inconvenience.
Jun 15, 02:40 UTC
Monitoring - The network issues affecting our European regions have been mitigated. Users should no longer experience packet loss/latency, timeouts, and related issues with Droplet-based services in those regions, including Droplets, Managed Kubernetes, and Managed Database.
We will continue to monitor network conditions for a period of time to establish a return to pre-incident conditions.
Jun 15, 01:26 UTC
Update - Our engineering team continues to investigate the ongoing issues impacting the networking in our European data centres including AMS2/3, FRA1 & LON1 regions. During this time, you may experience intermittent packet loss or increased latency while interacting with the resources in these regions. We apologize for the inconvenience and will share an update once we have more information.
Jun 14, 20:06 UTC
Investigating - From 16:40 UTC our Engineering team is investigating an issue impacting the networking in our European data centers including AMS2/3, FRA1 & LON1 regions. During this time, you may experience intermittent packet loss or increased latency while interacting with the resources in these regions.
At the moment, all the droplet-based services appear to be impacted and the users can expect to see brief connectivity issues and interrupted traffic flows. This will also be impacting services including Spaces and Managed Databases. 
We apologize for the inconvenience and will share an update once we have more information.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scheduled Maintenance]]></title>
        <id>https://status.make.com/incidents/413nrl6rvmsx</id>
        <link href="https://status.make.com/incidents/413nrl6rvmsx"/>
        <updated>2023-06-14T11:00:40.000Z</updated>
        <summary type="html"><![CDATA[Jun 14, 13:00 CEST
Completed - The scheduled maintenance has been completed.
Jun 14, 11:00 CEST
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
Jun 13, 15:02 CEST
Scheduled - We would like to inform you about a scheduled maintenance window that will be taking place on 14th June between 11:00 CEST - 13:00 CEST.
During this maintenance period, there will be a short interruption resulting in the unavailability of the login page and organisations page. 
If you experience a blank page , clearing your browser cache might resolve the issue . If not please reach out to our customer care team.
However, we assure you that there will be no data loss and all scenarios will continue running properly.
We apologize for any inconvenience caused and appreciate your understanding.]]></summary>
        <author>
            <name>Make Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Trouble with workflows and clips transcripts]]></title>
        <id>https://status.slack.com//2023-06/a0c185e5ad5eac55</id>
        <link href="https://status.slack.com//2023-06/a0c185e5ad5eac55"/>
        <updated>2023-06-14T03:06:22.000Z</updated>
        <summary type="html"><![CDATA[Issue summary: 

On June 13, 2023 from 11:55 AM PDT to around 3:47 PM PDT, some users may have experienced failure with clips transcribing and transcoding, execution of workflows with custom functions, new deployments of apps with hosted functions, and some delay when using canvases in Slack. 


These issues were due to an outage from an upstream service provider which affected many services. The provider actively worked to remediate those issues, which then fully resolved the reported failures for impacted Slack users.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Actions and Pages]]></title>
        <id>https://www.githubstatus.com/incidents/csnbwc85chp2</id>
        <link href="https://www.githubstatus.com/incidents/csnbwc85chp2"/>
        <updated>2023-06-13T00:17:05.000Z</updated>
        <summary type="html"><![CDATA[Jun 13, 00:17 UTC
Resolved - This incident has been resolved.
Jun 13, 00:09 UTC
Update - We have applied a mitigation and are seeing signs of recovery. We will post another update shortly.
Jun 12, 23:39 UTC
Update - We are investigating reports of degraded performance for Actions. We have identified the root cause and have begun applying a mitigation.
Jun 12, 22:48 UTC
Update - Pages is experiencing degraded performance. We are still investigating and will provide an update when we have one.
Jun 12, 22:43 UTC
Investigating - We are investigating reports of degraded performance for Actions.]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Container Registry in FRA1 and SGP1]]></title>
        <id>https://status.digitalocean.com/incidents/rptq6jh8ljd7</id>
        <link href="https://status.digitalocean.com/incidents/rptq6jh8ljd7"/>
        <updated>2023-06-12T17:44:00.000Z</updated>
        <summary type="html"><![CDATA[Jun 12, 17:44 UTC
Resolved - From 04:30 to 09:30 UTC, our Engineering team observed issues with DigitalOcean Container Registry in SGP1 and FRA1 regions. During this time, users might have experienced errors while interacting with their registries in SGP1 and FRA1 regions. Users might also have experienced latency in pushing/pulling images to/from registries.
Our Engineering team has observed that the impact has been mitigated. As of 17:20 UTC, users should no longer experience any issues with pushing/pulling images to/from their registries in SGP1 and FRA1 regions. We apologize for the inconvenience. If you are still experiencing any problems or have additional questions, please open a support ticket within your account.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Small number of users might be experiencing connectivity issues]]></title>
        <id>https://status.slack.com//2023-06/1bd97a73cb7874f1</id>
        <link href="https://status.slack.com//2023-06/1bd97a73cb7874f1"/>
        <updated>2023-06-12T14:56:48.000Z</updated>
        <summary type="html"><![CDATA[On June 11, 2023 from 10:57 AM PDT to 12:10 PM PDT, some users may have experienced difficulties when trying to access Slack due to a database issue.


The underlying cause has since been determined and remediation steps were applied. This resolved the above for all impacted users.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Pull Requests]]></title>
        <id>https://www.githubstatus.com/incidents/0csnqhwzxp1m</id>
        <link href="https://www.githubstatus.com/incidents/0csnqhwzxp1m"/>
        <updated>2023-06-09T23:17:57.000Z</updated>
        <summary type="html"><![CDATA[Jun  9, 23:17 UTC
Resolved - This incident has been resolved.
Jun  9, 22:46 UTC
Update - We are investigating elevated error rates on Pull Requests. We will continue to keep users updated on progress towards mitigation.
Jun  9, 22:18 UTC
Investigating - We are investigating reports of degraded performance for Pull Requests.]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Modifying DNS records via Cloud Control Panel]]></title>
        <id>https://status.digitalocean.com/incidents/5jvv4xltnbk7</id>
        <link href="https://status.digitalocean.com/incidents/5jvv4xltnbk7"/>
        <updated>2023-06-08T22:53:00.000Z</updated>
        <summary type="html"><![CDATA[Jun  8, 22:53 UTC
Resolved - Our Engineering team has confirmed that the issue impacting the modification of the DNS records for the existing domains via the Cloud Control Panel is fully resolved. 
If you continue to experience problems please open a ticket with our support team. Thank you for your patience and we apologize for the inconvenience.
Jun  8, 22:31 UTC
Monitoring - Our engineering team has implemented a fix to resolve the issue that affected the modification of the DNS records for the existing domains via the Cloud Control Panel. Users should now be able to modify or create new DNS records for the domains within their Cloud Control Panel.
We are monitoring the situation and will post another update once we confirm it is fully resolved.
Jun  8, 21:56 UTC
Investigating - Our Engineering team is investigating an issue with modifying or creating new DNS records in our Cloud Control Panel for the existing domains. 
During this time, some users may experience issues editing the DNS records from within the Cloud Control Panel and also when navigating through the tabs available in the domain section. Users should be able to modify or add new DNS records to the existing domains using the API.
We apologize for the inconvenience and will share an update once we have more information.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Pull Requests]]></title>
        <id>https://www.githubstatus.com/incidents/17c40y7spfgl</id>
        <link href="https://www.githubstatus.com/incidents/17c40y7spfgl"/>
        <updated>2023-06-08T12:55:12.000Z</updated>
        <summary type="html"><![CDATA[Jun  8, 12:55 UTC
Resolved - This incident has been resolved.
Jun  8, 12:55 UTC
Update - Our team continues to mitigate the impacted search results however we are going to status to green due to impact on overall service. We will continue to post updates on the status page as we mitigate
Jun  8, 12:23 UTC
Update - We are aware search results for PRs are returning incomplete results in certain scenarios. This is impacting most users. No other search results are impacted. All other PR functionality is working.
Jun  8, 11:58 UTC
Investigating - We are investigating reports of degraded performance for Pull Requests.]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[NYC3 Network Maintenance 2023-06-08 04:00 UTC]]></title>
        <id>https://status.digitalocean.com/incidents/tw85s4rhwpqm</id>
        <link href="https://status.digitalocean.com/incidents/tw85s4rhwpqm"/>
        <updated>2023-06-08T08:00:22.000Z</updated>
        <summary type="html"><![CDATA[Jun  8, 08:00 UTC
Completed - The scheduled maintenance has been completed.
Jun  8, 04:00 UTC
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
Jun  8, 03:08 UTC
Scheduled - Start time: 2023-06-08 04:00 UTC
End time: 2023-06-08 08:00 UTC
During the above window, our Networking team will be performing maintenance on core switches in our NYC3 datacenter as a part of network upgrades.
Expected Impact:
These upgrades are designed and tested to be seamless and we do not expect any impact to customer traffic due to this maintenance. If an unexpected issue arises, affected Droplets and Droplet-based services may experience a temporary loss of connectivity. We will endeavor to keep any such impact to a minimum.
If you have any questions or concerns regarding this maintenance, please reach out to us by opening up a ticket on your account via https://cloudsupport.digitalocean.com/s/createticket .]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scenarios using Custom Variables not working properly]]></title>
        <id>https://status.make.com/incidents/ts75knvtfm16</id>
        <link href="https://status.make.com/incidents/ts75knvtfm16"/>
        <updated>2023-06-07T22:47:29.000Z</updated>
        <summary type="html"><![CDATA[Jun  8, 00:47 CEST
Resolved - This incident is now resolved.
Jun  7, 21:32 CEST
Update - We have applied a permanent fix on eu1.make.celonis.com and eu1.make.com, and based on our checks there are no issues and all scenarios are running as expected.
Jun  7, 21:18 CEST
Update - We are applying a fix for this issue.
Jun  7, 13:13 CEST
Update - We have applied a permanent fix on us1.make.celonis.com and us1.make.com, and based on our checks there are no issues and all scenarios are running as expected.
In regards to eu1.make.celonis.com and eu1.make.com, we are going to roll out the fix outside of business hours. 
Please use the workaround as needed, it was described in the previous update.
We will post another update once a full fix is applied.
Jun  6, 11:39 CEST
Identified - We're currently experiencing an issue that appears only in certain unique circumstances when a running scenario is not properly using the values of team or organization variables during executions.
Specific circumstances for the issue are:
- A team or organization variable is used as a filter condition OR there is more than one team or organization variable referenced within a single mapped field, OR the variable is used inside a function.
- AND the scenario was created / modified before March 8, 2023 
- AND the execution occurs after May 3, 2023
Workaround: 
Any user encountering this issue can open the affected scenario, make any change (move a module) and hit save. This will immediately resolve the issue for that scenario.
Complete resolution: 
The development team is actively working on a fix that will address any scenario where the issue still persists. Will post an update once we have more information around the permanent fix.
Jun  6, 09:09 CEST
Investigating - We're currently experiencing issues with Scenarios that use Custom Variables. Our engineering team is investigating the root cause.]]></summary>
        <author>
            <name>Make Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Actions, Pull Requests and Webhooks]]></title>
        <id>https://www.githubstatus.com/incidents/1g1gkh0qpyvs</id>
        <link href="https://www.githubstatus.com/incidents/1g1gkh0qpyvs"/>
        <updated>2023-06-07T18:39:02.000Z</updated>
        <summary type="html"><![CDATA[Jun  7, 18:39 UTC
Resolved - This incident has been resolved.
Jun  7, 18:32 UTC
Update - Repository push workers are continuing to catch up with enqueued jobs.
Jun  7, 17:58 UTC
Update - We have mitigated the problem and are waiting for our repository push workers to catch up with enqueued jobs.
Jun  7, 17:42 UTC
Update - We have identified the cause of delayed processing for commits pushed to repositories and are actively working on mitigating this issue.
Jun  7, 17:31 UTC
Update - Webhooks is experiencing degraded performance. We are continuing to investigate.
Jun  7, 17:29 UTC
Update - Actions is experiencing degraded performance. We are still investigating and will provide an update when we have one.
Jun  7, 16:53 UTC
Update - Pushes to repositories may take longer for a significant number of customers. We are actively investigating.
Jun  7, 16:45 UTC
Investigating - We are investigating reports of degraded availability for Pull Requests.]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Issues with the Google Workspace integration]]></title>
        <id>https://status.rippling.com/incidents/tvr7l7344y0y</id>
        <link href="https://status.rippling.com/incidents/tvr7l7344y0y"/>
        <updated>2023-06-07T13:43:53.000Z</updated>
        <summary type="html"><![CDATA[Jun  7, 13:43 UTC
Resolved - This incident has been resolved.
Jun  6, 20:27 UTC
Update - We are continuing to monitor for any further issues.
Jun  6, 18:43 UTC
Monitoring - Google has implemented a fix and we are monitoring the results. Customers should be able to add new licenses and transfer subscriptions via the Google Workspace App in Rippling.
Jun  5, 22:07 UTC
Identified - We are continuing to work with Google to resolve an issue that is affecting our integration.
Jun  5, 17:32 UTC
Investigating - Customers are currently unable to add new licenses and transfer subscriptions via the Google Workspace App in Rippling. We are currently working with Google to resolve this issue.]]></summary>
        <author>
            <name>Rippling Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Some files may not be unfurling as expected]]></title>
        <id>https://status.slack.com//2023-06/6cb0bb4f227a82e8</id>
        <link href="https://status.slack.com//2023-06/6cb0bb4f227a82e8"/>
        <updated>2023-06-06T11:15:34.000Z</updated>
        <summary type="html"><![CDATA[Thank you for your patience while our team investigated this. All new file uploads are now expected to generate thumbnails for affected users and the issue has been resolved. Please note that previous attempts won't be retried, however new files should function as normal.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scheduled maintenance]]></title>
        <id>https://status.make.com/incidents/ms6hw0p562v8</id>
        <link href="https://status.make.com/incidents/ms6hw0p562v8"/>
        <updated>2023-06-06T08:00:15.000Z</updated>
        <summary type="html"><![CDATA[Jun  6, 10:00 CEST
Completed - The scheduled maintenance has been completed.
Jun  6, 08:00 CEST
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
Jun  1, 15:57 CEST
Scheduled - We would like to inform you about a scheduled maintenance window that will be taking place on 6th June between 08:00 CEST - 10:00 CEST.
During this maintenance period, there will be a short interruption resulting in the unavailability of the login page and organizations page. 
However, we assure you that there will be no data loss and all scenarios will continue running properly.
We apologize for any inconvenience caused and appreciate your understanding.]]></summary>
        <author>
            <name>Make Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Notion.so down]]></title>
        <id>https://status.notion.so/incidents/j5jk1f1ytyz1</id>
        <link href="https://status.notion.so/incidents/j5jk1f1ytyz1"/>
        <updated>2023-06-05T17:43:47.000Z</updated>
        <summary type="html"><![CDATA[Jun  5, 10:43 PDT
Resolved - This has been resolved -- all users can access notion.so without issue again.
Jun  5, 09:53 PDT
Investigating - The notion.so site is down for some users, we are investigating. Users can still log in and access their workspaces at notion.so/login.]]></summary>
        <author>
            <name>Notion Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Notion production outage]]></title>
        <id>https://status.notion.so/incidents/vpm90b50y09t</id>
        <link href="https://status.notion.so/incidents/vpm90b50y09t"/>
        <updated>2023-06-05T16:30:00.000Z</updated>
        <summary type="html"><![CDATA[Jun  5, 09:30 PDT
Resolved - Notion was down from around 9:25am - 9:40am Pacific time.  We are still investigating an issue that may be preventing some users from accessing notion.so while not logged in.]]></summary>
        <author>
            <name>Notion Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Issues with Workflow Builder]]></title>
        <id>https://status.slack.com//2023-06/f7c5d1e455e95466</id>
        <link href="https://status.slack.com//2023-06/f7c5d1e455e95466"/>
        <updated>2023-06-05T09:01:22.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:


On June 02, 2023 from 3:28 PM PDT to around 5:29 PM PDT, some customers may have experienced large empty spaces in the Workflow Builder UI and issues with publishing/adding or editing steps in a workflow. 


We traced the issue to a recent code change which caused the channel selector to appear out of view, resulting in the inability to take certain actions while editing a workflow. 


We reverted the change which solved the issue for all customers.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[500 Errors Across Multiple Endpoints]]></title>
        <id>https://airbnbapi.statuspage.io/incidents/xccq5r4gm6c5</id>
        <link href="https://airbnbapi.statuspage.io/incidents/xccq5r4gm6c5"/>
        <updated>2023-06-02T15:35:47.000Z</updated>
        <summary type="html"><![CDATA[Jun  2, 08:35 PDT
Resolved - This issue is now resolved. The incident that occurred yesterday (June 1, 2023) resulted in an elevated amount of 500 errors across multiple endpoints, for approximately 1 hour. If you are still encountering a high volume of 500 errors, please reach out to us through the Support Portal so we can assist you further.
We apologize for any inconvenience this may have caused.
Jun  1, 13:34 PDT
Monitoring - We have implemented a fix for the issue, and the error rate has dropped significantly. We will continue to monitor the results
Jun  1, 12:51 PDT
Identified - We are actively investigating an increased number of 500 errors across multiple endpoints. These errors started today (June 1, 2023) around 12:20 PM PDT. Please know our engineering and operations teams are working hard to get everything up and running again, and we will update you with the latest information as soon as possible]]></summary>
        <author>
            <name>Airbnb API Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Notion.so down]]></title>
        <id>https://status.notion.so/incidents/crfw2mn48z7m</id>
        <link href="https://status.notion.so/incidents/crfw2mn48z7m"/>
        <updated>2023-06-02T12:26:37.000Z</updated>
        <summary type="html"><![CDATA[Jun  2, 05:26 PDT
Resolved - The issue has been resolved, and notion.so is available to all users
Jun  2, 04:53 PDT
Investigating - The notion.so site is down for some users, we are investigating. Users can still log in and access their workspaces at notion.so/login.]]></summary>
        <author>
            <name>Notion Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Some users are reporting issues triggering shortcut Workflows]]></title>
        <id>https://status.slack.com//2023-05/d3da25ad25333a58</id>
        <link href="https://status.slack.com//2023-05/d3da25ad25333a58"/>
        <updated>2023-06-01T18:00:28.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:


From May 19, 2023 at 12:00 AM PDT until May 25, 2023 at 8:00 AM PDT, some users may have experienced issues triggering shortcut workflows.


We carried out our investigation and determined that cached data on the back end temporarily broke legacy workflows. In the process of determining our path to a resolution the issue resolved itself. We are taking the necessary steps to prevent similar issues in the future.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Users reporting issues with keyboard shortcuts]]></title>
        <id>https://status.slack.com//2023-05/223e97529097de1c</id>
        <link href="https://status.slack.com//2023-05/223e97529097de1c"/>
        <updated>2023-06-01T05:57:52.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:

On May 31, 2023 from 5:15 PM PDT to 7:12 PM PDT, some customers experienced issues with using keyboard shortcuts. 


We’ve traced that this issue was caused by a recent code change. We’ve rolled back this change, resolving the issue for all impacted customers.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SFO2 Network Maintenance 2023-06-01 01:00 UTC Phase 2]]></title>
        <id>https://status.digitalocean.com/incidents/r8yz7801sh9w</id>
        <link href="https://status.digitalocean.com/incidents/r8yz7801sh9w"/>
        <updated>2023-06-01T03:01:07.000Z</updated>
        <summary type="html"><![CDATA[Jun  1, 03:01 UTC
Completed - The scheduled maintenance has been completed.
Jun  1, 01:00 UTC
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
May 31, 23:11 UTC
Scheduled - Start: 2023-06-01 01:00 UTC
End: 2023-06-01 05:00 UTC
During the above window, our Networking team will be making changes to our core networking infrastructure to improve performance and scalability in the SFO2 region. This will be the second of the two maintenance activities performed by our team in the region on consecutive days.
Expected Impact:
These upgrades are designed and tested to be seamless and we do not expect any impact to customer traffic due to this maintenance. If an unexpected issue arises, affected Droplets and Droplet-based services may experience a temporary loss of private connectivity between VPCs. We will endeavor to keep any such impact to a minimum.
If you have any questions or concerns regarding this maintenance, please reach out to us by opening up a ticket on your account via https://cloudsupport.digitalocean.com/s/createticket .]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Autocomplete results ranking in search degraded]]></title>
        <id>https://status.slack.com//2023-05/aa025f4aef896b16</id>
        <link href="https://status.slack.com//2023-05/aa025f4aef896b16"/>
        <updated>2023-05-31T23:27:14.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:

From May 30th, 2023 at 8:02 AM PDT until 11:18 AM PDT, some users experienced unexpected behavior with autocomplete suggestions, including incorrect rankings & incomplete results when conducting searches.


We traced the source of the issue back to an error that occurred in our autocomplete cache. A fix was rolled out to our search logic which began to show the correct results.


Users can refresh their Slack client (by pressing Cmd/Ctrl + Shift + R) if they are still experiencing issues. We apologize for any interruption.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Reacji Channeler app is failing for some users]]></title>
        <id>https://status.slack.com//2023-05/0848cba206ef2188</id>
        <link href="https://status.slack.com//2023-05/0848cba206ef2188"/>
        <updated>2023-05-31T23:04:00.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:

From May 30th, 2023 at around 8:00 PM PDT until May 31st, 2023 at 9:20 AM PDT, users with the Reacji Channeler app installed in their workspace experienced some issues where the app would not execute.


The issue was traced back to a recent change that occurred for one of our app databases. This caused the app to accept new requests even though it was unable to connect to the database, resulting in timeout errors. 


We reverted the change and restarted the backend processes which allowed the app to connect to the database again, resolving the issue for impacted users. We apologize for any disruptions to your day.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scheduled maintenance]]></title>
        <id>https://status.make.com/incidents/2vlc5cz18jbn</id>
        <link href="https://status.make.com/incidents/2vlc5cz18jbn"/>
        <updated>2023-05-31T08:00:42.000Z</updated>
        <summary type="html"><![CDATA[May 31, 10:00 CEST
Completed - The scheduled maintenance has been completed.
May 31, 08:02 CEST
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
May 29, 15:34 CEST
Scheduled - We would like to inform you about a scheduled maintenance window that will be taking place on 31st May between 08:00 CEST - 10:00 CEST.
During this maintenance period, there will be a short interruption resulting in the unavailability of the login page and organizations page. 
However, we assure you that there will be no data loss and all scenarios will continue running properly.
We apologize for any inconvenience caused and appreciate your understanding.]]></summary>
        <author>
            <name>Make Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SFO2 Network Maintenance]]></title>
        <id>https://status.digitalocean.com/incidents/4rf2j2dmc382</id>
        <link href="https://status.digitalocean.com/incidents/4rf2j2dmc382"/>
        <updated>2023-05-31T04:04:49.000Z</updated>
        <summary type="html"><![CDATA[May 31, 04:04 UTC
Completed - The scheduled maintenance has been completed.
May 31, 01:30 UTC
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
May 31, 01:26 UTC
Scheduled - Start: 2023-05-31 01:00 UTC
End: 2023-05-31 05:00 UTC

During the above window, our Networking team will be making changes to our core networking infrastructure to improve performance and scalability in the SFO2 region. This maintenance will occur in two parts on consecutive days and we will send another maintenance notice for the second phase. 
Expected Impact:
These upgrades are designed and tested to be seamless and we do not expect any impact to customer traffic due to this maintenance. If an unexpected issue arises, affected Droplets and Droplet-based services may experience a temporary loss of private connectivity between VPCs. We will endeavor to keep any such impact to a minimum.
If you have any questions or concerns regarding this maintenance, please reach out to us by opening up a ticket on your account via https://cloudsupport.digitalocean.com/s/createticket .]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spaces API Availability in NYC3]]></title>
        <id>https://status.digitalocean.com/incidents/vmxnj2vv4k9k</id>
        <link href="https://status.digitalocean.com/incidents/vmxnj2vv4k9k"/>
        <updated>2023-05-31T02:25:35.000Z</updated>
        <summary type="html"><![CDATA[May 31, 02:25 UTC
Resolved - Our Engineering team has confirmed the full resolution of the issue impacting Spaces performance and availability in our NYC3 region.
From 00:20 to 00:57 UTC, users may have experienced slowness or timeouts when trying to access or manage their Spaces resources in NYC3, static site assets in NYC, or App Platform bandwidth insights.
Spaces should now be operating normally. If you continue to experience problems, please open a ticket with our support team from within your Cloud Control Panel. We apologize for any inconvenience.
May 31, 01:47 UTC
Monitoring - Our Engineering team has observed recovery of availability for Spaces in our NYC3 region. 
Availability returned to 100% at 00:57 UTC and since then, users should not be experiencing any issues with Spaces or App Platform. 
We'll now monitor the situation for a period of time and post a final update once we confirm the incident is resolved.
May 31, 01:05 UTC
Investigating - Our Engineering team is investigating a drop in availability for Spaces in our NYC region. During this time, some users may experience errors with API or object requests, be unable to create new buckets in NYC3, and/or see issues with loading Spaces in the Cloud Control Panel. 
Additionally, users of App Platform will be unable to see bandwidth insights in their dashboards and static site users may notice errors fetching assets from Spaces buckets in NYC3. 
We apologize for the inconvenience and will share an update once we have more information.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Subsea Fiber Faults in the APAC region]]></title>
        <id>https://status.digitalocean.com/incidents/qbszx5q5dd19</id>
        <link href="https://status.digitalocean.com/incidents/qbszx5q5dd19"/>
        <updated>2023-05-28T19:16:27.000Z</updated>
        <summary type="html"><![CDATA[May 28, 19:16 UTC
Resolved - Our Engineering team has continued to actively monitor the situation resulting from multiple subsea fiber faults in the APAC region. Over the last few days, our team has continued to make routing changes where possible. 
Crews have been able to complete some cable repairs and we expect to see our network routing stabilize once the repair of a few more cables are completed in the coming weeks. Until then, we expect to see intermittent periods of packet loss and latency on network routes between Singapore and New York City, as well as Singapore and Toronto. These are normally short-lived and happen during Singapore business hours when traffic is heavy. 
Given the relative stability of routes, we will now close out this incident and provide any needed updates sepa…]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Container Registry in SFO3]]></title>
        <id>https://status.digitalocean.com/incidents/93nbbqq83slf</id>
        <link href="https://status.digitalocean.com/incidents/93nbbqq83slf"/>
        <updated>2023-05-26T02:38:56.000Z</updated>
        <summary type="html"><![CDATA[May 26, 02:38 UTC
Resolved - As of 02:10 UTC, Our Engineering team has confirmed that the issue with our Container Registry services in the SFO3 region has been fully resolved. 
All operations should now be operating normally with our Container Registry services. If you continue to experience any trouble with these services please open a ticket with our support team. 
Thank you for your patience and we apologize for the inconvenience.
May 25, 23:31 UTC
Monitoring - As of 22:10 UTC, Our engineering team has implemented a fix to resolve the issue with our Container Registry services in the SFO3 region and is monitoring the situation closely. 
Users should no longer see 500-type errors when uploading/pushing/deleting images, slow cleanup operations, creation failures for new registries, or other errors when interacting with registries in the SFO3 region. 
We are going to continue to monitor the situation and will post an update once we are confident this issue will not recur.
May 25, 16:20 UTC
Investigating - We are observing some customer reports for issues with DigitalOcean Container Registries in the SFO3 region. Our Engineering team is investigating any potential issues that are causing these reports. This seems to be a reoccurrence of the incident mentioned in the below link:
https://status.digitalocean.com/incidents/mmngtxzmm6gs  
At this time, users may see 500 type errors when uploading/pushing/deleting images, slow cleanup operations, creation failures for new registries, or other errors when interacting with registries in SFO3. 
We will post an update as soon as we have further information. Thank you for your patience.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[App Platform Deployments in SFO region]]></title>
        <id>https://status.digitalocean.com/incidents/kg0b7wl8mshl</id>
        <link href="https://status.digitalocean.com/incidents/kg0b7wl8mshl"/>
        <updated>2023-05-25T09:45:27.000Z</updated>
        <summary type="html"><![CDATA[May 25, 09:45 UTC
Resolved - Our Engineering team has confirmed the full resolution of this incident.
From 06:00 - 08:00 UTC, users were unable to create and deploy new Apps and experienced errors when updating, and deploying existing Apps. The App deployments should now be operating normally.
If you continue to experience problems, please open a ticket with our support team from within your Cloud Control Panel.
May 25, 09:20 UTC
Monitoring - Our Engineering team has implemented a fix to resolve the issue with App deployments in the SFO region and is monitoring the situation. We will post an update as soon as the issue is fully resolved.
May 25, 08:47 UTC
Identified - Our Engineering team has identified the cause of the issue with network latency that is impacting the management and creation of Apps in the SFO region and is actively working on a fix. During this time, a subset of users might see errors when updating and deploying new/existing Apps. We will post an update as soon as additional information is available.
May 25, 08:30 UTC
Investigating - Our Engineering team is investigating an issue with network latency that is impacting the management and creation of Apps in the SFO region. As of 06:00 UTC, users are unable to create and deploy new Apps and may see errors when updating, and deploying existing Apps. At this time, previously deployed running Apps are not impacted. We apologize for the inconvenience and will share an update once we have more information.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scheduled maintenance]]></title>
        <id>https://status.make.com/incidents/zgjx54wdw2y9</id>
        <link href="https://status.make.com/incidents/zgjx54wdw2y9"/>
        <updated>2023-05-25T07:00:25.000Z</updated>
        <summary type="html"><![CDATA[May 25, 09:00 CEST
Completed - The scheduled maintenance has been completed.
May 25, 08:00 CEST
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
May 23, 15:00 CEST
Scheduled - We would like to inform you about a scheduled maintenance window that will be taking place on 25th May between 08:00 CEST - 09:00 CEST.
During this maintenance period, there will be a short interruption resulting in the unavailability of the login page and organizations page. 
However, we assure you that there will be no data loss and all scenarios will continue running properly.
We apologize for any inconvenience caused and appreciate your understanding.]]></summary>
        <author>
            <name>Make Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Container Registry in SFO3]]></title>
        <id>https://status.digitalocean.com/incidents/mmngtxzmm6gs</id>
        <link href="https://status.digitalocean.com/incidents/mmngtxzmm6gs"/>
        <updated>2023-05-25T02:49:34.000Z</updated>
        <summary type="html"><![CDATA[May 25, 02:49 UTC
Resolved - Our Engineering team has identified the root cause of the incident to be multiple DB calls causing DB contention. During this time, users might have experienced issues interacting and authenticating with the DigitalOcean Container Registry, creating new container registries, and pushing/deleting images to/from registries.
As of 00:10 UTC, we have confirmed the full resolution of the issue affecting the DigitalOcean Container Registry in the SFO3 region. We appreciate your patience throughout the process and if you continue to experience problems, please open a ticket with our support team for further review.
May 24, 22:53 UTC
Update - Our Engineering team continues to investigate the root cause of this incident but has observed a reduction in the error rate with DigitalOcean Container Registry in the SFO3 region.
At this time, users should no longer experience errors while interacting and authenticating with the DigitalOcean Container Registry, creating new container registries, and pushing/deleting images to/from registries.
We will post an update as soon as we have further information. Thank you for your patience.
May 24, 19:28 UTC
Investigating - Following an uptick in customer reports of issues with DigitalOcean Container Registries in SFO3, our Engineering team is investigating any potential issues that are causing these reports. 
At this time, users may see 500 type errors when uploading/pushing/deleting images, slow cleanup operations, creation failures for new registries, or other errors when interacting with  registries in SFO3. 
We will post an update as soon as we have further information. Thank you for your patience.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: A small percentage of users are experiencing issues with Slack.]]></title>
        <id>https://status.slack.com//2023-05/f1df0cac8d8d8d68</id>
        <link href="https://status.slack.com//2023-05/f1df0cac8d8d8d68"/>
        <updated>2023-05-24T22:29:00.000Z</updated>
        <summary type="html"><![CDATA[On May 23, 2023 between 8:38 AM PDT and 9:44 AM PDT some users were unable to send and edit messages, load threads, join channels and create group DMs.


Our investigation uncovered that a recent code change we made had caused an overwhelming impact on our databases. We rolled this change back and temporarily redirected user traffic as our databases recovered. Once we rolled back the change and our databases were in a healthier state, the issue became resolved for impacted users.


We will continue to implement new ways to detect issues like this early-on.


Thank you for your patience while we investigated and resolved the issue.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Snapshots and Backups Failure in SGP1]]></title>
        <id>https://status.digitalocean.com/incidents/y3033ln7n73w</id>
        <link href="https://status.digitalocean.com/incidents/y3033ln7n73w"/>
        <updated>2023-05-24T21:30:01.000Z</updated>
        <summary type="html"><![CDATA[May 24, 21:30 UTC
Resolved - As of 21:15 UTC, Our Engineering team has confirmed the full resolution of this incident. We have verified that the Snapshot and Backup events in the SGP1 region are processing without any failures and we will now mark this issue as resolved. 
Thank you for your patience and understanding throughout this process. If you should encounter any further issues at all, then please open a ticket with our Support team.
May 24, 21:05 UTC
Update - We are continuing to monitor for any further issues.
May 24, 20:44 UTC
Monitoring - As of 19:30 UTC, Our Engineering team was able to take action to mitigate the impact of this incident and allow Snapshot and Backup events to process normally in the SGP1 region. We will post an update as soon as the issue is fully resolved. 
Please note that while the situation has improved, there may still be a backlog of older events that are in the process of being resolved. We kindly ask for your patience as our team works diligently to address these remaining events. 
We apologize for any inconvenience caused and assure you that we are committed to resolving all outstanding issues.
May 24, 19:20 UTC
Investigating - As of 13:30 UTC our Engineering team is investigating an issue with intermittent Snapshot and Backup failures in our SGP1 region. Users may experience errors when performing Snapshots, but may eventually see retries succeed. 
Any Backup failures are automatically being retried within the Backup window for individual Droplets. 
We apologize for the inconvenience and will share an update once we have more information.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AMS3 Network Maintenance Phase 3]]></title>
        <id>https://status.digitalocean.com/incidents/gqtn5dtkstzg</id>
        <link href="https://status.digitalocean.com/incidents/gqtn5dtkstzg"/>
        <updated>2023-05-24T18:35:49.000Z</updated>
        <summary type="html"><![CDATA[May 24, 18:35 UTC
Completed - The scheduled maintenance has been completed.
May 24, 16:00 UTC
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
May 24, 15:05 UTC
Scheduled - Start: 2023-05-24 16:00 UTC
End:  2023-05-24 20:00 UTC

During the above window, our Networking team will be making changes to our core networking infrastructure to improve performance and scalability in the AMS3 region. This will be the final phase of the three maintenance activities performed by our team in AMS3 on consecutive days.
Expected Impact:
These upgrades are designed and tested to be seamless and we do not expect any impact to customer traffic due to this maintenance. If an unexpected issue arises, affected Droplets and Droplet-based services may experience a temporary loss of private connectivity between VPCs. We will endeavor to keep any such impact to a minimum.
If you have any questions or concerns regarding this maintenance, please reach out to us by opening up a ticket on your account via https://cloudsupport.digitalocean.com/s/createticket .]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
</feed>