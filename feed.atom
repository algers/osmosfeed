<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>urn:2023-06-16T00:24:56.377Z</id>
    <title>osmos::feed</title>
    <updated>2023-06-16T00:24:56.377Z</updated>
    <generator>osmosfeed 1.15.1</generator>
    <link rel="alternate" href="index.html"/>
    <entry>
        <title type="html"><![CDATA[US MMS Carrier Maintenance - Verizon]]></title>
        <id>https://status.twilio.com/incidents/st9ptfbpkhnv</id>
        <link href="https://status.twilio.com/incidents/st9ptfbpkhnv"/>
        <updated>2023-06-16T08:00:00.000Z</updated>
        <summary type="html"><![CDATA[THIS IS A SCHEDULED EVENT Jun 16, 01:00 - 02:00 PDT
Jun  8, 22:55 PDT
Scheduled - The Verizon network in US is conducting a Planned maintenance from 16 June 2023 at 01:00 PDT until 16 June 2023 at 02:00 PDT. During the maintenance window, there could be intermittent delays delivering MMS to and from Verizon US handsets.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[US SMS Carrier Maintenance - T-Mobile]]></title>
        <id>https://status.twilio.com/incidents/4m2rxl5mzr1v</id>
        <link href="https://status.twilio.com/incidents/4m2rxl5mzr1v"/>
        <updated>2023-06-16T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[THIS IS A SCHEDULED EVENT Jun 16, 00:00 - 03:00 PDT
Jun 14, 23:42 PDT
Scheduled - The T-Mobile network in the US is conducting an emergency maintenance from 16 June 2023 at 00:00 PDT until 16 June 2023 at 03:00 PDT. During the maintenance window, there could be intermittent delays delivering SMS to and from T-Mobile US handsets.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mexico SMS Carrier Maintenance - AT&T Mexico]]></title>
        <id>https://status.twilio.com/incidents/g9b8vjd2p7fn</id>
        <link href="https://status.twilio.com/incidents/g9b8vjd2p7fn"/>
        <updated>2023-06-16T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[THIS IS A SCHEDULED EVENT Jun 15, 23:00 PDT  -  Jun 16, 05:00 PDT
Jun 14, 10:26 PDT
Scheduled - The AT&T network in Mexico is conducting a planned maintenance from 15 June 2023 at 23:00 PDT until 16 June 2023 at 05:00 PDT. During the maintenance window, there could be intermittent delays delivering SMS to and from AT&T Mexico handsets.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mexico SMS Carrier Maintenance - AT&T]]></title>
        <id>https://status.twilio.com/incidents/wfcjqmlcn24g</id>
        <link href="https://status.twilio.com/incidents/wfcjqmlcn24g"/>
        <updated>2023-06-16T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[THIS IS A SCHEDULED EVENT Jun 15, 23:00 PDT  -  Jun 16, 05:00 PDT
Jun 13, 18:18 PDT
Scheduled - The AT&T network in Mexico is conducting a planned maintenance from 15 June 2023 at 23:00 PDT until 16 June 2023 at 05:00 PDT. During the maintenance window, there could be intermittent delays delivering SMS to and from AT&T Mexico handsets.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SMS delivery Delays to Brazil from Short Codes and Registered Sender IDs]]></title>
        <id>https://status.twilio.com/incidents/2s35h2hh7ykq</id>
        <link href="https://status.twilio.com/incidents/2s35h2hh7ykq"/>
        <updated>2023-06-15T23:36:42.000Z</updated>
        <summary type="html"><![CDATA[Jun 15, 16:36 PDT
Resolved - We are no longer experiencing SMS delivery delays when sending messages to Brazil from short codes and registered sender IDs. This incident has been resolved.
Jun 15, 15:08 PDT
Monitoring - We are observing recovery in SMS delivery delays when sending messages to Brazil from short codes and registered sender IDs. We will continue monitoring the service to ensure a full recovery. We will provide another update in 2 hours or as soon as more information becomes available.
Jun 15, 13:01 PDT
Update - We continue experiencing SMS delivery delays when sending messages to Brazil from short codes and registered sender IDs. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 2 hours or as soon as more information becomes available.
Jun 15, 11:50 PDT
Update - We are experiencing SMS delivery delays when sending messages to Brazil from short codes and registered sender IDs. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 1 hour or as soon as more information becomes available.
Jun 15, 11:42 PDT
Investigating - Our monitoring systems have detected a potential issue with SMS delivery delays to Brazil from short codes and registered sender IDs. Our engineering team has been alerted and is actively investigating. We will update as soon as we have more information.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Some users may notice slow performance throughout Slack]]></title>
        <id>https://status.slack.com//2023-06/7363f55dbcde89c1</id>
        <link href="https://status.slack.com//2023-06/7363f55dbcde89c1"/>
        <updated>2023-06-15T23:28:00.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:


On June 15, 2023 from 8:10 AM PDT to around 8:20 AM PDT, some users may have experienced slow performance and errors while loading conversations, sending messages and taking other actions in Slack.


We traced the issue to a recent code change which caused connection failures. We reverted this change and all affected functionality should be restored for users. Thank you for your patience while we resolved this issue.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SMS Delivery Delays to Brazil CTBC Network]]></title>
        <id>https://status.twilio.com/incidents/45xxth0d9pbc</id>
        <link href="https://status.twilio.com/incidents/45xxth0d9pbc"/>
        <updated>2023-06-15T23:23:27.000Z</updated>
        <summary type="html"><![CDATA[Jun 15, 16:23 PDT
Resolved - We are no longer experiencing SMS delivery delays when sending messages to Brazil CTBC Network. This incident has been resolved.
Jun 15, 14:37 PDT
Update - We are observing recovery in SMS delivery delays when sending messages to Brazil CTBC Network. We will continue monitoring the service to ensure a full recovery. We will provide another update in 2 hours or as soon as more information becomes available.
Jun 15, 12:30 PDT
Update - We are observing recovery in SMS delivery delays when sending messages to Brazil CTBC Network. We will continue monitoring the service to ensure a full recovery. We will provide another update in 2 hours or as soon as more information becomes available.
Jun 15, 10:30 PDT
Monitoring - We are observing recovery in SMS delivery delays when sending messages to Brazil CTBC Network. We will continue monitoring the service to ensure a full recovery. We will provide another update in 2 hours or as soon as more information becomes available.
Jun 15, 08:41 PDT
Update - We are continuing to experience SMS delivery delays when sending messages to Brazil CTBC Network. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 2 hours or as soon as more information becomes available.
Jun 15, 07:43 PDT
Investigating - We are experiencing SMS delivery delays when sending messages to Brazil CTBC Network. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 1 hour or as soon as more information becomes available.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Issue affecting listings bedrooms, bathrooms and beds]]></title>
        <id>https://airbnbapi.statuspage.io/incidents/620bns7c4y3p</id>
        <link href="https://airbnbapi.statuspage.io/incidents/620bns7c4y3p"/>
        <updated>2023-06-15T21:38:31.000Z</updated>
        <summary type="html"><![CDATA[Jun 15, 14:38 PDT
Monitoring - We are currently addressing a bug that affects the bedroom, bathroom, and bed count on our Listings API. Due to a change in behavior of how bedrooms, bathrooms and beds interact with the Listing Rooms API, you might come across the following issues:
* On the Listings API, some listings might have the fields `bedrooms`,`bathrooms` and/or `beds` set to 0.
* On the Listings Rooms API, some rooms might have been created/deleted.
As of today, we have reverted the problematic behavior and are working diligently to restore the correct bedrooms, bathrooms, and beds values on the Listings API. To ensure that your Listing Rooms are accurately set, we kindly ask you to re-sync your data.
We apologize for any inconvenience this may cause and appreciate your understanding as we resolve this issue.]]></summary>
        <author>
            <name>Airbnb API Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SMS Delivery delays to MTN Network in Cameroon]]></title>
        <id>https://status.twilio.com/incidents/mv0wxrd8q5zw</id>
        <link href="https://status.twilio.com/incidents/mv0wxrd8q5zw"/>
        <updated>2023-06-15T21:31:32.000Z</updated>
        <summary type="html"><![CDATA[Jun 15, 14:31 PDT
Update - We continue experiencing SMS delivery delays when sending messages to MTN Network in Cameroon. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 4 hours or as soon as more information becomes available.
Jun 15, 12:21 PDT
Update - We continue experiencing SMS delivery delays when sending messages to MTN Network in Cameroon. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 2 hours or as soon as more information becomes available.
Jun 15, 11:20 PDT
Investigating - We are experiencing SMS delivery delays when sending messages to MTN Network in Cameroon. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 1 hour or as soon as more information becomes available.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[RESOLVED: We're aware of a problem with Admin Console affecting a subset of Google Workspace Administrators. Some Google Workspace Administrators may experience issues when performing List, Create, Update, or Delete operations for OrgUnits using the Admin Console or Directory APIs. Attempting to navigate to the admin.google.com/ac/users/]]></title>
        <id>https://www.google.com/appsstatus/dashboard/incidents/1jNfhkFKus49vEyaUQLm</id>
        <link href="https://www.google.com/appsstatus/dashboard/incidents/1jNfhkFKus49vEyaUQLm"/>
        <updated>2023-06-15T21:23:03.000Z</updated>
        <summary type="html"><![CDATA[<p> Incident began at <strong>2023-06-02 19:25</strong> and ended at <strong>2023-06-03 11:57</strong> <span>(times are in <strong>Coordinated Universal Time (UTC)</strong>).</span></p><div class="cBIRi14aVDP__status-update-text"><h1>Incident Report</h1>
<h2>Summary</h2>
<p>From Friday, 2 June 2023 to Saturday, 3 June 2023, some Google Workspace Administrators experienced issues performing List, Create, Update, or Delete operations for users and organizational units (OU) when using the Admin Console or Directory APIs. The total outage duration was 16 hours and 32 minutes. We have conducted an internal investigation and are taking steps to improve our service.</p>
<h2>Root Cause</h2>
<p>The Google Workspace Admin Console and Directory APIs use a backend service to authorize requests to create/update/delete/read user and OU resources. A workflow synchronizes user and OU resources to that backend authorization service.</p>
<p>On Friday, 2 June 2023 at 12:25 PDT, engineers rolled out a configuration change that inadvertently caused the workflow to stop synchronizing resources to the authorization service. Because the authorization service was not aware of the new resources (those created during the outage), it was unable to authorize requests and returned a 403 Unauthorized error. The incorrect configuration went undetected before being deployed to production because the automatic pre-submit checks had been suppressed because engineers incorrectly believed the change was safe.</p>
<h2>Remediation and Prevention</h2>
<p>Google engineers were alerted to the outage via a support case on 2 June 2023 at 19:33 PDT and immediately started an investigation. Engineers identified that the roll out of the configuration change aligned with the start of 403 Unauthorized errors and initiated a rollback on 3 June 2023 at 00:14 PDT. The rollback completed at 00:57 PDT, mitigating the issue for new users and OU resources created after that time. Engineers performed a backfill to synchronize the impacted users and OU resources that were created after the start of the issue, fully mitigating the issue at 04:57 PDT.</p>
<p>Google is committed preventing a repeat of this issue in the future and is completing the following actions:</p>
<ul>
<li>We will be updating the pre-submit checks for workflow configuration changes to better identify potential issues before rolling out to production.</li>
<li>We will be adding a requirement to have a designated reviewer approve workflow configuration changes to ensure that automated presubmit checks are being run before rolling out to production.</li>
</ul>
<h2>Detailed Description of Impact</h2>
<p>From 2 June 2023 at 12:25 PDT to 3 June 2023 at 04:57, Google Workspace Administrators may have experienced 403 Unauthorized errors when attempting to perform actions for user and OU resources via Admin Console or Directory APIs. This issue affected Create, Fetch, Update, Delete and other related operations for user and OU resources created between 2 June 2023 at 12:25 PDT and 3 June 2023 at 00:57 PDT.</p>
</div><hr><p>Affected products: Admin Console</p>]]></summary>
        <author>
            <name>Google Workspace Status Dashboard Updates</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Indonesia Voice Carrier Partner Maintenance]]></title>
        <id>https://status.twilio.com/incidents/7s20z75gf18r</id>
        <link href="https://status.twilio.com/incidents/7s20z75gf18r"/>
        <updated>2023-06-15T20:01:11.000Z</updated>
        <summary type="html"><![CDATA[Jun 15, 13:01 PDT
Completed - The scheduled maintenance has been completed.
Jun 15, 10:06 PDT
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
Jun  8, 18:21 PDT
Scheduled - Our Voice carrier partner is conducting an emergency maintenance from 15 June 2023 at 10:05 PDT until 15 June 2023 at 13:00 PDT. During the maintenance window, there could be intermittent call disconnects and failures for calls to and from a subset of Twilio Indonesia phone numbers.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Copilot]]></title>
        <id>https://www.githubstatus.com/incidents/6tfr2b2s2073</id>
        <link href="https://www.githubstatus.com/incidents/6tfr2b2s2073"/>
        <updated>2023-06-15T19:36:17.000Z</updated>
        <summary type="html"><![CDATA[Jun 15, 19:36 UTC
Resolved - This incident has been resolved.
Jun 15, 19:22 UTC
Investigating - We are investigating reports of degraded performance for Copilot.]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Trouble with workflows, loading channels and accessing Slack]]></title>
        <id>https://status.slack.com//2023-06/20df18536cc9524b</id>
        <link href="https://status.slack.com//2023-06/20df18536cc9524b"/>
        <updated>2023-06-15T18:31:06.000Z</updated>
        <summary type="html"><![CDATA[Issue Summary:

From June 14, 2023 at 3:44 PM PDT until June 15, 2023 at 4:30 AM PDT, some customers may have been unable to send messages, join Huddles, run workflows, and access Slack.


A recent code change caused some resources on our backend web hosting service to be temporarily exhausted. Due to this, users experienced errors when joining Huddles, sending messages, and may have had their connection to Slack reset. We identified the issue and reverted the change restoring full functionality to these features.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Pages]]></title>
        <id>https://www.githubstatus.com/incidents/h3vqt1fvp9tc</id>
        <link href="https://www.githubstatus.com/incidents/h3vqt1fvp9tc"/>
        <updated>2023-06-15T16:57:15.000Z</updated>
        <summary type="html"><![CDATA[Jun 15, 16:57 UTC
Resolved - This incident has been resolved.
Jun 15, 16:47 UTC
Update - Due to an issue with Let's Encrypt, obtaining a new HTTPS certificate for Pages sites is delayed.
Jun 15, 16:34 UTC
Investigating - We are investigating reports of degraded performance for Pages.]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Germany Account Security Carrier Partner Maintenance]]></title>
        <id>https://status.twilio.com/incidents/88j70s2wfb8n</id>
        <link href="https://status.twilio.com/incidents/88j70s2wfb8n"/>
        <updated>2023-06-15T16:00:14.000Z</updated>
        <summary type="html"><![CDATA[Jun 15, 09:00 PDT
Completed - The scheduled maintenance has been completed.
Jun 15, 02:00 PDT
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
Jun  7, 16:03 PDT
Scheduled - Our Carrier Partner Telekom is conducting a planned maintenance from 15 June 2023 at 02:00 PDT until 15 June 2023 at 09:00 PDT. During the maintenance window, there could be intermittent API request failures for Telekom customers.
Impacted Products: SNA, Lookup SIM Swap and Identity Match]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Networking in Europe Datacenters (AMS, FRA, LON)]]></title>
        <id>https://status.digitalocean.com/incidents/1d5qv6pmsv6b</id>
        <link href="https://status.digitalocean.com/incidents/1d5qv6pmsv6b"/>
        <updated>2023-06-15T03:37:51.000Z</updated>
        <summary type="html"><![CDATA[Jun 15, 03:37 UTC
Resolved - Our Engineering team has confirmed the full resolution of the issue impacting networking in our European regions.
From 16:40 UTC to 02:10 UTC, Users may have experienced network timeouts, packet loss, and/or increased latency interacting with the resources in these regions (AMS2/3, FRA1 & LON1).
If you continue to experience problems, please open a ticket with our Support team. Thank you for your patience and we apologize for the inconvenience.
Jun 15, 02:40 UTC
Monitoring - The network issues affecting our European regions have been mitigated. Users should no longer experience packet loss/latency, timeouts, and related issues with Droplet-based services in those regions, including Droplets, Managed Kubernetes, and Managed Database.
We will continue to monitor network conditions for a period of time to establish a return to pre-incident conditions.
Jun 15, 01:26 UTC
Update - Our engineering team continues to investigate the ongoing issues impacting the networking in our European data centres including AMS2/3, FRA1 & LON1 regions. During this time, you may experience intermittent packet loss or increased latency while interacting with the resources in these regions. We apologize for the inconvenience and will share an update once we have more information.
Jun 14, 20:06 UTC
Investigating - From 16:40 UTC our Engineering team is investigating an issue impacting the networking in our European data centers including AMS2/3, FRA1 & LON1 regions. During this time, you may experience intermittent packet loss or increased latency while interacting with the resources in these regions.
At the moment, all the droplet-based services appear to be impacted and the users can expect to see brief connectivity issues and interrupted traffic flows. This will also be impacting services including Spaces and Managed Databases. 
We apologize for the inconvenience and will share an update once we have more information.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Issues Affecting Guest Name Parameters in Webhooks]]></title>
        <id>https://airbnbapi.statuspage.io/incidents/qn4kgtck381x</id>
        <link href="https://airbnbapi.statuspage.io/incidents/qn4kgtck381x"/>
        <updated>2023-06-14T23:46:33.000Z</updated>
        <summary type="html"><![CDATA[Jun 14, 16:46 PDT
Identified - Unfortunately, the mitigation did not resolve the issue and we are still seeing reservation acceptance confirmation webhooks missing the guest last name. Please know our engineering teams are working to get this issue resolved, and we will update you with the latest information as soon as possible. Meanwhile, please use the GET reservations API for any reservations that did not include the guest last name within the webhooks. We apologize for the inconvenience.
Jun 12, 08:41 PDT
Monitoring - We have implemented a fix for this issue and are monitoring the results. Apologies for the inconvenience caused.
Jun  9, 00:12 PDT
Identified - The issue has been identified and we are working on a fix.
Meanwhile, please attempt GET reservations requests for any reservations that did not include the guest names in full within the webhooks.
Jun  8, 19:36 PDT
Investigating - We are currently investigating an issue where guest names are not returned in full within webhooks - namely the reservation acceptance confirmation webhooks. This is not a widespread issue and is only affecting a small percentage of webhooks.
Alternatively, you may be able to retrieve the details with GET reservations requests.
We will post updates as soon as we know more.
Apologies for the inconvenience caused and thank you for your understanding.]]></summary>
        <author>
            <name>Airbnb API Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scheduled Maintenance]]></title>
        <id>https://status.make.com/incidents/413nrl6rvmsx</id>
        <link href="https://status.make.com/incidents/413nrl6rvmsx"/>
        <updated>2023-06-14T11:00:40.000Z</updated>
        <summary type="html"><![CDATA[Jun 14, 13:00 CEST
Completed - The scheduled maintenance has been completed.
Jun 14, 11:00 CEST
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
Jun 13, 15:02 CEST
Scheduled - We would like to inform you about a scheduled maintenance window that will be taking place on 14th June between 11:00 CEST - 13:00 CEST.
During this maintenance period, there will be a short interruption resulting in the unavailability of the login page and organisations page. 
If you experience a blank page , clearing your browser cache might resolve the issue . If not please reach out to our customer care team.
However, we assure you that there will be no data loss and all scenarios will continue running properly.
We apologize for any inconvenience caused and appreciate your understanding.]]></summary>
        <author>
            <name>Make Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Trouble with workflows and clips transcripts]]></title>
        <id>https://status.slack.com//2023-06/a0c185e5ad5eac55</id>
        <link href="https://status.slack.com//2023-06/a0c185e5ad5eac55"/>
        <updated>2023-06-14T03:06:22.000Z</updated>
        <summary type="html"><![CDATA[Issue summary: 

On June 13, 2023 from 11:55 AM PDT to around 3:47 PM PDT, some users may have experienced failure with clips transcribing and transcoding, execution of workflows with custom functions, new deployments of apps with hosted functions, and some delay when using canvases in Slack. 


These issues were due to an outage from an upstream service provider which affected many services. The provider actively worked to remediate those issues, which then fully resolved the reported failures for impacted Slack users.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[v2021.12.31 Webhook Migration Enforcement - Phase 1]]></title>
        <id>https://airbnbapi.statuspage.io/incidents/bf02v30139sd</id>
        <link href="https://airbnbapi.statuspage.io/incidents/bf02v30139sd"/>
        <updated>2023-06-13T07:00:43.000Z</updated>
        <summary type="html"><![CDATA[Jun 13, 00:00 PDT
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
Jun 12, 11:00 PDT
Scheduled - The deprecation date for API Webhook Version 2021.12.31 was May 31, 2023. Any applications that have not fully migrated webhooks will be automatically migrated to a newer version, which can result in application breakage.
Automatic webhook migration will occur in phases as detailed in https://developer.airbnb.com/docs/versioning-enforcement
Phase 1 will occur during the week of June 12th, 2023 and will automatically migrate all async webhooks (except Messaging, Reviews and Reservations).]]></summary>
        <author>
            <name>Airbnb API Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Actions and Pages]]></title>
        <id>https://www.githubstatus.com/incidents/csnbwc85chp2</id>
        <link href="https://www.githubstatus.com/incidents/csnbwc85chp2"/>
        <updated>2023-06-13T00:17:05.000Z</updated>
        <summary type="html"><![CDATA[Jun 13, 00:17 UTC
Resolved - This incident has been resolved.
Jun 13, 00:09 UTC
Update - We have applied a mitigation and are seeing signs of recovery. We will post another update shortly.
Jun 12, 23:39 UTC
Update - We are investigating reports of degraded performance for Actions. We have identified the root cause and have begun applying a mitigation.
Jun 12, 22:48 UTC
Update - Pages is experiencing degraded performance. We are still investigating and will provide an update when we have one.
Jun 12, 22:43 UTC
Investigating - We are investigating reports of degraded performance for Actions.]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Container Registry in FRA1 and SGP1]]></title>
        <id>https://status.digitalocean.com/incidents/rptq6jh8ljd7</id>
        <link href="https://status.digitalocean.com/incidents/rptq6jh8ljd7"/>
        <updated>2023-06-12T17:44:00.000Z</updated>
        <summary type="html"><![CDATA[Jun 12, 17:44 UTC
Resolved - From 04:30 to 09:30 UTC, our Engineering team observed issues with DigitalOcean Container Registry in SGP1 and FRA1 regions. During this time, users might have experienced errors while interacting with their registries in SGP1 and FRA1 regions. Users might also have experienced latency in pushing/pulling images to/from registries.
Our Engineering team has observed that the impact has been mitigated. As of 17:20 UTC, users should no longer experience any issues with pushing/pulling images to/from their registries in SGP1 and FRA1 regions. We apologize for the inconvenience. If you are still experiencing any problems or have additional questions, please open a support ticket within your account.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Small number of users might be experiencing connectivity issues]]></title>
        <id>https://status.slack.com//2023-06/1bd97a73cb7874f1</id>
        <link href="https://status.slack.com//2023-06/1bd97a73cb7874f1"/>
        <updated>2023-06-12T14:56:48.000Z</updated>
        <summary type="html"><![CDATA[On June 11, 2023 from 10:57 AM PDT to 12:10 PM PDT, some users may have experienced difficulties when trying to access Slack due to a database issue.


The underlying cause has since been determined and remediation steps were applied. This resolved the above for all impacted users.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Pull Requests]]></title>
        <id>https://www.githubstatus.com/incidents/0csnqhwzxp1m</id>
        <link href="https://www.githubstatus.com/incidents/0csnqhwzxp1m"/>
        <updated>2023-06-09T23:17:57.000Z</updated>
        <summary type="html"><![CDATA[Jun  9, 23:17 UTC
Resolved - This incident has been resolved.
Jun  9, 22:46 UTC
Update - We are investigating elevated error rates on Pull Requests. We will continue to keep users updated on progress towards mitigation.
Jun  9, 22:18 UTC
Investigating - We are investigating reports of degraded performance for Pull Requests.]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Modifying DNS records via Cloud Control Panel]]></title>
        <id>https://status.digitalocean.com/incidents/5jvv4xltnbk7</id>
        <link href="https://status.digitalocean.com/incidents/5jvv4xltnbk7"/>
        <updated>2023-06-08T22:53:00.000Z</updated>
        <summary type="html"><![CDATA[Jun  8, 22:53 UTC
Resolved - Our Engineering team has confirmed that the issue impacting the modification of the DNS records for the existing domains via the Cloud Control Panel is fully resolved. 
If you continue to experience problems please open a ticket with our support team. Thank you for your patience and we apologize for the inconvenience.
Jun  8, 22:31 UTC
Monitoring - Our engineering team has implemented a fix to resolve the issue that affected the modification of the DNS records for the existing domains via the Cloud Control Panel. Users should now be able to modify or create new DNS records for the domains within their Cloud Control Panel.
We are monitoring the situation and will post another update once we confirm it is fully resolved.
Jun  8, 21:56 UTC
Investigating - Our Engineering team is investigating an issue with modifying or creating new DNS records in our Cloud Control Panel for the existing domains. 
During this time, some users may experience issues editing the DNS records from within the Cloud Control Panel and also when navigating through the tabs available in the domain section. Users should be able to modify or add new DNS records to the existing domains using the API.
We apologize for the inconvenience and will share an update once we have more information.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Pull Requests]]></title>
        <id>https://www.githubstatus.com/incidents/17c40y7spfgl</id>
        <link href="https://www.githubstatus.com/incidents/17c40y7spfgl"/>
        <updated>2023-06-08T12:55:12.000Z</updated>
        <summary type="html"><![CDATA[Jun  8, 12:55 UTC
Resolved - This incident has been resolved.
Jun  8, 12:55 UTC
Update - Our team continues to mitigate the impacted search results however we are going to status to green due to impact on overall service. We will continue to post updates on the status page as we mitigate
Jun  8, 12:23 UTC
Update - We are aware search results for PRs are returning incomplete results in certain scenarios. This is impacting most users. No other search results are impacted. All other PR functionality is working.
Jun  8, 11:58 UTC
Investigating - We are investigating reports of degraded performance for Pull Requests.]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[NYC3 Network Maintenance 2023-06-08 04:00 UTC]]></title>
        <id>https://status.digitalocean.com/incidents/tw85s4rhwpqm</id>
        <link href="https://status.digitalocean.com/incidents/tw85s4rhwpqm"/>
        <updated>2023-06-08T08:00:22.000Z</updated>
        <summary type="html"><![CDATA[Jun  8, 08:00 UTC
Completed - The scheduled maintenance has been completed.
Jun  8, 04:00 UTC
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
Jun  8, 03:08 UTC
Scheduled - Start time: 2023-06-08 04:00 UTC
End time: 2023-06-08 08:00 UTC
During the above window, our Networking team will be performing maintenance on core switches in our NYC3 datacenter as a part of network upgrades.
Expected Impact:
These upgrades are designed and tested to be seamless and we do not expect any impact to customer traffic due to this maintenance. If an unexpected issue arises, affected Droplets and Droplet-based services may experience a temporary loss of connectivity. We will endeavor to keep any such impact to a minimum.
If you have any questions or concerns regarding this maintenance, please reach out to us by opening up a ticket on your account via https://cloudsupport.digitalocean.com/s/createticket .]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scenarios using Custom Variables not working properly]]></title>
        <id>https://status.make.com/incidents/ts75knvtfm16</id>
        <link href="https://status.make.com/incidents/ts75knvtfm16"/>
        <updated>2023-06-07T22:47:29.000Z</updated>
        <summary type="html"><![CDATA[Jun  8, 00:47 CEST
Resolved - This incident is now resolved.
Jun  7, 21:32 CEST
Update - We have applied a permanent fix on eu1.make.celonis.com and eu1.make.com, and based on our checks there are no issues and all scenarios are running as expected.
Jun  7, 21:18 CEST
Update - We are applying a fix for this issue.
Jun  7, 13:13 CEST
Update - We have applied a permanent fix on us1.make.celonis.com and us1.make.com, and based on our checks there are no issues and all scenarios are running as expected.
In regards to eu1.make.celonis.com and eu1.make.com, we are going to roll out the fix outside of business hours. 
Please use the workaround as needed, it was described in the previous update.
We will post another update once a full fix is applied.
Jun  6, 11:39 CEST
Identified - We're currently experiencing an issue that appears only in certain unique circumstances when a running scenario is not properly using the values of team or organization variables during executions.
Specific circumstances for the issue are:
- A team or organization variable is used as a filter condition OR there is more than one team or organization variable referenced within a single mapped field, OR the variable is used inside a function.
- AND the scenario was created / modified before March 8, 2023 
- AND the execution occurs after May 3, 2023
Workaround: 
Any user encountering this issue can open the affected scenario, make any change (move a module) and hit save. This will immediately resolve the issue for that scenario.
Complete resolution: 
The development team is actively working on a fix that will address any scenario where the issue still persists. Will post an update once we have more information around the permanent fix.
Jun  6, 09:09 CEST
Investigating - We're currently experiencing issues with Scenarios that use Custom Variables. Our engineering team is investigating the root cause.]]></summary>
        <author>
            <name>Make Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Actions, Pull Requests and Webhooks]]></title>
        <id>https://www.githubstatus.com/incidents/1g1gkh0qpyvs</id>
        <link href="https://www.githubstatus.com/incidents/1g1gkh0qpyvs"/>
        <updated>2023-06-07T18:39:02.000Z</updated>
        <summary type="html"><![CDATA[Jun  7, 18:39 UTC
Resolved - This incident has been resolved.
Jun  7, 18:32 UTC
Update - Repository push workers are continuing to catch up with enqueued jobs.
Jun  7, 17:58 UTC
Update - We have mitigated the problem and are waiting for our repository push workers to catch up with enqueued jobs.
Jun  7, 17:42 UTC
Update - We have identified the cause of delayed processing for commits pushed to repositories and are actively working on mitigating this issue.
Jun  7, 17:31 UTC
Update - Webhooks is experiencing degraded performance. We are continuing to investigate.
Jun  7, 17:29 UTC
Update - Actions is experiencing degraded performance. We are still investigating and will provide an update when we have one.
Jun  7, 16:53 UTC
Update - Pushes to repositories may take longer for a significant number of customers. We are actively investigating.
Jun  7, 16:45 UTC
Investigating - We are investigating reports of degraded availability for Pull Requests.]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Issues with the Google Workspace integration]]></title>
        <id>https://status.rippling.com/incidents/tvr7l7344y0y</id>
        <link href="https://status.rippling.com/incidents/tvr7l7344y0y"/>
        <updated>2023-06-07T13:43:53.000Z</updated>
        <summary type="html"><![CDATA[Jun  7, 13:43 UTC
Resolved - This incident has been resolved.
Jun  6, 20:27 UTC
Update - We are continuing to monitor for any further issues.
Jun  6, 18:43 UTC
Monitoring - Google has implemented a fix and we are monitoring the results. Customers should be able to add new licenses and transfer subscriptions via the Google Workspace App in Rippling.
Jun  5, 22:07 UTC
Identified - We are continuing to work with Google to resolve an issue that is affecting our integration.
Jun  5, 17:32 UTC
Investigating - Customers are currently unable to add new licenses and transfer subscriptions via the Google Workspace App in Rippling. We are currently working with Google to resolve this issue.]]></summary>
        <author>
            <name>Rippling Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Some files may not be unfurling as expected]]></title>
        <id>https://status.slack.com//2023-06/6cb0bb4f227a82e8</id>
        <link href="https://status.slack.com//2023-06/6cb0bb4f227a82e8"/>
        <updated>2023-06-06T11:15:34.000Z</updated>
        <summary type="html"><![CDATA[Thank you for your patience while our team investigated this. All new file uploads are now expected to generate thumbnails for affected users and the issue has been resolved. Please note that previous attempts won't be retried, however new files should function as normal.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scheduled maintenance]]></title>
        <id>https://status.make.com/incidents/ms6hw0p562v8</id>
        <link href="https://status.make.com/incidents/ms6hw0p562v8"/>
        <updated>2023-06-06T08:00:15.000Z</updated>
        <summary type="html"><![CDATA[Jun  6, 10:00 CEST
Completed - The scheduled maintenance has been completed.
Jun  6, 08:00 CEST
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
Jun  1, 15:57 CEST
Scheduled - We would like to inform you about a scheduled maintenance window that will be taking place on 6th June between 08:00 CEST - 10:00 CEST.
During this maintenance period, there will be a short interruption resulting in the unavailability of the login page and organizations page. 
However, we assure you that there will be no data loss and all scenarios will continue running properly.
We apologize for any inconvenience caused and appreciate your understanding.]]></summary>
        <author>
            <name>Make Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Notion.so down]]></title>
        <id>https://status.notion.so/incidents/j5jk1f1ytyz1</id>
        <link href="https://status.notion.so/incidents/j5jk1f1ytyz1"/>
        <updated>2023-06-05T17:43:47.000Z</updated>
        <summary type="html"><![CDATA[Jun  5, 10:43 PDT
Resolved - This has been resolved -- all users can access notion.so without issue again.
Jun  5, 09:53 PDT
Investigating - The notion.so site is down for some users, we are investigating. Users can still log in and access their workspaces at notion.so/login.]]></summary>
        <author>
            <name>Notion Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Notion production outage]]></title>
        <id>https://status.notion.so/incidents/vpm90b50y09t</id>
        <link href="https://status.notion.so/incidents/vpm90b50y09t"/>
        <updated>2023-06-05T16:30:00.000Z</updated>
        <summary type="html"><![CDATA[Jun  5, 09:30 PDT
Resolved - Notion was down from around 9:25am - 9:40am Pacific time.  We are still investigating an issue that may be preventing some users from accessing notion.so while not logged in.]]></summary>
        <author>
            <name>Notion Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Issues with Workflow Builder]]></title>
        <id>https://status.slack.com//2023-06/f7c5d1e455e95466</id>
        <link href="https://status.slack.com//2023-06/f7c5d1e455e95466"/>
        <updated>2023-06-05T09:01:22.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:


On June 02, 2023 from 3:28 PM PDT to around 5:29 PM PDT, some customers may have experienced large empty spaces in the Workflow Builder UI and issues with publishing/adding or editing steps in a workflow. 


We traced the issue to a recent code change which caused the channel selector to appear out of view, resulting in the inability to take certain actions while editing a workflow. 


We reverted the change which solved the issue for all customers.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[500 Errors Across Multiple Endpoints]]></title>
        <id>https://airbnbapi.statuspage.io/incidents/xccq5r4gm6c5</id>
        <link href="https://airbnbapi.statuspage.io/incidents/xccq5r4gm6c5"/>
        <updated>2023-06-02T15:35:47.000Z</updated>
        <summary type="html"><![CDATA[Jun  2, 08:35 PDT
Resolved - This issue is now resolved. The incident that occurred yesterday (June 1, 2023) resulted in an elevated amount of 500 errors across multiple endpoints, for approximately 1 hour. If you are still encountering a high volume of 500 errors, please reach out to us through the Support Portal so we can assist you further.
We apologize for any inconvenience this may have caused.
Jun  1, 13:34 PDT
Monitoring - We have implemented a fix for the issue, and the error rate has dropped significantly. We will continue to monitor the results
Jun  1, 12:51 PDT
Identified - We are actively investigating an increased number of 500 errors across multiple endpoints. These errors started today (June 1, 2023) around 12:20 PM PDT. Please know our engineering and operations teams are working hard to get everything up and running again, and we will update you with the latest information as soon as possible]]></summary>
        <author>
            <name>Airbnb API Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Notion.so down]]></title>
        <id>https://status.notion.so/incidents/crfw2mn48z7m</id>
        <link href="https://status.notion.so/incidents/crfw2mn48z7m"/>
        <updated>2023-06-02T12:26:37.000Z</updated>
        <summary type="html"><![CDATA[Jun  2, 05:26 PDT
Resolved - The issue has been resolved, and notion.so is available to all users
Jun  2, 04:53 PDT
Investigating - The notion.so site is down for some users, we are investigating. Users can still log in and access their workspaces at notion.so/login.]]></summary>
        <author>
            <name>Notion Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Some users are reporting issues triggering shortcut Workflows]]></title>
        <id>https://status.slack.com//2023-05/d3da25ad25333a58</id>
        <link href="https://status.slack.com//2023-05/d3da25ad25333a58"/>
        <updated>2023-06-01T18:00:28.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:


From May 19, 2023 at 12:00 AM PDT until May 25, 2023 at 8:00 AM PDT, some users may have experienced issues triggering shortcut workflows.


We carried out our investigation and determined that cached data on the back end temporarily broke legacy workflows. In the process of determining our path to a resolution the issue resolved itself. We are taking the necessary steps to prevent similar issues in the future.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Users reporting issues with keyboard shortcuts]]></title>
        <id>https://status.slack.com//2023-05/223e97529097de1c</id>
        <link href="https://status.slack.com//2023-05/223e97529097de1c"/>
        <updated>2023-06-01T05:57:52.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:

On May 31, 2023 from 5:15 PM PDT to 7:12 PM PDT, some customers experienced issues with using keyboard shortcuts. 


We’ve traced that this issue was caused by a recent code change. We’ve rolled back this change, resolving the issue for all impacted customers.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SFO2 Network Maintenance 2023-06-01 01:00 UTC Phase 2]]></title>
        <id>https://status.digitalocean.com/incidents/r8yz7801sh9w</id>
        <link href="https://status.digitalocean.com/incidents/r8yz7801sh9w"/>
        <updated>2023-06-01T03:01:07.000Z</updated>
        <summary type="html"><![CDATA[Jun  1, 03:01 UTC
Completed - The scheduled maintenance has been completed.
Jun  1, 01:00 UTC
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
May 31, 23:11 UTC
Scheduled - Start: 2023-06-01 01:00 UTC
End: 2023-06-01 05:00 UTC
During the above window, our Networking team will be making changes to our core networking infrastructure to improve performance and scalability in the SFO2 region. This will be the second of the two maintenance activities performed by our team in the region on consecutive days.
Expected Impact:
These upgrades are designed and tested to be seamless and we do not expect any impact to customer traffic due to this maintenance. If an unexpected issue arises, affected Droplets and Droplet-based services may experience a temporary loss of private connectivity between VPCs. We will endeavor to keep any such impact to a minimum.
If you have any questions or concerns regarding this maintenance, please reach out to us by opening up a ticket on your account via https://cloudsupport.digitalocean.com/s/createticket .]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Autocomplete results ranking in search degraded]]></title>
        <id>https://status.slack.com//2023-05/aa025f4aef896b16</id>
        <link href="https://status.slack.com//2023-05/aa025f4aef896b16"/>
        <updated>2023-05-31T23:27:14.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:

From May 30th, 2023 at 8:02 AM PDT until 11:18 AM PDT, some users experienced unexpected behavior with autocomplete suggestions, including incorrect rankings & incomplete results when conducting searches.


We traced the source of the issue back to an error that occurred in our autocomplete cache. A fix was rolled out to our search logic which began to show the correct results.


Users can refresh their Slack client (by pressing Cmd/Ctrl + Shift + R) if they are still experiencing issues. We apologize for any interruption.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Reacji Channeler app is failing for some users]]></title>
        <id>https://status.slack.com//2023-05/0848cba206ef2188</id>
        <link href="https://status.slack.com//2023-05/0848cba206ef2188"/>
        <updated>2023-05-31T23:04:00.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:

From May 30th, 2023 at around 8:00 PM PDT until May 31st, 2023 at 9:20 AM PDT, users with the Reacji Channeler app installed in their workspace experienced some issues where the app would not execute.


The issue was traced back to a recent change that occurred for one of our app databases. This caused the app to accept new requests even though it was unable to connect to the database, resulting in timeout errors. 


We reverted the change and restarted the backend processes which allowed the app to connect to the database again, resolving the issue for impacted users. We apologize for any disruptions to your day.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scheduled maintenance]]></title>
        <id>https://status.make.com/incidents/2vlc5cz18jbn</id>
        <link href="https://status.make.com/incidents/2vlc5cz18jbn"/>
        <updated>2023-05-31T08:00:42.000Z</updated>
        <summary type="html"><![CDATA[May 31, 10:00 CEST
Completed - The scheduled maintenance has been completed.
May 31, 08:02 CEST
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
May 29, 15:34 CEST
Scheduled - We would like to inform you about a scheduled maintenance window that will be taking place on 31st May between 08:00 CEST - 10:00 CEST.
During this maintenance period, there will be a short interruption resulting in the unavailability of the login page and organizations page. 
However, we assure you that there will be no data loss and all scenarios will continue running properly.
We apologize for any inconvenience caused and appreciate your understanding.]]></summary>
        <author>
            <name>Make Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SFO2 Network Maintenance]]></title>
        <id>https://status.digitalocean.com/incidents/4rf2j2dmc382</id>
        <link href="https://status.digitalocean.com/incidents/4rf2j2dmc382"/>
        <updated>2023-05-31T04:04:49.000Z</updated>
        <summary type="html"><![CDATA[May 31, 04:04 UTC
Completed - The scheduled maintenance has been completed.
May 31, 01:30 UTC
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
May 31, 01:26 UTC
Scheduled - Start: 2023-05-31 01:00 UTC
End: 2023-05-31 05:00 UTC

During the above window, our Networking team will be making changes to our core networking infrastructure to improve performance and scalability in the SFO2 region. This maintenance will occur in two parts on consecutive days and we will send another maintenance notice for the second phase. 
Expected Impact:
These upgrades are designed and tested to be seamless and we do not expect any impact to customer traffic due to this maintenance. If an unexpected issue arises, affected Droplets and Droplet-based services may experience a temporary loss of private connectivity between VPCs. We will endeavor to keep any such impact to a minimum.
If you have any questions or concerns regarding this maintenance, please reach out to us by opening up a ticket on your account via https://cloudsupport.digitalocean.com/s/createticket .]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spaces API Availability in NYC3]]></title>
        <id>https://status.digitalocean.com/incidents/vmxnj2vv4k9k</id>
        <link href="https://status.digitalocean.com/incidents/vmxnj2vv4k9k"/>
        <updated>2023-05-31T02:25:35.000Z</updated>
        <summary type="html"><![CDATA[May 31, 02:25 UTC
Resolved - Our Engineering team has confirmed the full resolution of the issue impacting Spaces performance and availability in our NYC3 region.
From 00:20 to 00:57 UTC, users may have experienced slowness or timeouts when trying to access or manage their Spaces resources in NYC3, static site assets in NYC, or App Platform bandwidth insights.
Spaces should now be operating normally. If you continue to experience problems, please open a ticket with our support team from within your Cloud Control Panel. We apologize for any inconvenience.
May 31, 01:47 UTC
Monitoring - Our Engineering team has observed recovery of availability for Spaces in our NYC3 region. 
Availability returned to 100% at 00:57 UTC and since then, users should not be experiencing any issues with Spaces or App Platform. 
We'll now monitor the situation for a period of time and post a final update once we confirm the incident is resolved.
May 31, 01:05 UTC
Investigating - Our Engineering team is investigating a drop in availability for Spaces in our NYC region. During this time, some users may experience errors with API or object requests, be unable to create new buckets in NYC3, and/or see issues with loading Spaces in the Cloud Control Panel. 
Additionally, users of App Platform will be unable to see bandwidth insights in their dashboards and static site users may notice errors fetching assets from Spaces buckets in NYC3. 
We apologize for the inconvenience and will share an update once we have more information.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Subsea Fiber Faults in the APAC region]]></title>
        <id>https://status.digitalocean.com/incidents/qbszx5q5dd19</id>
        <link href="https://status.digitalocean.com/incidents/qbszx5q5dd19"/>
        <updated>2023-05-28T19:16:27.000Z</updated>
        <summary type="html"><![CDATA[May 28, 19:16 UTC
Resolved - Our Engineering team has continued to actively monitor the situation resulting from multiple subsea fiber faults in the APAC region. Over the last few days, our team has continued to make routing changes where possible. 
Crews have been able to complete some cable repairs and we expect to see our network routing stabilize once the repair of a few more cables are completed in the coming weeks. Until then, we expect to see intermittent periods of packet loss and latency on network routes between Singapore and New York City, as well as Singapore and Toronto. These are normally short-lived and happen during Singapore business hours when traffic is heavy. 
Given the relative stability of routes, we will now close out this incident and provide any needed updates sepa…]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Container Registry in SFO3]]></title>
        <id>https://status.digitalocean.com/incidents/93nbbqq83slf</id>
        <link href="https://status.digitalocean.com/incidents/93nbbqq83slf"/>
        <updated>2023-05-26T02:38:56.000Z</updated>
        <summary type="html"><![CDATA[May 26, 02:38 UTC
Resolved - As of 02:10 UTC, Our Engineering team has confirmed that the issue with our Container Registry services in the SFO3 region has been fully resolved. 
All operations should now be operating normally with our Container Registry services. If you continue to experience any trouble with these services please open a ticket with our support team. 
Thank you for your patience and we apologize for the inconvenience.
May 25, 23:31 UTC
Monitoring - As of 22:10 UTC, Our engineering team has implemented a fix to resolve the issue with our Container Registry services in the SFO3 region and is monitoring the situation closely. 
Users should no longer see 500-type errors when uploading/pushing/deleting images, slow cleanup operations, creation failures for new registries, or other errors when interacting with registries in the SFO3 region. 
We are going to continue to monitor the situation and will post an update once we are confident this issue will not recur.
May 25, 16:20 UTC
Investigating - We are observing some customer reports for issues with DigitalOcean Container Registries in the SFO3 region. Our Engineering team is investigating any potential issues that are causing these reports. This seems to be a reoccurrence of the incident mentioned in the below link:
https://status.digitalocean.com/incidents/mmngtxzmm6gs  
At this time, users may see 500 type errors when uploading/pushing/deleting images, slow cleanup operations, creation failures for new registries, or other errors when interacting with registries in SFO3. 
We will post an update as soon as we have further information. Thank you for your patience.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[App Platform Deployments in SFO region]]></title>
        <id>https://status.digitalocean.com/incidents/kg0b7wl8mshl</id>
        <link href="https://status.digitalocean.com/incidents/kg0b7wl8mshl"/>
        <updated>2023-05-25T09:45:27.000Z</updated>
        <summary type="html"><![CDATA[May 25, 09:45 UTC
Resolved - Our Engineering team has confirmed the full resolution of this incident.
From 06:00 - 08:00 UTC, users were unable to create and deploy new Apps and experienced errors when updating, and deploying existing Apps. The App deployments should now be operating normally.
If you continue to experience problems, please open a ticket with our support team from within your Cloud Control Panel.
May 25, 09:20 UTC
Monitoring - Our Engineering team has implemented a fix to resolve the issue with App deployments in the SFO region and is monitoring the situation. We will post an update as soon as the issue is fully resolved.
May 25, 08:47 UTC
Identified - Our Engineering team has identified the cause of the issue with network latency that is impacting the management and creation of Apps in the SFO region and is actively working on a fix. During this time, a subset of users might see errors when updating and deploying new/existing Apps. We will post an update as soon as additional information is available.
May 25, 08:30 UTC
Investigating - Our Engineering team is investigating an issue with network latency that is impacting the management and creation of Apps in the SFO region. As of 06:00 UTC, users are unable to create and deploy new Apps and may see errors when updating, and deploying existing Apps. At this time, previously deployed running Apps are not impacted. We apologize for the inconvenience and will share an update once we have more information.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scheduled maintenance]]></title>
        <id>https://status.make.com/incidents/zgjx54wdw2y9</id>
        <link href="https://status.make.com/incidents/zgjx54wdw2y9"/>
        <updated>2023-05-25T07:00:25.000Z</updated>
        <summary type="html"><![CDATA[May 25, 09:00 CEST
Completed - The scheduled maintenance has been completed.
May 25, 08:00 CEST
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
May 23, 15:00 CEST
Scheduled - We would like to inform you about a scheduled maintenance window that will be taking place on 25th May between 08:00 CEST - 09:00 CEST.
During this maintenance period, there will be a short interruption resulting in the unavailability of the login page and organizations page. 
However, we assure you that there will be no data loss and all scenarios will continue running properly.
We apologize for any inconvenience caused and appreciate your understanding.]]></summary>
        <author>
            <name>Make Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Container Registry in SFO3]]></title>
        <id>https://status.digitalocean.com/incidents/mmngtxzmm6gs</id>
        <link href="https://status.digitalocean.com/incidents/mmngtxzmm6gs"/>
        <updated>2023-05-25T02:49:34.000Z</updated>
        <summary type="html"><![CDATA[May 25, 02:49 UTC
Resolved - Our Engineering team has identified the root cause of the incident to be multiple DB calls causing DB contention. During this time, users might have experienced issues interacting and authenticating with the DigitalOcean Container Registry, creating new container registries, and pushing/deleting images to/from registries.
As of 00:10 UTC, we have confirmed the full resolution of the issue affecting the DigitalOcean Container Registry in the SFO3 region. We appreciate your patience throughout the process and if you continue to experience problems, please open a ticket with our support team for further review.
May 24, 22:53 UTC
Update - Our Engineering team continues to investigate the root cause of this incident but has observed a reduction in the error rate with DigitalOcean Container Registry in the SFO3 region.
At this time, users should no longer experience errors while interacting and authenticating with the DigitalOcean Container Registry, creating new container registries, and pushing/deleting images to/from registries.
We will post an update as soon as we have further information. Thank you for your patience.
May 24, 19:28 UTC
Investigating - Following an uptick in customer reports of issues with DigitalOcean Container Registries in SFO3, our Engineering team is investigating any potential issues that are causing these reports. 
At this time, users may see 500 type errors when uploading/pushing/deleting images, slow cleanup operations, creation failures for new registries, or other errors when interacting with  registries in SFO3. 
We will post an update as soon as we have further information. Thank you for your patience.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: A small percentage of users are experiencing issues with Slack.]]></title>
        <id>https://status.slack.com//2023-05/f1df0cac8d8d8d68</id>
        <link href="https://status.slack.com//2023-05/f1df0cac8d8d8d68"/>
        <updated>2023-05-24T22:29:00.000Z</updated>
        <summary type="html"><![CDATA[On May 23, 2023 between 8:38 AM PDT and 9:44 AM PDT some users were unable to send and edit messages, load threads, join channels and create group DMs.


Our investigation uncovered that a recent code change we made had caused an overwhelming impact on our databases. We rolled this change back and temporarily redirected user traffic as our databases recovered. Once we rolled back the change and our databases were in a healthier state, the issue became resolved for impacted users.


We will continue to implement new ways to detect issues like this early-on.


Thank you for your patience while we investigated and resolved the issue.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Snapshots and Backups Failure in SGP1]]></title>
        <id>https://status.digitalocean.com/incidents/y3033ln7n73w</id>
        <link href="https://status.digitalocean.com/incidents/y3033ln7n73w"/>
        <updated>2023-05-24T21:30:01.000Z</updated>
        <summary type="html"><![CDATA[May 24, 21:30 UTC
Resolved - As of 21:15 UTC, Our Engineering team has confirmed the full resolution of this incident. We have verified that the Snapshot and Backup events in the SGP1 region are processing without any failures and we will now mark this issue as resolved. 
Thank you for your patience and understanding throughout this process. If you should encounter any further issues at all, then please open a ticket with our Support team.
May 24, 21:05 UTC
Update - We are continuing to monitor for any further issues.
May 24, 20:44 UTC
Monitoring - As of 19:30 UTC, Our Engineering team was able to take action to mitigate the impact of this incident and allow Snapshot and Backup events to process normally in the SGP1 region. We will post an update as soon as the issue is fully resolved. 
Please note that while the situation has improved, there may still be a backlog of older events that are in the process of being resolved. We kindly ask for your patience as our team works diligently to address these remaining events. 
We apologize for any inconvenience caused and assure you that we are committed to resolving all outstanding issues.
May 24, 19:20 UTC
Investigating - As of 13:30 UTC our Engineering team is investigating an issue with intermittent Snapshot and Backup failures in our SGP1 region. Users may experience errors when performing Snapshots, but may eventually see retries succeed. 
Any Backup failures are automatically being retried within the Backup window for individual Droplets. 
We apologize for the inconvenience and will share an update once we have more information.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AMS3 Network Maintenance Phase 3]]></title>
        <id>https://status.digitalocean.com/incidents/gqtn5dtkstzg</id>
        <link href="https://status.digitalocean.com/incidents/gqtn5dtkstzg"/>
        <updated>2023-05-24T18:35:49.000Z</updated>
        <summary type="html"><![CDATA[May 24, 18:35 UTC
Completed - The scheduled maintenance has been completed.
May 24, 16:00 UTC
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
May 24, 15:05 UTC
Scheduled - Start: 2023-05-24 16:00 UTC
End:  2023-05-24 20:00 UTC

During the above window, our Networking team will be making changes to our core networking infrastructure to improve performance and scalability in the AMS3 region. This will be the final phase of the three maintenance activities performed by our team in AMS3 on consecutive days.
Expected Impact:
These upgrades are designed and tested to be seamless and we do not expect any impact to customer traffic due to this maintenance. If an unexpected issue arises, affected Droplets and Droplet-based services may experience a temporary loss of private connectivity between VPCs. We will endeavor to keep any such impact to a minimum.
If you have any questions or concerns regarding this maintenance, please reach out to us by opening up a ticket on your account via https://cloudsupport.digitalocean.com/s/createticket .]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Creates on Functions in NYC1]]></title>
        <id>https://status.digitalocean.com/incidents/6z8tp8bvmpkj</id>
        <link href="https://status.digitalocean.com/incidents/6z8tp8bvmpkj"/>
        <updated>2023-05-24T11:10:47.000Z</updated>
        <summary type="html"><![CDATA[May 24, 11:10 UTC
Resolved - Our engineering team has confirmed the full resolution of this issue. From approximately 09:05 UTC - 10:40 UTC, users were seeing errors when attempting to create new Functions, invoking or updating existing deploys. Functions should now be operating normally. If you continue to experience problems, please open a ticket with our support team. Thank you for your patience and we apologize for any inconvenience.
May 24, 10:50 UTC
Monitoring - Our Engineering team has deployed a fix to resolve an issue with Serverless Functions in the NYC1 region. All users should be able to create new Functions, invoking or updating existing deploys should be operational. We are monitoring the situation closely and will share an update once the issue is resolved completely.
May 24, 10:34 UTC
Identified - Our Engineering team has identified the cause of the issue with Serverless Functions in the NYC1 region and is actively working on a fix. During this time users may see errors when attempting to create new Functions, as well as when invoking or updating existing deploys. We will post an update as soon as additional information is available.
May 24, 10:09 UTC
Investigating - As of 09:05 UTC, our Engineering team is investigating an issue with Serverless Functions in the NYC1 region. Users may see errors when attempting to create new Functions, as well as when invoking or updating existing deploys in the NYC1 region. We apologize for the inconvenience and will share an update once we have more information.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Users reporting trouble loading profile information]]></title>
        <id>https://status.slack.com//2023-05/b98bebfae64a9007</id>
        <link href="https://status.slack.com//2023-05/b98bebfae64a9007"/>
        <updated>2023-05-24T06:34:17.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:

On May 23, 2023 from 5:30 PM PDT to around 8:15 PM PDT, some customers may have experienced blank profile pictures, display names, channel names, and emoji in Slack.


A code change inadvertently altered the firewall rules for some of our regional servers, preventing the Slack clients connected to these regions from loading profile and channel elements as expected.


As an immediate mitigation step, we stopped the code change from rolling out any further, and pushed all traffic from the affected servers to other regions. This resolved the issue for impacted customers. 


We then reverted the code change and manually restored the correct firewall rules on the affected servers. Once the correct rules were back in place, we reintroduced traffic to these regions, fully resolving the issue.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Some users unable to post reminders with custom emoji]]></title>
        <id>https://status.slack.com//2023-05/8e89e3e3b313b225</id>
        <link href="https://status.slack.com//2023-05/8e89e3e3b313b225"/>
        <updated>2023-05-23T21:07:14.000Z</updated>
        <summary type="html"><![CDATA[Issue Summary:

On May 18, 2023 from 12:50 PM PDT to May 22, 2023 07:35 AM PDT, some users found that channel reminders containing emojis couldn't be sent. 


We determined that a recent change in code added a property that was invalid in the reminder creation schema, which caused reminders to be rejected upon sending.


Once we reverted the change, the issue was resolved for affected users.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AMS3 Network Maintenance 2023-05-23 16:00 UTC Phase 2]]></title>
        <id>https://status.digitalocean.com/incidents/xhrg6p90g0yv</id>
        <link href="https://status.digitalocean.com/incidents/xhrg6p90g0yv"/>
        <updated>2023-05-23T19:11:07.000Z</updated>
        <summary type="html"><![CDATA[May 23, 19:11 UTC
Completed - The scheduled maintenance has been completed.
May 23, 16:00 UTC
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
May 23, 15:20 UTC
Scheduled - Start: 2023-05-23 16:00 UTC
End: 2023-05-23 20:00 UTC

During the above window, our Networking team will be making changes to our core networking infrastructure to improve performance and scalability in the AMS3 region. This will be the second of three maintenance activities performed by our team in AMS3 on consecutive days.
Expected Impact:
These upgrades are designed and tested to be seamless and we do not expect any impact to customer traffic due to this maintenance. If an unexpected issue arises, affected Droplets and Droplet-based services may experience a temporary loss of private connectivity between VPCs. We will endeavor to keep any such impact to a minimum.
If you have any questions or concerns regarding this maintenance, please reach out to us by opening up a ticket on your account via https://cloudsupport.digitalocean.com/s/createticket .]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Some users from Indonesia are having trouble connecting to Slack]]></title>
        <id>https://status.slack.com//2023-05/df664b4db7d12627</id>
        <link href="https://status.slack.com//2023-05/df664b4db7d12627"/>
        <updated>2023-05-23T06:16:18.000Z</updated>
        <summary type="html"><![CDATA[On May 23, 2023 from around 7:00 PM to 10:37 PM PDT, some users located in Indonesia may have experienced connectivity issues with Slack. 


We investigated, and determined that a local Internet service provider (ISP) is not resolving Slack domains as expected. 


If you're having trouble connecting to Slack, please reach out to your ISP for assistance.


Note: This post has been edited to accurately reflect the duration of this issue.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AMS3 Network Maintenance 2023-05-22 16:00 UTC Phase 1]]></title>
        <id>https://status.digitalocean.com/incidents/6gkqfc6j4jq5</id>
        <link href="https://status.digitalocean.com/incidents/6gkqfc6j4jq5"/>
        <updated>2023-05-22T19:30:09.000Z</updated>
        <summary type="html"><![CDATA[May 22, 19:30 UTC
Completed - The scheduled maintenance has been completed.
May 22, 16:00 UTC
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
May 22, 15:20 UTC
Scheduled - Start: 2023-05-22 16:00 UTC
End: 2023-05-22 20:00 UTC
During the above window, our Networking team will be making changes to our core networking infrastructure to improve performance and scalability in the AMS3 region. This maintenance will occur in three parts on consecutive days, and we will send other maintenance notices for the second and third phases. 
Expected Impact:
These upgrades are designed and tested to be seamless and we do not expect any impact to customer traffic due to this maintenance. If an unexpected issue arises, affected Droplets and Droplet-based services may experience a temporary loss of private connectivity between VPCs. We will endeavor to keep any such impact to a minimum.
If you have any questions or concerns regarding this maintenance, please reach out to us by opening up a ticket on your account via https://cloudsupport.digitalocean.com/s/createticket .]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Missing Cleaning Fee in Reservations]]></title>
        <id>https://airbnbapi.statuspage.io/incidents/y9spcdfq87h1</id>
        <link href="https://airbnbapi.statuspage.io/incidents/y9spcdfq87h1"/>
        <updated>2023-05-22T16:24:50.000Z</updated>
        <summary type="html"><![CDATA[May 22, 09:24 PDT
Resolved - We have identified and fixed an issue related to missing PASS_THROUGH_CLEANING_FEE standard fee that occurred between 07:41 AM PDT May 17th until 10:17 AM PDT May 23rd 2023. 
The issue caused standard fee PASS_THROUGH_CLEANING_FEE to be cleared and as a result some reservations might be missing the cleaning fee. 
Please reapply the Standard Fees by making PUT pricing_settings requests with the desired fees.
This should re-populate the listings' Standard Fees array as intended, namely the PASS_THROUGH_CLEANING_FEE.
If you have any further queries related to this incident, please submit a ticket via the Partner Support Portal and our team will get back to you as soon as possible.
Apologies for the inconvenience caused and thank you for your understanding.]]></summary>
        <author>
            <name>Airbnb API Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scheduled maintenance]]></title>
        <id>https://status.make.com/incidents/drg7g8lyvk6c</id>
        <link href="https://status.make.com/incidents/drg7g8lyvk6c"/>
        <updated>2023-05-22T08:00:25.000Z</updated>
        <summary type="html"><![CDATA[May 22, 10:00 CEST
Completed - The scheduled maintenance has been completed.
May 22, 09:00 CEST
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
May 18, 13:23 CEST
Scheduled - We would like to inform you about a scheduled maintenance window that will be taking place on 22nd May between 09:00 CEST - 10:00 CEST.
During this maintenance period, there will be a short interruption resulting in the unavailability of the login page and organizations page. 
However, we assure you that there will be no data loss and all scenarios will continue running properly.
We apologize for any inconvenience caused and appreciate your understanding.]]></summary>
        <author>
            <name>Make Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DNS Services and App Platform Deployments]]></title>
        <id>https://status.digitalocean.com/incidents/m32tbckd7mgh</id>
        <link href="https://status.digitalocean.com/incidents/m32tbckd7mgh"/>
        <updated>2023-05-20T14:55:05.000Z</updated>
        <summary type="html"><![CDATA[May 20, 14:55 UTC
Resolved - Our Engineering team has confirmed full resolution of this incident. 
From 12:24 - 13:26 UTC, we experienced an issue that impacted our DNS API services. During this time, customer deployments to App Platform will have failed to process, and managing domains and DNS records through both the Cloud Control Panel and API would have been unavailable. 
If you continue to experience problems with either of these services please open a ticket with our support team from within your Cloud Control Panel. Thank you for your patience.
May 20, 13:57 UTC
Monitoring - Our Engineering team identified that the root cause of the issues impacting App Platform deployments was a wider issue involving our DNS API. Along with the App Platform deployment errors, customers would have experienced trouble viewing and editing domains and their DNS records through both the Cloud Control Panel and the API. 
A fix has been rolled out and as of 13:26 UTC customers should no longer be experiencing any issues involving the services listed above. Our team will continue to monitor the situation to ensure stability and provide a final update as soon as we confirm the issue has been fully resolved. 
Thank you for your patience.
May 20, 12:46 UTC
Investigating - As of 12:24 UTC, Our Engineering team is investigating a global issue with our App Platform service. During this time, users may experience issues while performing any operations for new, updated and deleting deployments. 
At this time, previously deployed running Apps are not impacted. We will provide an update as soon as possible.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Event processing in FRA1 region]]></title>
        <id>https://status.digitalocean.com/incidents/tsb7y4bqyg1d</id>
        <link href="https://status.digitalocean.com/incidents/tsb7y4bqyg1d"/>
        <updated>2023-05-20T11:19:41.000Z</updated>
        <summary type="html"><![CDATA[May 20, 11:19 UTC
Resolved - Our Engineering team has confirmed full resolution of this incident. From 07:01 UTC - 11:00 UTC, we have verified that there is no further risk to event processing in the FRA1 region, and we will now mark this issue as Resolved. Thank you for your patience and understanding throughout this process. If you should encounter any further issues at all, then please open a ticket with our Support team.
May 20, 08:43 UTC
Monitoring - Our Engineering team was able to take action to mitigate the impact of this incident and allow events to process normally. We will post an update as soon as the issue is fully resolved. Please note that while the situation has improved, there may still be a backlog of older events that are in the process of being resolved. We kindly ask for your patience as our team works diligently to address these remaining events. We apologize for any inconvenience caused and assure you that we are committed to resolving all outstanding issues.
May 20, 08:20 UTC
Identified - Our Engineering team has identified the cause of the issue with event processing in the FRA1 region and is actively working on a fix. During this time, only a subset of users may experience delays during creates, destroys, and power events in the cloud panel. We will post an update as soon as additional information is available.
May 20, 07:59 UTC
Investigating - Our Engineering team is investigating an issue with event processing in the FRA1 region. Beginning 07:01 UTC, users may experience delays during creates, destroys, and power events. We apologize for the inconvenience and will share an update once we have more information.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[v2021.12.31 Migration Enforcement - Phase 5]]></title>
        <id>https://airbnbapi.statuspage.io/incidents/jfj0pfxnz17q</id>
        <link href="https://airbnbapi.statuspage.io/incidents/jfj0pfxnz17q"/>
        <updated>2023-05-20T07:00:08.000Z</updated>
        <summary type="html"><![CDATA[May 20, 00:00 PDT
Completed - The scheduled maintenance has been completed.
May 15, 00:00 PDT
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
May 10, 09:58 PDT
Scheduled - The deprecation date for API Version 2021.12.31 was March 31, 2023. Any applications that have not fully migrated will be automatically migrated to a newer version, which can result in application breakage.
Automatic migration will occur in phases as detailed in https://developer.airbnb.com/docs/versioning-enforcement
Phase 5 is the last phase and begins on May 15, 2023 for the following endpoints: Listings, Listing Permits, Async Calendars]]></summary>
        <author>
            <name>Airbnb API Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Volumes Availability and Downstream Services in FRA1]]></title>
        <id>https://status.digitalocean.com/incidents/q8m2ql93bwtj</id>
        <link href="https://status.digitalocean.com/incidents/q8m2ql93bwtj"/>
        <updated>2023-05-18T18:48:03.000Z</updated>
        <summary type="html"><![CDATA[May 18, 18:48 UTC
Resolved - Our Engineering team has confirmed full resolution of this incident. 
From 17:06 - 17:39 UTC, we experienced an availability outage on an internal storage cluster, due to an issue with a networking component. Users may have seen degraded performance with Volumes, issues connecting to Managed Kubernetes clusters, issues creating/deleting Mongo clusters, and delayed deploys/updates to existing Apps in our FRA1 region. 
If you continue to experience problems, please open a ticket with our support team from within your Cloud Control Panel. Thank you for your patience throughout this incident.
May 18, 17:59 UTC
Monitoring - Our Engineering team has confirmed the issue with the networking component of the internal storage cluster was the root cause and the remediatio…]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Slack is not loading properly for some users]]></title>
        <id>https://status.slack.com//2023-05/72e5e8644f160e6a</id>
        <link href="https://status.slack.com//2023-05/72e5e8644f160e6a"/>
        <updated>2023-05-17T22:40:00.000Z</updated>
        <summary type="html"><![CDATA[Issue Summary:


On May 17, 2023 from 11:28 AM to 11:55 AM PDT some users encountered error messages while connecting to Slack.


This issue was a result of an operational change made in error, which caused our databases to become inaccessible. We rolled back this change, fixing the problem for all impacted users.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Outage: Users having issues loading Slack]]></title>
        <id>https://status.slack.com//2023-05/f2b711ba48d8803a</id>
        <link href="https://status.slack.com//2023-05/f2b711ba48d8803a"/>
        <updated>2023-05-17T14:58:25.000Z</updated>
        <summary type="html"><![CDATA[Our engineering team deployed a minor technical change to the handling of cryptographic operations, such as API token validation.

During this redirection we saw a higher than anticipated volume of failed API requests which resulted in an impact to the Slack service. As a result, Slack was down between 1:56 PM PDT - 2:03 PM PDT.

This was resolved when these changes were rolled back by infrastructure teams.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
</feed>