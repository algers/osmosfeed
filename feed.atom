<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>urn:2024-03-21T00:21:59.825Z</id>
    <title>osmos::feed</title>
    <updated>2024-03-21T00:21:59.825Z</updated>
    <generator>osmosfeed 1.15.1</generator>
    <link rel="alternate" href="index.html"/>
    <entry>
        <title type="html"><![CDATA[Russia SMS Carrier Maintenance - MTS]]></title>
        <id>https://status.twilio.com/incidents/ln6vbw9d3clj</id>
        <link href="https://status.twilio.com/incidents/ln6vbw9d3clj"/>
        <updated>2024-03-21T04:30:00.000Z</updated>
        <summary type="html"><![CDATA[THIS IS A SCHEDULED EVENT Mar 20, 21:30 - 23:00 PDT
Mar 19, 16:36 PDT
Scheduled - The MTS network in Russia is conducting an emergency maintenance from 20 March 2024 at 21:30 PDT until 20 March 2024 at 23:00 PDT. During the maintenance window, there could be intermittent delays delivering SMS to MTS Russia handsets.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[US SMS Carrier Maintenance - Small US Carriers]]></title>
        <id>https://status.twilio.com/incidents/99j83grzmcgr</id>
        <link href="https://status.twilio.com/incidents/99j83grzmcgr"/>
        <updated>2024-03-21T04:00:00.000Z</updated>
        <summary type="html"><![CDATA[THIS IS A SCHEDULED EVENT Mar 20, 21:00 PDT  -  Mar 21, 01:00 PDT
Mar 16, 13:02 PDT
Scheduled - A subset of small US networks in the US are conducting a planned maintenance from 20 March 2024 at 21:00 PDT until 21 March 2024 at 01:00 PDT. During the maintenance window, there could be intermittent delays delivering SMS to small US carriers handsets.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[US and Canada SMS and MMS Carrier partner Maintenance]]></title>
        <id>https://status.twilio.com/incidents/gjvnq8st93fb</id>
        <link href="https://status.twilio.com/incidents/gjvnq8st93fb"/>
        <updated>2024-03-21T03:00:00.000Z</updated>
        <summary type="html"><![CDATA[THIS IS A SCHEDULED EVENT Mar 20, 20:00 PDT  -  Mar 21, 00:00 PDT
Mar  1, 23:33 PST
Scheduled - Our SMS and MMS carrier partner in the US and Canada is conducting a planned maintenance from 20 March 2024 at 20:00 PDT until 21 March 2024 at 00:00 PDT. During the maintenance window, there could be intermittent delays delivering SMS and MMS to and from US and Canada handsets via Toll-free numbers.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Trouble loading channels, viewing channel membership, and clearing user status]]></title>
        <id>https://slack-status.com/2024-03/1d7a64340d07f102</id>
        <link href="https://slack-status.com/2024-03/1d7a64340d07f102"/>
        <updated>2024-03-20T20:54:57.000Z</updated>
        <summary type="html"><![CDATA[We’ve determined that this issue may also be preventing some users from viewing profile photos and message activity. Fortunately we’re beginning to see signs of improvement, but are still working towards a full resolution. We’re keeping a close eye and will continue to provide updates as they become available.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Issues with file previews]]></title>
        <id>https://slack-status.com/2024-03/f050004edd32fdb2</id>
        <link href="https://slack-status.com/2024-03/f050004edd32fdb2"/>
        <updated>2024-03-20T17:46:17.000Z</updated>
        <summary type="html"><![CDATA[We’re still actively investigating this issue, but we don’t have any new information to share at this time. 

Thanks for sticking with us as we continue to work towards a fix.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[500 Errors Across Multiple APIs]]></title>
        <id>https://airbnbapi.statuspage.io/incidents/zgxmpgh6k7s2</id>
        <link href="https://airbnbapi.statuspage.io/incidents/zgxmpgh6k7s2"/>
        <updated>2024-03-20T04:11:05.000Z</updated>
        <summary type="html"><![CDATA[Mar 19, 21:11 PDT
Resolved - This incident has been resolved. The effects began around 1:30 PM PST, and were mostly resolved by 2:15 PM PST. There may have been some lingering affects until around 6 PM PST, but at this point we do not expect any further issues.
Mar 19, 14:18 PDT
Investigating - We are currently investigating an issue that's causing sporadic errors on a variety of different APIs. The Booking Settings API appears to be primarily impacted, but other endpoints are sporadically affected as well.]]></summary>
        <author>
            <name>Airbnb API Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Issues loading Slack for less than 1% of customers]]></title>
        <id>https://slack-status.com/2024-03/35ce2793cef7d175</id>
        <link href="https://slack-status.com/2024-03/35ce2793cef7d175"/>
        <updated>2024-03-20T03:40:21.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:
On March 19, 2024 from 2:50 PM PDT to 8:16 PM PDT, less than 1% of users were unable to load Slack. 

A corrupted table in our database infrastructure prevented one of our databases from responding to requests, causing connection issues for customers whose workspaces were hosted on that database. We manually triggered a backup of the affected database. While we always have backups in place, we were concerned that the existing replicas would be affected by the same bug. We used this manual backup to provision new databases, spinning up several fresh replicas. 

Once the replicas were up and running, we directed traffic from the impacted workspaces to these new databases. This restored access for affected customers. We continued working to address the bug that caused the original issue to prevent this from occurring to any other database.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Device management functionality is degraded]]></title>
        <id>https://status.rippling.com/incidents/sqd2d2w23lsw</id>
        <link href="https://status.rippling.com/incidents/sqd2d2w23lsw"/>
        <updated>2024-03-19T20:30:21.000Z</updated>
        <summary type="html"><![CDATA[Mar 19, 20:30 UTC
Resolved - This incident has been resolved.
Mar 19, 20:29 UTC
Update - We are continuing to monitor for any further issues.
Mar 19, 20:29 UTC
Monitoring - A fix has been implemented and we are monitoring the results.
Mar 19, 18:57 UTC
Identified - The issue has been identified and a fix is being implemented.
Mar 19, 17:32 UTC
Investigating - Page loads are slow and occasionally failing]]></summary>
        <author>
            <name>Rippling Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Issues with accessing External Connections]]></title>
        <id>https://slack-status.com/2024-03/d38973d5b190a450</id>
        <link href="https://slack-status.com/2024-03/d38973d5b190a450"/>
        <updated>2024-03-18T23:29:50.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:
From 1:00 PM PDT on March 16, 2024 to 2:57 PM PDT on March 18, 2024, some users encountered a REB434A8313F error message when attempting to access the External Connections tab in Slack. On March 16th, a small number of users reported impact, however, it was later determined that more users were affected. 

We determined that a recent backend change to the navigation bar badging rules was preventing this view from loading properly. We reverted this change, which resolved the issue for all affected users.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DigitalOcean Support Portal Maintenance]]></title>
        <id>https://status.digitalocean.com/incidents/6w4ffgm83798</id>
        <link href="https://status.digitalocean.com/incidents/6w4ffgm83798"/>
        <updated>2024-03-17T05:00:56.000Z</updated>
        <summary type="html"><![CDATA[Mar 17, 05:00 UTC
Completed - The scheduled maintenance has been completed.
Mar 17, 02:00 UTC
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
Mar 12, 16:11 UTC
Scheduled - Start: 2024-03-17 02:00 UTC
End: 2024-03-17 05:00 UTC
During the above maintenance window, there will be maintenance performed on our ticketing system.
Expected Impact:
During the course of the maintenance, users will be unable to submit support tickets, update existing tickets, or receive replies to existing tickets. Users will also be unable to log into https://cloudsupport.digitalocean.com/s/ or open the Support Portal from within the Cloud Control Panel.
Any tickets submitted during the maintenance via alternate methods (such as replying to an email chain or via our webform) will be saved and entered into our ticketing system at the completion of the maintenance.
Our Support Team will also be impacted by this maintenance and will be unable to enter the ticketing system to receive any tickets or reply to existing tickets. As soon as the vendor maintenance has completed, our team will address all support queries as quickly as possible.
We appreciate your patience throughout this process.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Droplet Creation in BLR1]]></title>
        <id>https://status.digitalocean.com/incidents/2nng21f5nvfn</id>
        <link href="https://status.digitalocean.com/incidents/2nng21f5nvfn"/>
        <updated>2024-03-15T23:54:14.000Z</updated>
        <summary type="html"><![CDATA[Mar 15, 23:54 UTC
Resolved - Our Engineering team has confirmed full resolution of DNS resolution issue in the BLR1 region. 
We appreciate your patience throughout this process and if you continue to experience problems, please open a ticket with our support team for further review.
Mar 15, 23:27 UTC
Monitoring - Our Engineering team has rolled out a fix for the DNS resolution issue in the BLR1 region. Users should now be able to create Droplets with firewall rules.
We'll post an update once the incident is fully resolved.
Mar 15, 23:09 UTC
Investigating - Our Engineering team is currently investigating issues with DNS resolution in BLR1 region. During this time, customers may experience issues while creating new Droplets with firewall rules in the BLR1 region.
We apologize for the inconvenience and will share an update once we have more information.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Actions and Pages]]></title>
        <id>https://www.githubstatus.com/incidents/m07hfg0gly20</id>
        <link href="https://www.githubstatus.com/incidents/m07hfg0gly20"/>
        <updated>2024-03-15T20:28:06.000Z</updated>
        <summary type="html"><![CDATA[Mar 15, 20:28 UTC
Resolved - This incident has been resolved.
Mar 15, 20:27 UTC
Update - Actions is operating normally.
Mar 15, 20:09 UTC
Update - Pages is experiencing degraded performance. We are continuing to investigate.
Mar 15, 20:07 UTC
Investigating - We are investigating reports of degraded performance for Actions]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Codespaces and API Requests]]></title>
        <id>https://www.githubstatus.com/incidents/9ym5p2sg6w5v</id>
        <link href="https://www.githubstatus.com/incidents/9ym5p2sg6w5v"/>
        <updated>2024-03-15T20:24:44.000Z</updated>
        <summary type="html"><![CDATA[Mar 15, 20:24 UTC
Resolved - This incident has been resolved.
Mar 15, 20:21 UTC
Update - Codespaces is operating normally.
Mar 15, 20:20 UTC
Update - API Requests is operating normally.
Mar 15, 20:17 UTC
Update - We rolled back the most recent deployment and are seeing improvements across all services, and will continue to monitor for additional impact.
Mar 15, 20:11 UTC
Update - API Requests is experiencing degraded performance. We are continuing to investigate.
Mar 15, 20:03 UTC
Update - Codespaces is experiencing degraded availability. We are continuing to investigate.
Mar 15, 20:03 UTC
Update - API Requests is experiencing degraded availability. We are continuing to investigate.
Mar 15, 20:00 UTC
Update - API Requests is experiencing degraded performance. We are continuing to investigate.
Mar 15, 19:55 UTC
Investigating - We are investigating reports of degraded performance for Codespaces]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Device management functionality is degraded]]></title>
        <id>https://status.rippling.com/incidents/b20xb0qlwd48</id>
        <link href="https://status.rippling.com/incidents/b20xb0qlwd48"/>
        <updated>2024-03-15T20:18:17.000Z</updated>
        <summary type="html"><![CDATA[Mar 15, 20:18 UTC
Resolved - This incident has been resolved.
Mar 15, 19:51 UTC
Monitoring - A fix has been implemented and we are monitoring the results.
Mar 15, 18:55 UTC
Investigating - We are currently investigating this issue.]]></summary>
        <author>
            <name>Rippling Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Reports of slowness and connectivity issues in Slack]]></title>
        <id>https://slack-status.com/2024-03/070ad43095b540ab</id>
        <link href="https://slack-status.com/2024-03/070ad43095b540ab"/>
        <updated>2024-03-15T01:35:34.000Z</updated>
        <summary type="html"><![CDATA[Issue summary: 
From 12:40 PM to 4:55 PM PDT on March 13, 2024, users from one Enterprise Grid organization may have experienced slowness or connectivity issues when using Slack.

A routine infrastructure process inadvertently caused an increase in requests to the database hosting the affected Enterprise Grid organization. This resulted in slower than usual response times for user actions in Slack, and some connectivity failures. 

We identified the cause of the problem and manually increased the database capacity, restoring normal functionality for impacted users. 

Thank you for bearing with us while we resolved this issue.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: User are receiving errors when attempting to access certain app configuration pages.]]></title>
        <id>https://slack-status.com/2024-03/e954ecf8fbab9711</id>
        <link href="https://slack-status.com/2024-03/e954ecf8fbab9711"/>
        <updated>2024-03-14T11:01:37.000Z</updated>
        <summary type="html"><![CDATA[Issue summary: 
On March 13, 2024 from 5:02 PM PDT until 9:48 PM PDT some users may have encountered "Something's gone awry" or "Slack isn't loading" errors when attempting to access their certain app configuration pages. 

We determined that a recent code change caused this issue. We reverted the code change and the issue was resolved.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[RESOLVED: **Summary:**
Admin Console is experiencing elevated errors with the Chrome setting pages.
**Description:**
Mitigation work is currently underway by our engineering team.
The mitigation is expected to complete by Wednesday, 2024-03-06 16:15 US/Pacific.
We will provide more information by Wednesday, 2024-03-06 16:45 US/Pacific.
**Customer Symptoms:**
The impacted customers would encounter a HTTP 500 error while accessing user or device setting pages within Chrome Admin Console. Additionally, customers would not be able to view or change any policies.
**Workaround:**
None at this time.]]></title>
        <id>https://www.google.com/appsstatus/dashboard/incidents/Nr8avWyykjurdUqXYSDW</id>
        <link href="https://www.google.com/appsstatus/dashboard/incidents/Nr8avWyykjurdUqXYSDW"/>
        <updated>2024-03-13T21:26:43.000Z</updated>
        <summary type="html"><![CDATA[<p> Incident began at <strong>2024-03-06 22:32</strong> and ended at <strong>2024-03-06 23:29</strong> <span>(times are in <strong>Coordinated Universal Time (UTC)</strong>).</span></p><div class="cBIRi14aVDP__status-update-text"><h1>Incident Report</h1>
<h2>Summary</h2>
<p>On Wednesday, 06 March 2024, Google Workspace users experienced elevated errors while accessing user or device setting pages within the Chrome Admin Console for a duration of 1 hour, 27 minutes.</p>
<p>To our Google Workspace customers who were impacted during this disruption, we sincerely apologize. This is not the level of quality and reliability we strive to offer you, and we are taking immediate steps to improve the platform’s performance and availability.</p>
<h2>Root Cause</h2>
<p>Google Workspace Admin Console uses a backend authentication service to grant privileged access to internal accounts. As part of ongoing efforts to migrate the account authorization workflow to a new backend authentication service, Google engineers identified and cleaned up invalid account role assignments in the configuration.</p>
<p>During this clean up effort, engineers identified a privilege which was undefined in the application manifest and removed it from the configuration. Upon further investigation, engineering confirmed the privilege was mapped to an access control setting used by the Admin Console for Chrome. This change resulted in users being unable to access Chrome user and device settings page.</p>
<h2>Remediation and Prevention</h2>
<p>Google engineers were alerted to the outage via an internal monitoring alert on Wednesday, 06 March 2024 at 15:04 US/Pacific and immediately started an investigation. Once the nature and scope of the issue became clear, Google engineers initiated a rollback of the configuration change at 15:36 and the incident was fully resolved at 15:59 once the rollback completed.</p>
<p>Google is committed to preventing a repeat of this issue in the future and is completing the following actions:</p>
<ul>
<li>Improve procedural documentation on how to safely cleanup access control settings from authorization configuration.</li>
<li>Complete thorough investigation of privilege usage for the Admin Console to prevent further issues of this type.</li>
<li>Identify and register a new owner for this privilege in the application manifest and create permission mapping for faster verification in the future.</li>
</ul>
<p>Google is committed to quickly and continually improving our technology and operations to prevent service disruptions. We appreciate your patience and apologize again for the impact to your organization. We thank you for your business.</p>
<h2>Detailed Description of Impact</h2>
<p>On Wednesday, 06 March 2024 from 14:32 to 15:59 US/Pacific, Google Workspace users attempting to work within the Admin Console encountered an HTTP 500 error when accessing user or device setting pages within the console.</p>
<hr>
</div><hr><p>Affected products: Admin Console</p>]]></summary>
        <author>
            <name>Google Workspace Status Dashboard Updates</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Pull Requests]]></title>
        <id>https://www.githubstatus.com/incidents/q3gl44chgxwv</id>
        <link href="https://www.githubstatus.com/incidents/q3gl44chgxwv"/>
        <updated>2024-03-13T01:58:49.000Z</updated>
        <summary type="html"><![CDATA[Mar 13, 01:58 UTC
Resolved - From March 12, 2024 23:39 UTC to March 13, 2024 1:58 UTC, some Pull Requests updates were delayed and did not reflect the latest code that had been pushed. On average, 20% of Pull Requests page loads were out of sync and up to 30% of Pull Requests were impacted at peak. An internal component of our job queueing system was incorrectly handling invalid messages, resulting in stalled processing.
We mitigated the incident by shipping a fix to handle the edge case gracefully and allow processing to continue.
Once the fix was deployed at 1:47 UTC, our systems fully caught up with pending background jobs at 1:58 UTC.
We’re working to improve resiliency to invalid messages in our system to prevent future delays for these pull request updates. We are also reviewing our monitoring and observability to identify and remediate these types of failure cases faster.

Mar 13, 01:58 UTC
Update - Pull Requests is operating normally.
Mar 13, 01:53 UTC
Update - We believe we've found a mitigation and are currently monitoring systems for recovery.
Mar 13, 01:18 UTC
Update - We're continuing to investigate delays in PR updates. Next update in 30 minutes.
Mar 13, 00:47 UTC
Update - We're continuing to investigate an elevated number of pull requests that are out of sync on page load.
Mar 13, 00:12 UTC
Update - We're continuing to investigate an elevated number of pull requests that are out of sync on page load.
Mar 12, 23:39 UTC
Update - We're seeing an elevated number of pull requests that are out of sync on page load.
Mar 12, 23:39 UTC
Investigating - We are investigating reports of degraded performance for Pull Requests]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Outage: Trouble loading multiple features in Slack]]></title>
        <id>https://slack-status.com/2024-03/811378903bd22810</id>
        <link href="https://slack-status.com/2024-03/811378903bd22810"/>
        <updated>2024-03-12T20:18:00.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:
On March 11, 2024 from 2:43 PM PDT until 3:43 PM PDT some users in workspaces using International Data Residency (IDR) experienced issues with several Slack features, including messages loading or sending, channels appearing blank, canvases loading, huddles connecting, and trouble with some workflows were also noted.

We identified a spike in error rates that was tied to a recent change to a backend service configuration logic. This change resulted in a cache discrepancy between services causing the errors. We rolled back the recent changes which immediately reduced error rates, resolving the issue for affected users. We are working on modifying the service handler in an effort to reduce the likelihood of this occurring in the future.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Issue with focus in workflows]]></title>
        <id>https://slack-status.com/2024-03/c60bb5e0edd2cd89</id>
        <link href="https://slack-status.com/2024-03/c60bb5e0edd2cd89"/>
        <updated>2024-03-12T19:21:05.000Z</updated>
        <summary type="html"><![CDATA[Issue Summary:
On March 11, 2024 at 3:00 PDT to March 12, 2024 at 12:00 AM PDT, some users had trouble completing workflows that contained either text or drop-down fields due to a bug that caused the cursor to revert to the previous field in the workflow.

Upon investigation, we discovered a recent code change that introduced this bug. We rolled back the change and pushed a fix to all users resolving the issue.

Thank you again for bearing with us in the meantime.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Droplet connectivity and Event processing in multiple regions.]]></title>
        <id>https://status.digitalocean.com/incidents/65lj1w0mxvmb</id>
        <link href="https://status.digitalocean.com/incidents/65lj1w0mxvmb"/>
        <updated>2024-03-12T11:43:59.000Z</updated>
        <summary type="html"><![CDATA[Mar 12, 11:43 UTC
Resolved - As of 10:09 UTC, our Engineering team has confirmed the full resolution of the issue impacting Droplet connectivity and Event processing in multiple regions.
Users should no longer see issues with their Droplets and Droplet-related services.
If you continue to experience problems, please open a ticket with our support team. Thank you for your patience throughout this incident.
Mar 12, 10:07 UTC
Monitoring - Our Engineering team has confirmed that the issue impacting Droplet connectivity in multiple regions has been mitigated.
At this time, users should no longer see issues when connecting to their Droplet and Droplet-related services.
We will further monitor this incident and will post an update as soon as the issue is fully resolved.
Mar 12, 09:29 UTC
Identifi…]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with API Requests, Git Operations, Webhooks and Copilot]]></title>
        <id>https://www.githubstatus.com/incidents/fr6fgvdn41sw</id>
        <link href="https://www.githubstatus.com/incidents/fr6fgvdn41sw"/>
        <updated>2024-03-12T01:00:51.000Z</updated>
        <summary type="html"><![CDATA[Mar 12, 01:00 UTC
Resolved - On March 11, 2024 starting at 22:45 UTC and ending on March 12, 2024 00:48 UTC various GitHub services were degraded and returned intermittent errors for users. During this incident, the following customer impacts occurred: API error rates as high as 1%, Copilot error rates as high as 17%, and Secret Scanning and 2FA using GitHub Mobile error rates as high as 100% followed by a drop in error rates to 30% starting at 22:55 UTC. This elevated error rate was due to a degradation of our centralized authentication service upon which many other services depend.
The issue was caused by a deployment of network related configuration that was inadvertently applied to the incorrect environment. This error was detected within 4 minutes and a rollback was initiated. While e…]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Actions]]></title>
        <id>https://www.githubstatus.com/incidents/bgnqgwyj76l4</id>
        <link href="https://www.githubstatus.com/incidents/bgnqgwyj76l4"/>
        <updated>2024-03-11T19:22:16.000Z</updated>
        <summary type="html"><![CDATA[Mar 11, 19:22 UTC
Resolved - On March 11, 2024 between at 18:44 UTC and 19:10 UTC, GitHub Actions performance was degraded and some users experienced errors when trying to queue workflows. Approximately 3.7% of runs queued during this time were unable to start.
The issue was partially caused by a deployment of an internal system Actions relies on to process workflow run events. The pausing of the queue processing during this deployment for about 3 minutes caused a spike in queued workflow runs. When this queue began to be processed, the high number of queued workflows overwhelmed a secret-initialization component of the workflow invocation system. The errors generated by this overwhelmed system ultimately delayed workflow invocation. Through our alerting system, we received initial indications of an issue at approximately 18:44 UTC. However, we did not initially see impact on our run start delays and run queuing availability metrics until approximately 18:52 UTC. As the large queue of workflow run events burned down, we saw recovery in our key customer impact measures by 19:11 UTC, but waited to declare the incident resolved at 19:22 UTC while verifying there was no further customer impact.
We are working on various measures to reduce spikes in queue build up during deployments of our queueing system, and have scaled up the workers which handle secret generation and storage during the workflow invocation process.

Mar 11, 19:21 UTC
Update - Actions experienced a period of decreased workflow run throughput, and we are seeing recovery now.  We are in the process of investigating the cause.
Mar 11, 19:02 UTC
Investigating - We are investigating reports of degraded performance for Actions]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Copilot]]></title>
        <id>https://www.githubstatus.com/incidents/7f4bllnv3h1n</id>
        <link href="https://www.githubstatus.com/incidents/7f4bllnv3h1n"/>
        <updated>2024-03-11T10:20:15.000Z</updated>
        <summary type="html"><![CDATA[Mar 11, 10:20 UTC
Resolved - On March 11, 2024, between 06:30 UTC and 11:45 UTC the Copilot Chat service was degraded and customers may have encountered errors or timed out requests for chat interactions. On average, the error rate was 10% and peaked at 45% of requests to the service for short periods of time.
This was due to a gap in handling an edge case for messages returned from the underlying language models. We mitigated the incident by applying a fix to the handling of the streaming response.
We are working to update monitoring to reduce time to detection and increase resiliency to message format changes.
Mar 11, 10:02 UTC
Update - We are deploying mitigations for the failures we have been observing in some chat requests for Copilot. We will continue to monitor and update.
Mar 11, 09:03 UTC
Update - We are seeing an elevated failure rate for chat requests for Copilot. We are investigating and will continue to keep users updated on progress towards mitigation.
Mar 11, 08:14 UTC
Investigating - We are investigating reports of degraded performance for Copilot]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Issues with legacy custom integration configuration pages]]></title>
        <id>https://slack-status.com/2024-03/1f506e0a906e75bb</id>
        <link href="https://slack-status.com/2024-03/1f506e0a906e75bb"/>
        <updated>2024-03-08T14:35:09.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:

On March 6, 2024 from 7:45 PM PST to around 9:33 PM PST customers reported that they were receiving a 500 error when viewing the legacy Incoming Webhook custom integration page.

We identified a backend code change that inadvertently changed data that the Incoming Webhook page needed to load which consequently caused the page to respond with an HTTP 500 error.

We rolled back the change, correcting the issue and all customers should now be able to access the Incoming Webhook page as expected.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Huddles not working for some Windows users]]></title>
        <id>https://slack-status.com/2024-03/b9c8573e14eec256</id>
        <link href="https://slack-status.com/2024-03/b9c8573e14eec256"/>
        <updated>2024-03-08T10:54:49.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:
On March 5, 2024 from 6:05 PM PST to March 6, 2024 8:17 AM PST customers on the Windows operating systems reported that Huddles were freezing when screen sharing.
We determined that a recent change that was made to the video codec of Huddles, which may have been moving more of the video encoding to the computer's Graphic Processing Unit. This would cause performance problems & freezing during a screen share.
After narrowing down the exact cause we rolled back the change which restored full functionality to Huddles screen sharing.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[500 Errors Across Multiple Endpoints]]></title>
        <id>https://airbnbapi.statuspage.io/incidents/hjdlmbqk7krr</id>
        <link href="https://airbnbapi.statuspage.io/incidents/hjdlmbqk7krr"/>
        <updated>2024-03-07T22:40:08.000Z</updated>
        <summary type="html"><![CDATA[Mar  7, 14:40 PST
Resolved - This incident has been resolved as of March 6th, 2024, 12:08 AM PST. Error rates have returned to normal levels. Please retry any failed requests.
We apologize for the inconvenience caused and thank you for your patience and understanding.
Mar  6, 12:38 PST
Monitoring - We've identified an increased number of 500 errors across multiple endpoints starting today 11:52 AM PST.This issue has been mitigated at 12:08 AM PST. 
Please apply any failed requests during the incident.]]></summary>
        <author>
            <name>Airbnb API Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Delays creating accounts in third-party apps]]></title>
        <id>https://status.rippling.com/incidents/j0y55xs3d05q</id>
        <link href="https://status.rippling.com/incidents/j0y55xs3d05q"/>
        <updated>2024-03-07T18:09:18.000Z</updated>
        <summary type="html"><![CDATA[Mar  7, 18:09 UTC
Resolved - This incident has been resolved.
Mar  6, 22:57 UTC
Monitoring - A fix has been implemented and we are monitoring the results.
Mar  6, 16:58 UTC
Update - We are continuing to work on a fix for this issue. This affects users who have their accounts created prior to their start date.
Mar  6, 16:51 UTC
Identified - The issue has been identified and a fix is being implemented.]]></summary>
        <author>
            <name>Rippling Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spaces Availability in SFO2]]></title>
        <id>https://status.digitalocean.com/incidents/1755wn45yqyw</id>
        <link href="https://status.digitalocean.com/incidents/1755wn45yqyw"/>
        <updated>2024-03-07T12:21:18.000Z</updated>
        <summary type="html"><![CDATA[Mar  7, 12:21 UTC
Resolved - Our Engineering team identified and resolved an issue that affected Spaces availability in the SFO2 region.
From 11:38 UTC to 11:58 UTC, users may have encountered errors while accessing Spaces objects and creating new buckets in the SFO2 region.
If you continue to experience problems, please open a ticket with our support team. Thank you for your patience and we apologize for any inconvenience.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Network Connectivity in TOR1]]></title>
        <id>https://status.digitalocean.com/incidents/l9d26ggtbw8h</id>
        <link href="https://status.digitalocean.com/incidents/l9d26ggtbw8h"/>
        <updated>2024-03-06T19:09:05.000Z</updated>
        <summary type="html"><![CDATA[Mar  6, 19:09 UTC
Resolved - Our Engineering team has identified and resolved an issue in the TOR1 region that impacted the network connectivity for a subset of Droplets and Droplet-based services for a brief duration.
From 17:38 - 17:47 UTC, users might have experienced delays or errors while accessing and connecting to their resources in the TOR1 region from the public internet or from other resources in TOR1. Swift action was taken by our Engineering team that restored service and all services in TOR1 are operating correctly. 
We apologize for the inconvenience. If you have any questions or continue to experience issues, please reach out via a Support ticket on your account.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Some customers may be unable to access the App Directory]]></title>
        <id>https://slack-status.com/2024-03/a20334cecc6fff7c</id>
        <link href="https://slack-status.com/2024-03/a20334cecc6fff7c"/>
        <updated>2024-03-06T07:23:50.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:
On March 5, 2024 from 3:36 PM PST until 9:36 PM PST some customers were unable to visit the app detail page in App Directory, instead seeing a page displaying a "Server Error" message.

We traced the issue to a recent backend code change and reverted the change, which fixed this issue.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: 'Invite people' popup menu in Manage Members page populates name of wrong workspace.]]></title>
        <id>https://slack-status.com/2024-03/9c34d28b9b3f4e7b</id>
        <link href="https://slack-status.com/2024-03/9c34d28b9b3f4e7b"/>
        <updated>2024-03-06T05:00:19.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:
From March 1, 2024 at 12:13 PM PST to March 4, 2024 at 7:06 PM PST, Enterprise Grid admins and owners may have experienced issues inviting members to workspaces. 

We made a code change that inadvertently introduced a logic error, resulting in the incorrect workspaces being listed in the invite modal. We reverted the code change, restoring normal invite functionality for all affected users.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Managed Databases Control Plane and Connectivity]]></title>
        <id>https://status.digitalocean.com/incidents/s5v9qwsvlxjv</id>
        <link href="https://status.digitalocean.com/incidents/s5v9qwsvlxjv"/>
        <updated>2024-03-05T23:41:12.000Z</updated>
        <summary type="html"><![CDATA[Mar  5, 23:41 UTC
Resolved - Our Engineering team has confirmed that this incident has been fully resolved.
If you continue to experience any issues with Managed Database Clusters please open a ticket with our support team. Thank you for your patience.
Mar  5, 20:28 UTC
Monitoring - Our Engineering team has implemented a fix to resolve the issue with our Managed Databases services. At this time, we're observing error rates returning to pre-incident levels and seeing operations such as create/fork/restore succeed. Trusted sources updates are also functioning normally, so connectivity to Database clusters from newly added resources to trusted sources is restored. 
We are monitoring the situation closely and will post an update as soon as we confirm the issue is fully resolved.
Mar  5, 17:39 …]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[500 Errors Across Multiple Availability Endpoints]]></title>
        <id>https://airbnbapi.statuspage.io/incidents/5qkdf7vy8v6v</id>
        <link href="https://airbnbapi.statuspage.io/incidents/5qkdf7vy8v6v"/>
        <updated>2024-03-05T21:22:24.000Z</updated>
        <summary type="html"><![CDATA[Mar  5, 13:22 PST
Resolved - This incident has been resolved.
Mar  4, 04:41 PST
Monitoring - We've mitigated the issue at 4:10AM PDT and will continue to monitor it.
Mar  4, 02:49 PST
Investigating - We are investigating an increased number of 500 errors across multiple availability related endpoints. These errors started on March 01, 2024.
Our engineering teams are actively working towards a resolution to restore service fully.]]></summary>
        <author>
            <name>Airbnb API Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BLR1 Network Maintenance]]></title>
        <id>https://status.digitalocean.com/incidents/gqwgnn1x1m4z</id>
        <link href="https://status.digitalocean.com/incidents/gqwgnn1x1m4z"/>
        <updated>2024-03-05T15:00:56.000Z</updated>
        <summary type="html"><![CDATA[Mar  5, 15:00 UTC
Completed - The scheduled maintenance has been completed.
Mar  5, 14:00 UTC
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
Mar  5, 11:30 UTC
Scheduled - Start: 2024-03-05 14:00 UTC
End:  2024-03-05 15:00 UTC
During the above window, we will be performing maintenance in our BLR1 region as part of a firewall migration. This maintenance was previously attempted on 2024-02-19 but the changes were reverted after our Engineers encountered unexpected issues, resulting from the maintenance. Our team has performed a thorough examination of the previous attempt and is confident in performing this maintenance, as well as measures to mitigate any negative outcomes. 
Expected impact:
As part of this maintenance, event processing in BLR1 will be delayed for a period of up to 15 minutes during the one-hour window. During this period, users will experience a delay with creating, destroying, or modifying new or existing DO services in BLR1(such as Droplets, DBaaS/DOKS clusters, etc.), existing services that are running should not be impacted.
If you have any questions related to this issue, please send us a ticket from your cloud support page. https://cloudsupport.digitalocean.com/s/createticket]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Some customers are unable to share their screen during a huddle]]></title>
        <id>https://slack-status.com/2024-03/629a8aa472f5f9c2</id>
        <link href="https://slack-status.com/2024-03/629a8aa472f5f9c2"/>
        <updated>2024-03-05T04:32:04.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:
On March 4, 2024, from 4:18 PM PST until 10:17 PM PST some users experienced an issue when sharing their screen during a huddle. Attempting to share their screen would fail without any error or warning.

An incorrect piece of code was identified as the cause of the screen share issue. We safely reverted the problematic code, resolving the issue that users experienced. To capture the fix, a hard refresh (by pressing Cmd/Ctrl + Shift + R) may be required.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[500 Errors Across Multiple Endpoints]]></title>
        <id>https://airbnbapi.statuspage.io/incidents/47y20gmnl3h9</id>
        <link href="https://airbnbapi.statuspage.io/incidents/47y20gmnl3h9"/>
        <updated>2024-03-05T00:16:15.000Z</updated>
        <summary type="html"><![CDATA[Mar  4, 16:16 PST
Resolved - This incident has been resolved.
Error rates have returned to normal levels. Please retry any failed requests.
We apologize for the inconvenience caused and thank you for your patience and understanding.
Mar  4, 14:10 PST
Monitoring - The issue has been mitigated at 1:45 PM PDT. Please apply any failed requests during the incident.
Mar  4, 13:24 PST
Investigating - We are actively investigating an increased number of 500 errors across multiple endpoints. These errors started today (March 4, 2024) around 12:57 PM PDT. Our engineering teams are working to get everything up and running again and we will update you with the latest information as soon as possible.]]></summary>
        <author>
            <name>Airbnb API Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Issue with reservation related webhooks]]></title>
        <id>https://airbnbapi.statuspage.io/incidents/5vnndg8lvchr</id>
        <link href="https://airbnbapi.statuspage.io/incidents/5vnndg8lvchr"/>
        <updated>2024-03-04T22:25:36.000Z</updated>
        <summary type="html"><![CDATA[Mar  4, 14:25 PST
Resolved - This incident has been resolved. Don't hesitate to contact us if you need further assistance.
Mar  4, 11:17 PST
Monitoring - We recently experienced an incident that affected all reservation-related webhooks between 9:54 AM and 10:44 AM PT on March 4, 2024. During this time, you may have noticed reservations being requested, confirmed, altered, and canceled on your listings, but no corresponding webhooks were received. The issue has been resolved, and we will be sending all the missing webhooks in the upcoming hours. In the meantime, if you need to retrieve reservation information for your listings, you can use the GET reservations API. Please note that this incident only affected reservation-related webhooks.
We apologize for the inconvenience, and please don't hesitate to contact us if you need further assistance.]]></summary>
        <author>
            <name>Airbnb API Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Help website is currently unreachable]]></title>
        <id>https://status.make.com/incidents/1vm1k0hxtbdb</id>
        <link href="https://status.make.com/incidents/1vm1k0hxtbdb"/>
        <updated>2024-03-04T10:12:14.000Z</updated>
        <summary type="html"><![CDATA[Mar  4, 11:12 CET
Resolved - We are still in contact with our third-party provider to gather more information and prevent this issue from happening again. Meanwhile, the workaround that was implemented has been working as expected. The incident has been resolved.
Mar  1, 17:44 CET
Monitoring - We have successfully implemented a workaround, and the content of the affected pages is now accessible. However, we are still awaiting a response from the third-party service and further insight into the issue. Currently, the entire webpage is operational. We will continue to monitor the situation closely until we receive additional information from the third party.
Mar  1, 16:51 CET
Update - We are still investigating the issue, and our initial suspicion is that it may be related to one of our third-party services. We anticipate providing the next update within the next 2 hours, or as soon as more information becomes available.
Mar  1, 16:02 CET
Investigating - Our Help and API documentation websites are currently unreachable due to unknown reasons. We are currently investigating the root cause. The rest of the platform's functionalities are unaffected. We will provide an update in the next 30 minutes. Sorry for the inconvenience.]]></summary>
        <author>
            <name>Make Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with API Requests, Copilot, Git Operations, Actions and Pages]]></title>
        <id>https://www.githubstatus.com/incidents/7x5z8plb48t6</id>
        <link href="https://www.githubstatus.com/incidents/7x5z8plb48t6"/>
        <updated>2024-03-01T17:42:41.000Z</updated>
        <summary type="html"><![CDATA[Mar  1, 17:42 UTC
Resolved - On March 1, 2024, between 17:00 UTC and 17:42 UTC, we saw elevated failure rates (from 1 to 10%) for Copilot, Actions, Pages, and Git for various APIs.
This incident was triggered by a newly-discovered failure mode of a deployment pipeline to one of our compute clusters when it could not write a specific configuration file. This caused a drop in the amount of resources available in this cluster, which was mitigated by a redeployment.
We have addressed the specific scenario to ensure resources are properly written and retrieved and added safeguards to ensure the deployment does not proceed if there is an issue of this type.  We are also reviewing our systems to more effectively route traffic toward healthy clusters during an outage and adding more safeguards on cluster resource adjustments.

Mar  1, 17:42 UTC
Update - Git Operations is operating normally.
Mar  1, 17:41 UTC
Update - Actions and Pages are operating normally.
Mar  1, 17:36 UTC
Update - Copilot is operating normally.
Mar  1, 17:34 UTC
Update - Pages is experiencing degraded performance. We are continuing to investigate.
Mar  1, 17:34 UTC
Update - One of our clusters is experiencing problems, and we are working on restoring the cluster at this time.
Mar  1, 17:30 UTC
Investigating - We are investigating reports of degraded performance for API Requests, Copilot, Git Operations and Actions]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Pull Requests, Actions and Issues]]></title>
        <id>https://www.githubstatus.com/incidents/wcl1sw4mzg60</id>
        <link href="https://www.githubstatus.com/incidents/wcl1sw4mzg60"/>
        <updated>2024-03-01T16:12:23.000Z</updated>
        <summary type="html"><![CDATA[Mar  1, 16:12 UTC
Resolved - On March 1, 2024, between 14:17 UTC and 15:54 UTC the service that sends messages from our event stream into our background job processing service was degraded and delayed the transmission of jobs for processing.  No data or jobs were lost.  From 14:17 to 14:41 UTC, there was a partial degradation, where customers would experience intermittent delays with PRs and Actions.  From 14:41 to 15:24 UTC, 36% of PRs users saw stale data, and 100% of in progress Actions workflows did not see updates , even though the workflows were succeeding.  At 15:24 UTC, we mitigated the incident by redeploying our service and jobs began to burn down, with full job catchup by 15:54 UTC. This was due to under provisioned memory and lack of memory based back pressure in the service, which overwhelmed consumers and led to OutOfMemory crashes.
We have adjusted memory configurations to prevent this problem, and are analyzing and adjusting our alert sensitivity to reduce our time to detection of issues like this one in the future.

Mar  1, 16:12 UTC
Update - Issues, Pull Requests and Actions are operating normally.
Mar  1, 15:48 UTC
Update - We're seeing our background job queue sizes trend down, and expect full recovery in the next 15 minutes.
Mar  1, 15:39 UTC
Update - Issues is experiencing degraded performance. We are continuing to investigate.
Mar  1, 15:27 UTC
Update - We're continuing to investigate issues with background jobs that have impacted Actions and Pull Requests. We have a mitigation in place and are monitoring for recovery.
Mar  1, 14:51 UTC
Update - We're investigating issues with background jobs that are causing sporadic delays in pull request synchronization and reduced Actions throughput.
Mar  1, 14:39 UTC
Investigating - We are investigating reports of degraded performance for Pull Requests and Actions]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[New improved payment description format]]></title>
        <id>287075</id>
        <link href="https://changelog.bookingsync.com/new-improved-payment-description-format-287075"/>
        <updated>2024-03-01T12:58:56.000Z</updated>
        <summary type="html"><![CDATA[Improvement
  
We've enhancing the payment descriptions that are displayed in your Stripe or BookingPay account on your transactions, to make them clearer and more useful for you, based on your valuable feedback.
Here's What's Changing:
The description will now include the booking reference:
Old Format: "Payment for Beautiful Example Rental from Monday 27 May 2024, 04:00 PM to Sunday 02 Jun 2024, 10:00 AM"
​


New Format: "Payment for booking XYZ123 at Beautiful Example Rental from 27 May 2024 to 02 Jun 2024"


Why? To streamline tracking and management of your bookings, making reconciliation easier.
Thank you for being a valuable member of the Smily community. We're thrilled to keep enhancing your property management journey!]]></summary>
        <author>
            <name>Megan, Product Manager</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Users unable to create or edit workflows]]></title>
        <id>https://slack-status.com/2024-02/35134eda119581f5</id>
        <link href="https://slack-status.com/2024-02/35134eda119581f5"/>
        <updated>2024-03-01T05:48:33.000Z</updated>
        <summary type="html"><![CDATA[Issue summary: 
On February 29, 2024 from 1:28 PM PST to around 4:36 PM PST, users were unable to create or update some workflows.

We determined that a recent code change had inadvertently introduced a logic problem, resulting in errors for workflows that used event triggers. We reverted this code change. However, rolling back reintroduced a separate issue that we'd resolved earlier in the day. 

We prepared a tailored revert to roll back the code causing the workflow problem while also including the fix for the previous issue. This second revert resolved both problems, restoring full functionality to Slack. 

Thank you for being patient with us.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Workflows are unable to be viewed or triggered]]></title>
        <id>https://slack-status.com/2024-02/939919184ea7655b</id>
        <link href="https://slack-status.com/2024-02/939919184ea7655b"/>
        <updated>2024-02-29T20:47:52.000Z</updated>
        <summary type="html"><![CDATA[Issue summary: 
On February 29, 2024 at 8:00 AM PST to 9:55 AM PST, users saw errors when attempting to trigger and manage legacy workflows.

Upon investigation, we discovered a code change prevented part of the infrastructure that supports workflows from functioning correctly.

To resolve the issue, we reverted the code change and all workflows were restored.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Issues, Webhooks and Actions]]></title>
        <id>https://www.githubstatus.com/incidents/5lc3f39mjcq8</id>
        <link href="https://www.githubstatus.com/incidents/5lc3f39mjcq8"/>
        <updated>2024-02-29T12:27:17.000Z</updated>
        <summary type="html"><![CDATA[Feb 29, 12:27 UTC
Resolved - On February 29, 2024, between 9:32 and 11:54 UTC, queuing in our background job service caused processing delays to Webhooks, Actions, and Issues. Nearly 95% of delays occurred between 11:05 and 11:27 UTC, with 5% during the remainder of the incident. During this incident, the following customer impacts occurred: 50% of webhooks experienced delays of up to 5m, 1% of webhooks experienced delays of 17m at peak; Actions: on average, 7% of customers experienced delays, with a peak of 44%; and many Issues saw a delay in appearing in searches. At 9:32 UTC our automated failover successfully routed traffic to a secondary cluster. But an improper restoration to primary at 10:32 UTC caused a significant increase in queued jobs until 11:21 UTC, when a correction was made and healthy services began burning down the backlog until full resolution.
We have made improvements to the automation and reliability of our fallback process to prevent recurrence. We also have larger work already in progress to improve the overall reliability of our job processing platform.

Feb 29, 12:21 UTC
Update - We're seeing recovery and are going to take time to verify that all systems are back in a working state.
Feb 29, 12:19 UTC
Update - Issues is operating normally.
Feb 29, 12:18 UTC
Update - Webhooks is operating normally.
Feb 29, 11:05 UTC
Update - We're continuing to investigate delayed background jobs. We've seen partial recovery for Issues, and there is ongoing impact to actions, notifications and webhooks.
Feb 29, 10:58 UTC
Update - Actions is experiencing degraded performance. We are continuing to investigate.
Feb 29, 10:36 UTC
Update - We're seeing issues related to background jobs, which are causing delays for webhook delivery and search indexing, and other updates.
Feb 29, 10:33 UTC
Investigating - We are investigating reports of degraded performance for Issues and Webhooks]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Droplet Recovery Image]]></title>
        <id>https://status.digitalocean.com/incidents/dj2p47c4zss1</id>
        <link href="https://status.digitalocean.com/incidents/dj2p47c4zss1"/>
        <updated>2024-02-29T05:50:18.000Z</updated>
        <summary type="html"><![CDATA[Feb 29, 05:50 UTC
Resolved - Our Engineering team identified and resolved an issue that was affecting the booting of Droplets from the Recovery ISO.
From 00:20 UTC to 05:24 UTC, users might have experienced errors when attempting to boot Droplets from the Recovery ISO.
If you continue to experience problems, please open a ticket with our support team. Thank you for your patience and we apologize for any inconvenience.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CreateMessage API - WRITE downtime]]></title>
        <id>https://airbnbapi.statuspage.io/incidents/qfy422ht70s1</id>
        <link href="https://airbnbapi.statuspage.io/incidents/qfy422ht70s1"/>
        <updated>2024-02-29T01:05:56.000Z</updated>
        <summary type="html"><![CDATA[Feb 28, 17:05 PST
Completed - The scheduled maintenance has been completed.
Feb 28, 17:00 PST
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
Feb 22, 23:23 PST
Scheduled - Please note upcoming maintenance occurring on Wednesday, 2/28/2024 at 5:00 PM PT, that will result in ~30-60 second WRITE downtime to CreateMessage API. Reads will not be affected.
Alerts and errors pertaining to Messaging on Wednesday, 2/28/2024 around 5:00 PM PT, are to be expected. Please consider any corrective actions needed to mitigate potential data loss during this ~30-60 second period.]]></summary>
        <author>
            <name>Airbnb API Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Managed Databases creation - PostgresSQL v16]]></title>
        <id>https://status.digitalocean.com/incidents/cd70bby9qynm</id>
        <link href="https://status.digitalocean.com/incidents/cd70bby9qynm"/>
        <updated>2024-02-28T22:53:47.000Z</updated>
        <summary type="html"><![CDATA[Feb 28, 22:53 UTC
Resolved - Our Engineering team has confirmed that creation, forking, and restoration of PostgreSQL clusters on v16 is functioning correctly.
Upgrades for lower-versioned PostgreSQL clusters to v16 remain unavailable at this time and users will see errors if they attempt to perform that upgrade. Our Engineering team continues to work on making upgrades to v16 available again, but we expect this to take some time.
If you continue to experience issues or have any questions, please open a ticket with our support team.
Feb 28, 20:56 UTC
Monitoring - After testing, teams have determined that PostgreSQL v16 is safe for new creations, as well as forks and restores for existing clusters. At this time, v16 is re-enabled in our Cloud Control Panel and users creating, forking, or re…]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SFO Networking]]></title>
        <id>https://status.digitalocean.com/incidents/g4sdvwy4z4zm</id>
        <link href="https://status.digitalocean.com/incidents/g4sdvwy4z4zm"/>
        <updated>2024-02-28T22:49:41.000Z</updated>
        <summary type="html"><![CDATA[Feb 28, 22:49 UTC
Resolved - Our Engineering team has confirmed full resolution of the issue with networking in our SFO2 region. 
If you continue to experience problems, please open a ticket with our support team. Thank you for your patience throughout this incident!
Feb 28, 22:23 UTC
Monitoring - Our Engineering team has confirmed that the faulty network hardware component was the cause of this issue. From 21:39 - 22:11 UTC, this component was not functioning correctly, causing networking issues for a subset of customers in our SFO2 region, as well as internal alerts in our SFO1/SFO3 regions. 
At this time, all services should now be operating normally. We will monitor this incident for a short period of time to confirm full resolution.
Feb 28, 22:17 UTC
Identified - Our Engineering team has identified the cause of the issue with networking in our SFO regions to be related to an issue with a network hardware component in SFO2. They have isolated that component and we're observing error rates returning to pre-incident levels at this time. 
We are continuing to look into this failure, but users should be seeing recovery on their services. We'll provide another update soon.
Feb 28, 22:06 UTC
Investigating - Our Engineering team is currently investigating internal alerts and customer reports for an increase in networking errors in our SFO regions for Droplets and Droplet-based services. We will provide an update as soon as we have further information.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unlock your rental's potential: Expert Vrbo Strategies, Smily Innovations & Upcomming Events! 🗝️]]></title>
        <id>286877</id>
        <link href="https://changelog.bookingsync.com/unlock-your-rental's-potential-expert-vrbo-strategies-smily-innovations-upcomming-events!-286877"/>
        <updated>2024-02-28T10:21:46.000Z</updated>
        <summary type="html"><![CDATA[Communications
  
In today’s Smily newsletter, we directly address Vrbo performance optimization, spotlighting essential optimization tips shared by our Partner Vrbo. We also introduce our latest releases, designed to streamline your operations, and preview upcoming events where Smily will be featured. This edition delivers focused insights and recent developments to strengthen your property management strategies. 🙌
🔍Optimization tips: Enhance your listings on Vrbo
Our partner Vrbo, has generously provided a selection of their top optimization practices to elevate your overall listing's performance. Below are the main highlights, along with guidance on implementing these strategies through your Smily account:
Optimize listing content - What makes a Vrbo listing attractive 💙
Key amenitie…]]></summary>
        <author>
            <name>Ella, Chief Customer Officer (CCO) &amp; Cofounder</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Trouble signing in on mobile for some Owners and Admins]]></title>
        <id>https://slack-status.com/2024-02/2ea2fda2874858b7</id>
        <link href="https://slack-status.com/2024-02/2ea2fda2874858b7"/>
        <updated>2024-02-28T05:55:13.000Z</updated>
        <summary type="html"><![CDATA[Issue Summary: 
On February 27, 2024 from around 8:30 PM PST to 10:06 PM PST Workspace Owners and Admins were experiencing issues while setting up two-factor authentication during sign in on iOS devices.

The issue was caused by a two-factor authentication feature deploy to users on the Pro subscription. After identifying the root cause the feature was was rolled back and this allowed all users to log back into Slack.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AMS3 Network Maintenance]]></title>
        <id>https://status.digitalocean.com/incidents/7rzlkzs0ksqs</id>
        <link href="https://status.digitalocean.com/incidents/7rzlkzs0ksqs"/>
        <updated>2024-02-27T20:00:57.000Z</updated>
        <summary type="html"><![CDATA[Feb 27, 20:00 UTC
Completed - The scheduled maintenance has been completed.
Feb 27, 16:00 UTC
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
Feb 20, 15:19 UTC
Scheduled - Start: 2024-02-27 16:00 UTC
End:  2024-02-27  20:00 UTC

During the above window, our Networking team will be making changes to core networking infrastructure, to improve performance and scalability in the AMS3 region. 
Expected impact:
These upgrades are designed and tested to be seamless and we do not expect any impact to customer traffic due to this maintenance. If an unexpected issue arises, affected Droplets and Droplet-based services may experience increased latency or a brief disruption in network traffic. We will endeavor to keep any such impact to a minimum.
If you have any questions related to this issue please send us a ticket from your cloud support page. https://cloudsupport.digitalocean.com/s/createticket]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Close button for right pane not appearing for some users]]></title>
        <id>https://slack-status.com/2024-02/cedce965afd47ebb</id>
        <link href="https://slack-status.com/2024-02/cedce965afd47ebb"/>
        <updated>2024-02-27T15:41:56.000Z</updated>
        <summary type="html"><![CDATA[Issue summary: 
On February 26, 2024, from 9:21 AM PST to 9:16 AM PST on February 27, some users encountered the close button disappearing in the right pane where threads and profiles are viewed.

We discovered this was caused by a missing check in the change workspace process that prevented the right pane elements from rendering properly. Once the cause was identified, a change was made to the logic for drawing Slack's interface when switching workspaces. Once the change was rolled out, the issue was resolved.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Users are not able to create workflows]]></title>
        <id>https://slack-status.com/2024-02/b1389c8cd318a7d1</id>
        <link href="https://slack-status.com/2024-02/b1389c8cd318a7d1"/>
        <updated>2024-02-27T02:50:48.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:
From 12:30 PM PST to 1:05 PM PST on February 26, 2024, users were unable to create workflows.

We determined that the related API method needed updating in order to eliminate inconsistencies that were causing elevated replication lag.

We deployed an update to the API method correcting this issue, and all workflow creation will now work as expected.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Issues sending and loading messages]]></title>
        <id>https://slack-status.com/2024-02/4c0af99013428a7a</id>
        <link href="https://slack-status.com/2024-02/4c0af99013428a7a"/>
        <updated>2024-02-27T01:47:26.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:
On February 26, 2024 from 9:00 AM PST to 9:36 AM PST, some users experienced problems sending and loading messages in Slack. Others may have completed these actions successfully but more slowly than expected.

Earlier today, we deployed a routine update to part of our network infrastructure. During this work, we deprovisioned some of our proxy servers and provisioned a new set. Some of our webapp servers took longer than expected to sync with the new list of proxy servers, resulting in a spike in connection errors. This coincided with the regular 9:00 AM PST increase in traffic to our servers, which may have exacerbated impact.

By around 9:36 AM PST, error rates had decreased and user impact had completely subsided, most likely due to our automatic scaling functionality. However, we're continuing to analyze data from this event to fully understand the root cause and prevent similar issues in the future.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Issues registering an account]]></title>
        <id>https://status.rippling.com/incidents/5pv7fqwgvtck</id>
        <link href="https://status.rippling.com/incidents/5pv7fqwgvtck"/>
        <updated>2024-02-27T01:21:53.000Z</updated>
        <summary type="html"><![CDATA[Feb 27, 01:21 UTC
Resolved - This incident has been resolved.
Feb 26, 23:24 UTC
Monitoring - A fix has been implemented and we are monitoring the results.
Feb 26, 22:06 UTC
Identified - The issue has been identified and a fix is being implemented.]]></summary>
        <author>
            <name>Rippling Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Problem with executing scenarios]]></title>
        <id>https://status.make.com/incidents/smcl14qd1qxw</id>
        <link href="https://status.make.com/incidents/smcl14qd1qxw"/>
        <updated>2024-02-26T23:06:42.000Z</updated>
        <summary type="html"><![CDATA[Feb 27, 00:06 CET
Resolved - This incident has been resolved.
Feb 26, 21:58 CET
Monitoring - A fix has been implemented and we are monitoring the results.
Feb 26, 21:34 CET
Investigating - We're encountering issues executing scenarios on eu2.make.com. Users may experience delays and errors when attempting to execute any scenarios. There are no other issues with scenario creation or general connectivity to Make. We're currently investigating this issue and will update this Statuspage within the next hour, or as more information comes to hand.]]></summary>
        <author>
            <name>Make Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[We are investigating reports of degraded performance.]]></title>
        <id>https://www.githubstatus.com/incidents/f9ntcnd3fdvs</id>
        <link href="https://www.githubstatus.com/incidents/f9ntcnd3fdvs"/>
        <updated>2024-02-26T21:40:00.000Z</updated>
        <summary type="html"><![CDATA[Feb 26, 21:40 UTC
Resolved - On Monday, February 26th, from 20:45 UTC to 21:39 UTC, GitHub Packages reported an outage indicating a degradation in GitHub Container Registry and NPM package upload functionality. Upon investigation, we found a misconfigured observability metric which inadvertently pulled in data from a newly provisioned test environment. All failures being reported were traced back to this test environment. We confirmed that there was no real customer impact to GitHub Packages during this incident. We have since reconfigured our observability metrics to accurately report based on environment.
Feb 26, 21:20 UTC
Update - We are seeing some recovery in NPM and GitHub Container Registry functionality, but are maintaining red status until we are certain issues won’t recur.
Feb 26, 21:03 UTC
Update - NPM and GitHub Container Registry services are degraded, particularly the upload functionality. Investigation is underway.
Feb 26, 21:01 UTC
Investigating - We are currently investigating this issue.]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Webhooks, Actions, Pull Requests and Issues]]></title>
        <id>https://www.githubstatus.com/incidents/78qz8zwhx9tj</id>
        <link href="https://www.githubstatus.com/incidents/78qz8zwhx9tj"/>
        <updated>2024-02-26T19:37:32.000Z</updated>
        <summary type="html"><![CDATA[Feb 26, 19:37 UTC
Resolved - On February 26, 2024, between 18:34 UTC and 19:37 UTC our background job service was degraded and caused job start delays up to 15 minutes. Users experienced delays in Webhooks, Actions, and some UI updates (e.g. a delay in UI updates on pull requests). This was due to capacity problems with our job queueing service, and a failure of our automated failover system.
We mitigated the incident by manually failing over to our secondary cluster.   No data was lost - recovery began at 18:55 UTC, when the backlog of enqueued jobs began to process.
We are actively working to repair our failover automation and expand the capacity of our background job queuing service to prevent issues like this in the future.

Feb 26, 19:37 UTC
Update - Actions and Pull Requests are operating normally.
Feb 26, 19:37 UTC
Update - Webhooks and Issues are operating normally.
Feb 26, 19:05 UTC
Update - Issues is experiencing degraded performance. We are continuing to investigate.
Feb 26, 18:57 UTC
Update - Pull Requests is experiencing degraded performance. We are continuing to investigate.
Feb 26, 18:55 UTC
Update - We have deployed a fix for issues affecting Webhooks, Actions, and some other services. We are beginning to see recovery and will continue to monitor and fix as needed.
Feb 26, 18:55 UTC
Update - Webhooks is experiencing degraded performance. We are continuing to investigate.
Feb 26, 18:48 UTC
Update - Actions is experiencing degraded performance. We are continuing to investigate.
Feb 26, 18:47 UTC
Investigating - We are investigating reports of degraded performance for Webhooks]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Issues with the billing history page]]></title>
        <id>https://slack-status.com/2024-02/b4d41d5daac6431c</id>
        <link href="https://slack-status.com/2024-02/b4d41d5daac6431c"/>
        <updated>2024-02-26T14:30:45.000Z</updated>
        <summary type="html"><![CDATA[Issue Summary:

From 2:58 PM PST on February 22, 2024, until 9:47 PM PST on February 25, 2024, some users were unable to access their workspace billing history.

We traced the issue to a recent backend code change and reverted the change, which fixed the issue for all affected users.

Thank you very much for your patience while we resolved this.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Manage your VRBO guest review from Smily interface]]></title>
        <id>286647</id>
        <link href="https://changelog.bookingsync.com/manage-your-vrbo-guest-review-from-smily-interface-286647"/>
        <updated>2024-02-26T10:54:27.000Z</updated>
        <summary type="html"><![CDATA[New!
  
Are you connected to VRBO OTA?
Starting today at 2pm UTC, we will be fetching guest reviews and ratings from VRBO, and you'll be able to respond to them directly from Smily interface :)
🚧 Pain Points Addressed:
No need to visit VRBO to check and respond to guest reviews.
Previously, you couldn't rate a guest.
🚀 Benefits for you:
Manage all your reviews in one place.
Easily read and respond to VRBO guest reviews from our Review section on the Smily interface.
Rate guests with ease.
ℹ️ Information and next steps:
We will fetch all your past reviews.


You will be able to rate all past bookings matching those criteria:
--> Bookings without guest review that ended in the last 365 days;
--> Bookings for which a guest review is already present and 14 days haven’t passed since the guest made the review;


Make use of this new feature and ensure to leave reviews for guests. This is an important criterion for VRBO and will impact your property ranking.


Lastly, you can use our "automated reviews" feature, released at the end of last year, for VRBO reviews too.


Have a great review day,
Your Smily team :)]]></summary>
        <author>
            <name>Basile, Product Manager</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scheduled infrastructure maintenance]]></title>
        <id>https://status.make.com/incidents/6hnyx0v9zjbh</id>
        <link href="https://status.make.com/incidents/6hnyx0v9zjbh"/>
        <updated>2024-02-26T07:00:56.000Z</updated>
        <summary type="html"><![CDATA[Feb 26, 08:00 CET
Completed - The scheduled maintenance has been completed.
Feb 26, 06:00 CET
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
Feb 15, 16:40 CET
Scheduled - Hello,
Please note there is scheduled infrastructure maintenance on 26.02.2024, between 6:00-8:00 AM CET, when you can expect a slower scenario processing. Specifically, scenarios using a datastore module might see reduced performance which can cause its longer execution.
We will inform you once the maintenance is completed.
Thank you very much for understanding.
Kind regards,
Make team]]></summary>
        <author>
            <name>Make Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Some template duplication may fail]]></title>
        <id>https://status.notion.so/incidents/gnzy4hx09dq6</id>
        <link href="https://status.notion.so/incidents/gnzy4hx09dq6"/>
        <updated>2024-02-24T00:52:27.000Z</updated>
        <summary type="html"><![CDATA[Feb 23, 16:52 PST
Resolved - Our engineering team identified the issue and released a fix to resolve it.
Feb 23, 16:42 PST
Investigating - Customers may experience an error when duplicating some templates.
Our team is investigating the root cause now and we will share updates as soon as possible.]]></summary>
        <author>
            <name>Notion Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Threads aren't loading for some users]]></title>
        <id>https://slack-status.com/2024-02/548b72776056c03b</id>
        <link href="https://slack-status.com/2024-02/548b72776056c03b"/>
        <updated>2024-02-23T03:05:59.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:
From 2:54 PM to 2:59 PM PDT on February 22, 2024, some users were having issues loading Threads.

We carried out a thorough investigation and observed trends, but found no evidence of an issue on our side. By around 2:59 PM PDT, error rates had already subsided and we received confirmation from several users that they could load Threads again by reloading Slack.

Whilst no remedial action was taken on our end, we're analyzing data from this event to understand ways to mitigate similar issues that may occur in the future.

We're confident that there will be no further impact to users.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Screen readers are not announcing unread messages when using the Ctrl + K command on Windows.]]></title>
        <id>https://slack-status.com/2024-02/83f4c18fc4d11c93</id>
        <link href="https://slack-status.com/2024-02/83f4c18fc4d11c93"/>
        <updated>2024-02-23T01:46:26.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:
On February 21, 2024 from 6:30 PM PST to 8:00 PM PST, customers using the JAWS or NVDA screen readers on Windows may have experienced issues with announcements for unread messages in the Quick Switcher (Ctrl + K). 

A recent code change inadvertently introduced a conflict with an HTML label for an interactive element.

We reverted the code change, fixing the issue and restoring normal announcement behaviour.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Trouble with password resets]]></title>
        <id>https://slack-status.com/2024-02/e04276624660caf9</id>
        <link href="https://slack-status.com/2024-02/e04276624660caf9"/>
        <updated>2024-02-22T14:32:08.000Z</updated>
        <summary type="html"><![CDATA[Issue Summary:

Between 1:18 AM PST on February 21, 2024, and 5:35 AM PST on February 22, 2024, some users experienced issues resetting their passwords, especially when trying to set up two-factor authentication. 

We traced the issue to a recent backend code change and reverted the change, which fixed the issue for all affected users. 

Thank you for your patience while we resolved this and we apologize for any disruption to your work day.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Some users are unable to upload, download, and view files in Slack.]]></title>
        <id>https://slack-status.com/2024-01/f39851209d6c471a</id>
        <link href="https://slack-status.com/2024-01/f39851209d6c471a"/>
        <updated>2024-02-22T14:31:13.000Z</updated>
        <summary type="html"><![CDATA[Issue Summary:

Between 1:18 AM PST on February 21, 2024, and 5:35 AM PST on February 22, 2024, some users experienced issues resetting their passwords, especially when trying to set up two-factor authentication. 

We traced the issue to a recent backend code change and reverted the change, which fixed the issue for all affected users. 

Thank you for your patience while we resolved this and we apologize for any disruption to your work day.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Container Registry Latency in Multiple Regions]]></title>
        <id>https://status.digitalocean.com/incidents/n9211k9rmml7</id>
        <link href="https://status.digitalocean.com/incidents/n9211k9rmml7"/>
        <updated>2024-02-21T20:43:48.000Z</updated>
        <summary type="html"><![CDATA[Feb 21, 20:43 UTC
Resolved - Our Engineering team has confirmed the resolution of the issue impacting the Container Registry in multiple regions. 
Everything involving the Container Registry should now be functioning normally. 
We appreciate your patience throughout the process and if you continue to experience problems, please open a ticket with our support team for further review.
Feb 21, 18:03 UTC
Monitoring - Our Engineering team has identified an internal operation within the Container Registry service which was placing load on the service, leading to latency and errors. The team has paused that operation in order to resolve the issue impacting the Container Registry in multiple regions. Users should not be facing any latency issues while interacting with their Container registries and also while building their Apps. 
We are actively monitoring the situation to ensure stability and will provide an update once the incident has been fully resolved. 
Thank you for your patience and we apologize for the inconvenience.
Feb 21, 15:41 UTC
Investigating - Our Engineering team is investigating an issue with the DigitalOcean Container Registry service. Beginning around 20:00 UTC on February 20, there has been an uptick in 401 errors for image pulls from the Container Registry service.
During this time, a subset of customers may experience latency or see 401 errors while interacting with Container Registries. This issue also impacts App Platform builds and users may encounter delays while building their Apps or experience timeout errors in builds as a result. Users utilizing Container Registry for images for deployment to Managed Kubernetes clusters may also see latency or failures to deploy.
We apologize for the inconvenience and will share an update once we have more information.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Actions]]></title>
        <id>https://www.githubstatus.com/incidents/wn6s1w8vkk1y</id>
        <link href="https://www.githubstatus.com/incidents/wn6s1w8vkk1y"/>
        <updated>2024-02-21T17:30:06.000Z</updated>
        <summary type="html"><![CDATA[Feb 21, 17:30 UTC
Resolved - On Wednesday February 21, 2024, 17:07 UTC, we deployed a configuration change to one of our services inside of Actions. At 17:14 UTC we noticed an increase in exceptions that impacted approximately 85% of runs at that time. 
At 17:18 UTC, we reverted the deployment and our service immediately recovered. During this timeframe, customers may have noticed their workflows failed to trigger or workflows were queued but did not progress.
To prevent this issue in the future we are improving our deployment observability tooling to detect errors earlier in the deployment pipeline.
Feb 21, 17:20 UTC
Investigating - We are investigating reports of degraded performance for Actions]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
</feed>