<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>urn:2023-09-26T00:20:24.641Z</id>
    <title>osmos::feed</title>
    <updated>2023-09-26T00:20:24.641Z</updated>
    <generator>osmosfeed 1.15.1</generator>
    <link rel="alternate" href="index.html"/>
    <entry>
        <title type="html"><![CDATA[Russia SMS Carrier Maintenance - MTS]]></title>
        <id>https://status.twilio.com/incidents/nfcmkq9375t0</id>
        <link href="https://status.twilio.com/incidents/nfcmkq9375t0"/>
        <updated>2023-09-26T04:30:00.000Z</updated>
        <summary type="html"><![CDATA[THIS IS A SCHEDULED EVENT Sep 25, 21:30 - 23:00 PDT
Sep 23, 06:38 PDT
Scheduled - The MTS network in Russia is conducting a planned maintenance from 25 September 2023 at 21:30 PDT until 25 September 2023 at 23:00 PDT. During the maintenance window, there could be intermittent delays delivering SMS to MTS Russia handsets.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Russia SMS Carrier Maintenance - Megafon and Yota]]></title>
        <id>https://status.twilio.com/incidents/xrz7hbjwld58</id>
        <link href="https://status.twilio.com/incidents/xrz7hbjwld58"/>
        <updated>2023-09-26T00:00:33.000Z</updated>
        <summary type="html"><![CDATA[Sep 25, 17:00 PDT
Completed - The scheduled maintenance has been completed.
Sep 25, 13:00 PDT
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
Sep 21, 06:41 PDT
Scheduled - The Megafon and Yota networks in Russia is conducting a planned maintenance from 25 September 2023 at 13:00 PDT until 25 September 2023 at 17:00 PDT. During the maintenance window, there could be intermittent delays delivering SMS to Megafon and Yota Russia handsets.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Russia SMS Carrier Maintenance - Beeline]]></title>
        <id>https://status.twilio.com/incidents/7vf3t6ryzp76</id>
        <link href="https://status.twilio.com/incidents/7vf3t6ryzp76"/>
        <updated>2023-09-26T00:00:09.000Z</updated>
        <summary type="html"><![CDATA[Sep 25, 17:00 PDT
Completed - The scheduled maintenance has been completed.
Sep 25, 14:00 PDT
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
Sep 20, 05:55 PDT
Scheduled - The Beeline network in Russia is conducting a planned maintenance from 25 September 2023 at 14:00 PDT until 25 September 2023 at 17:00 PDT. During the maintenance window, there could be intermittent delays delivering SMS to Beeline Russia handsets.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ukraine SMS Carrier Maintenance - Astelit]]></title>
        <id>https://status.twilio.com/incidents/bsh1hh81mn80</id>
        <link href="https://status.twilio.com/incidents/bsh1hh81mn80"/>
        <updated>2023-09-25T23:00:07.000Z</updated>
        <summary type="html"><![CDATA[Sep 25, 16:00 PDT
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
Sep 20, 21:51 PDT
Scheduled - The Astelit network in Ukraine is conducting a planned maintenance from 25 September 2023 at 16:00 PDT until 25 September 2023 at 20:00 PDT. During the maintenance window, there could be intermittent delays delivering SMS to Astelit Ukraine handsets.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SMS Delivery Delays to CTBC Cellular SA Network in Brazil]]></title>
        <id>https://status.twilio.com/incidents/4280dkf39vcy</id>
        <link href="https://status.twilio.com/incidents/4280dkf39vcy"/>
        <updated>2023-09-25T19:00:08.000Z</updated>
        <summary type="html"><![CDATA[Sep 25, 12:00 PDT
Resolved - We are no longer experiencing SMS delivery delays when sending messages to CTBC Cellular SA network in Brazil. This incident has been resolved.
Sep 25, 10:09 PDT
Monitoring - We are observing recovery in SMS delivery delays when sending messages to CTBC Cellular SA network in Brazil. We will continue monitoring the service to ensure a full recovery. We will provide another update in 2 hours or as soon as more information becomes available.
Sep 25, 08:17 PDT
Update - We are still experiencing SMS delivery delays when sending messages to CTBC Cellular SA network in Brazil. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 2 hours or as soon as more information becomes available.
Sep 25, 07:17 PDT
Investigating - We are experiencing SMS delivery delays when sending messages to CTBC Cellular SA network in Brazil. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 1 hour or as soon as more information becomes available.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SMS Delivery Delays to IUSA Cell Network in Mexico]]></title>
        <id>https://status.twilio.com/incidents/dt4qmqcg9xsb</id>
        <link href="https://status.twilio.com/incidents/dt4qmqcg9xsb"/>
        <updated>2023-09-25T18:39:25.000Z</updated>
        <summary type="html"><![CDATA[Sep 25, 11:39 PDT
Resolved - We are no longer experiencing SMS delivery delays when sending messages to IUSA Cell network in Mexico. This incident has been resolved.
Sep 25, 09:44 PDT
Monitoring - We are observing recovery in SMS delivery delays when sending messages to IUSA Cell network in Mexico. We will continue monitoring the service to ensure a full recovery. We will provide another update in 2 hours or as soon as more information becomes available.
Sep 25, 08:47 PDT
Investigating - We are experiencing SMS delivery delays when sending messages to IUSA Cell network in Mexico. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 1 hour or as soon as more information becomes available.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Trouble with custom emoji]]></title>
        <id>https://status.slack.com//2023-09/8315491ac04ad325</id>
        <link href="https://status.slack.com//2023-09/8315491ac04ad325"/>
        <updated>2023-09-25T18:29:48.000Z</updated>
        <summary type="html"><![CDATA[We’ve shipped a potential fix for this emoji issue, but we’re still monitoring closely. We’ll let you know when functionality is fully restored. Thank you for your patience!]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Data Store application Issue]]></title>
        <id>https://status.make.com/incidents/5r55sspmpx14</id>
        <link href="https://status.make.com/incidents/5r55sspmpx14"/>
        <updated>2023-09-25T12:26:20.000Z</updated>
        <summary type="html"><![CDATA[Sep 25, 14:26 CEST
Resolved - This incident has been resolved.
Sep 21, 18:13 CEST
Monitoring - We have now contacted all customers that were affected by the Data Store issue. We will continue working with them directly to fix any discrepancies that have arisen in their Data Stores. If we have not contacted you, you were not impacted by the issue.
Sep 20, 18:40 CEST
Update - We have now completed our investigation and identified that the issue affected a small percentage of Make users and their organizations. We are preparing to update all impacted customers with information about the scenarios and particular executions that may have produced incorrect data in the Data Store. We expect to update all impacted customers in the next 24 hours.
Sep 20, 14:50 CEST
Update - We have confirmed that …]]></summary>
        <author>
            <name>Make Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mexico SMS Carrier Maintenance - AT&T]]></title>
        <id>https://status.twilio.com/incidents/7sxvk411wwfr</id>
        <link href="https://status.twilio.com/incidents/7sxvk411wwfr"/>
        <updated>2023-09-25T12:00:10.000Z</updated>
        <summary type="html"><![CDATA[Sep 25, 05:00 PDT
Completed - The scheduled maintenance has been completed.
Sep 24, 23:00 PDT
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
Sep 19, 18:54 PDT
Scheduled - The AT&T network in Mexico is conducting a planned maintenance from 24 September 2023 at 23:00 PDT until 25 September 2023 at 05:00 PDT. During the maintenance window, there could be intermittent delays delivering SMS to and from AT&T Mexico handsets.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[US SMS Carrier Maintenance - T-Mobile]]></title>
        <id>https://status.twilio.com/incidents/z2v31kdbv6p4</id>
        <link href="https://status.twilio.com/incidents/z2v31kdbv6p4"/>
        <updated>2023-09-25T11:00:21.000Z</updated>
        <summary type="html"><![CDATA[Sep 25, 04:00 PDT
Completed - The scheduled maintenance has been completed.
Sep 24, 22:01 PDT
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
Sep 22, 00:22 PDT
Scheduled - The T-Mobile network in the US is conducting a planned maintenance from 24 September 2023 at 22:00 PDT until 25 September 2023 at 04:00 PDT. During the maintenance window, there could be intermittent delays delivering SMS to and from T-Mobile US handsets.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[US SMS Carrier Maintenance - AT&T]]></title>
        <id>https://status.twilio.com/incidents/pd43hywffhys</id>
        <link href="https://status.twilio.com/incidents/pd43hywffhys"/>
        <updated>2023-09-25T10:30:07.000Z</updated>
        <summary type="html"><![CDATA[Sep 25, 03:30 PDT
Completed - The scheduled maintenance has been completed.
Sep 25, 00:30 PDT
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
Sep 20, 23:29 PDT
Scheduled - The AT&T network in the US is conducting a planned maintenance from 25 September 2023 at 00:30 PDT until 25 September 2023 at 03:30 PDT. During the maintenance window, there could be intermittent delays delivering SMS to and from AT&T US handsets.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[500 Errors Across Multiple Endpoints]]></title>
        <id>https://airbnbapi.statuspage.io/incidents/lpxzhxccln48</id>
        <link href="https://airbnbapi.statuspage.io/incidents/lpxzhxccln48"/>
        <updated>2023-09-25T03:22:05.000Z</updated>
        <summary type="html"><![CDATA[Sep 24, 20:22 PDT
Resolved - This incident has been resolved.
Error rates have returned to normal levels. Please retry any failed requests.
We apologize for the inconvenience caused and thank you for your patience and understanding.
Sep 22, 10:43 PDT
Monitoring - The issue has been mitigated at 10:30AM PDT. Please apply any failed requests during the incident.
Sep 22, 10:10 PDT
Investigating - We are actively investigating an increased number of 500 errors across multiple endpoints. These errors started today (Sept 22, 2023) around 09:45 AM PDT. Our engineering teams are working to get everything up and running again and we will update you with the latest information as soon as possible.]]></summary>
        <author>
            <name>Airbnb API Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sep 24 2023 Notion is down]]></title>
        <id>https://status.notion.so/incidents/lmy95r4d97sq</id>
        <link href="https://status.notion.so/incidents/lmy95r4d97sq"/>
        <updated>2023-09-25T01:04:53.000Z</updated>
        <summary type="html"><![CDATA[Sep 24, 18:04 PDT
Resolved - The issue has been resolved, and notion.so is available to all users.
Sep 24, 18:03 PDT
Update - The issue has been resolved, and notion.so is available to all users.
Sep 24, 17:56 PDT
Investigating - Notion.so is currently down for some users. We are actively investigating.]]></summary>
        <author>
            <name>Notion Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[New customer signups]]></title>
        <id>https://status.digitalocean.com/incidents/nf42p0nw61c4</id>
        <link href="https://status.digitalocean.com/incidents/nf42p0nw61c4"/>
        <updated>2023-09-23T13:45:35.000Z</updated>
        <summary type="html"><![CDATA[Sep 23, 13:45 UTC
Resolved - Our engineering team has confirmed that the issues affecting the new signups have been fully resolved. We appreciate your patience throughout the process and if you continue to experience problems, please open a ticket with our support team for further review.
Sep 23, 09:53 UTC
Monitoring - Our Engineering team has implemented a fix to resolve the issue impacting new account signups and monitoring the situation. We will post an update as soon as the issue is fully resolved.
Sep 23, 09:40 UTC
Identified - Our Engineering team has identified the issue impacting new account signups and is actively working on a fix. We will post an update as soon as additional information is available.
Sep 23, 09:13 UTC
Investigating - As of 08.45 UTC, our Engineering team is investigating an issue with new customer signups. During this time, some new customers are unable to finish the signup process, as the submit button for the initial questionnaire does not proceed further.
We apologize for the inconvenience and will provide an update as soon as possible.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[RESOLVED: We're investigating reports of an issue with Admin Console. We will provide more information shortly.]]></title>
        <id>https://www.google.com/appsstatus/dashboard/incidents/XafPwePF23NQJgPNtPrC</id>
        <link href="https://www.google.com/appsstatus/dashboard/incidents/XafPwePF23NQJgPNtPrC"/>
        <updated>2023-09-22T18:32:35.000Z</updated>
        <summary type="html"><![CDATA[<p> Incident began at <strong>2023-09-21 21:00</strong> and ended at <strong>2023-09-22 14:10</strong> <span>(times are in <strong>Coordinated Universal Time (UTC)</strong>).</span></p><div class="cBIRi14aVDP__status-update-text"><h1>Mini Incident Report</h1>
<p>We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Workspace Support using help article <a href="https://support.google.com/a/answer/1047213">https://support.google.com/a/answer/1047213</a>.</p>
<p>(All Times US/Pacific)</p>
<p><strong>Incident Start:</strong> 21 September 2023 14:00</p>
<p><strong>Incident End:</strong> 22 September 2023 07:10</p>
<p><strong>Duration:</strong> 17 hours, 10 minutes</p>
<p><strong>Affected Services and Features:</strong></p>
<p>Google Workspace Admin Console</p>
<p><strong>Regions/Zones:</strong> Global</p>
<p><strong>Description:</strong></p>
<p>Google Workspace experienced issues with new domain creations for a duration of 17 hours, 10 minutes. From preliminary analysis, the root cause of the issue was due to a recent change that prevented email verification of the initial user (superuser) on new domains prior to the domain being verified.</p>
<p><strong>Customer Impact:</strong></p>
<p>During the time of impact, the first user (superuser) for new domains would have been unable to access any Google Workspace products. Additional users added to new domains and existing domains were not impacted.</p>
<p><strong>Additional details:</strong></p>
<p>The issue was mitigated by rolling back the change at 07:10 US/Pacific on 22 September.</p>
</div><hr><p>Affected products: Admin Console</p>]]></summary>
        <author>
            <name>Google Workspace Status Dashboard Updates</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Managed Databases Creation]]></title>
        <id>https://status.digitalocean.com/incidents/99c30sdym613</id>
        <link href="https://status.digitalocean.com/incidents/99c30sdym613"/>
        <updated>2023-09-22T18:32:09.000Z</updated>
        <summary type="html"><![CDATA[Sep 22, 18:32 UTC
Resolved - Our Engineering team has confirmed full resolution of the issue with creation of Managed Database clusters.
If you continue to experience problems, please open a ticket with our support team.
Sep 22, 17:58 UTC
Monitoring - Our Engineering team is continuing to investigate the root cause of this incident, but creation of Managed Database clusters has remained stable. 
We will continue to monitor this incident to ensure the issue does not recur and will provide an update when we have more information, or we are confident this is resolved. Thank you.
Sep 22, 17:04 UTC
Update - Our Engineering team continues to investigate the root cause of this issue, but we are now seeing previously created clusters coming online and creations going through correctly. At this time, users should be able to access clusters previously stuck in the creation state and create new clusters.
Sep 22, 16:40 UTC
Investigating - Our Engineering team is investigating an issue with creation of Managed Database clusters not completing. At this time, users may see cluster creation for Postgres, MySQL, Redis, and Kafka clusters taking a long time and/or not completing. 
We will provide another update as soon as we have further information.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Slack Connect invitations page not loading]]></title>
        <id>https://status.slack.com//2023-09/798ffab066d9a5d6</id>
        <link href="https://status.slack.com//2023-09/798ffab066d9a5d6"/>
        <updated>2023-09-22T17:48:18.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:

On September 21, 2023 from 3:00 PM PDT to 8:30 PM PDT, some users encountered a message stating "Something went wrong" when accessing the Slack Connect invites page.


We determined that rate limits set for querying invites were the cause of the "Something went wrong" message. These limits were set prior to the  product decision to include these in the Activity view. Because use of this view has increased, the limits are reached much sooner than originally expected.


These limits were lifted for the invites page, resolving the issue for users. We appreciate your patience while we sorted this out and apologize for any inconvenience this may have caused.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Pages]]></title>
        <id>https://www.githubstatus.com/incidents/4ypqyv8zbrck</id>
        <link href="https://www.githubstatus.com/incidents/4ypqyv8zbrck"/>
        <updated>2023-09-22T17:39:54.000Z</updated>
        <summary type="html"><![CDATA[Sep 22, 17:39 UTC
Resolved - This incident has been resolved.
Sep 22, 17:27 UTC
Update - We have identified the issue with Pages deploys and are actively working to mitigate the issue.
Sep 22, 17:10 UTC
Investigating - We are investigating reports of degraded performance for Pages]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Issues completing an MFA authentication challenge]]></title>
        <id>https://status.rippling.com/incidents/262wf83cx2t3</id>
        <link href="https://status.rippling.com/incidents/262wf83cx2t3"/>
        <updated>2023-09-21T17:04:12.000Z</updated>
        <summary type="html"><![CDATA[Sep 21, 17:04 UTC
Resolved - This incident has been resolved.
Sep 21, 14:11 UTC
Update - We are continuing to monitor for any further issues.
Sep 21, 13:54 UTC
Monitoring - A fix has been implemented and we are monitoring the results.
Sep 21, 13:26 UTC
Identified - The issue has been identified and a fix is being implemented.
Sep 21, 13:22 UTC
Investigating - Users asked to complete an MFA challenge are unable to advance past the page. We are investigating this issue]]></summary>
        <author>
            <name>Rippling Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[HTTP traffic to App Platform in FRA1]]></title>
        <id>https://status.digitalocean.com/incidents/wnx731vkk630</id>
        <link href="https://status.digitalocean.com/incidents/wnx731vkk630"/>
        <updated>2023-09-21T12:59:45.000Z</updated>
        <summary type="html"><![CDATA[Sep 21, 12:59 UTC
Resolved - As of 12:46 UTC, our Engineering team confirmed that the mitigation applied has successfully resolved the issue impacting the App Platform in the FRA1 region. If you continue to experience problems, please open a ticket with our support team from within your Cloud Control Panel.
Thank you for your patience and we apologize for the inconvenience.
Sep 21, 12:52 UTC
Monitoring - As of 12:30 UTC, our Engineering team has identified the issue impacting the App Platform in the FRA1 region and has put mitigations in place to fix the issue. We are actively monitoring the situation to ensure stability and will provide an update once the incident has been fully resolved. In the meantime, if you experience any issues with your APP, please redeploy the App.
Thank you for your patience and we apologize for the inconvenience.
Sep 21, 12:29 UTC
Investigating - As of 12:05 UTC, our Engineering team is investigating reports of an issue with our App Platform service in the FRA1 region. At this time the HTTP traffic to the existing Apps might be affected. Currently, traffic to two clusters in this region is closed. If your App resides in one of these clusters, we request you to redeploy the App so that it will land on a new cluster.
We will provide an update as soon as we have additional information.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Network Connectivity in NYC region]]></title>
        <id>https://status.digitalocean.com/incidents/p931kzltztmb</id>
        <link href="https://status.digitalocean.com/incidents/p931kzltztmb"/>
        <updated>2023-09-21T07:14:44.000Z</updated>
        <summary type="html"><![CDATA[Sep 21, 07:14 UTC
Resolved - From 04:30 - 05:10 UTC, our Engineering team observed an issue with network connectivity in the NYC region. During this time, users might have experienced high latency or errors while connecting to services, including Droplets and Droplet-based products like Managed Kubernetes, Managed Database, and App Platform Apps. 
As of 05:10 UTC, the impact has been subsided and users should no longer be facing network connectivity issues. We apologize for the inconvenience and if you are still experiencing issues or have any additional questions then please open a support ticket from within your account.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Codespaces]]></title>
        <id>https://www.githubstatus.com/incidents/c85syxc7gnbx</id>
        <link href="https://www.githubstatus.com/incidents/c85syxc7gnbx"/>
        <updated>2023-09-20T21:05:57.000Z</updated>
        <summary type="html"><![CDATA[Sep 20, 21:05 UTC
Resolved - This incident has been resolved.
Sep 20, 21:05 UTC
Update - Creates and resumes in US West are working normally
Sep 20, 20:47 UTC
Update - Codespace resumes in US West are currently impacted. New Codespaces are working normally.
Sep 20, 20:21 UTC
Investigating - We are investigating reports of degraded performance for Codespaces]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Users are unable to change their payment method]]></title>
        <id>https://status.notion.so/incidents/sj01vbq7vgb4</id>
        <link href="https://status.notion.so/incidents/sj01vbq7vgb4"/>
        <updated>2023-09-20T21:03:28.000Z</updated>
        <summary type="html"><![CDATA[Sep 20, 14:03 PDT
Resolved - This incident has been resolved. Users are not able to change their payment method.
Sep 20, 13:52 PDT
Identified - The issue has been identified and a fix is being implemented]]></summary>
        <author>
            <name>Notion Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Actions]]></title>
        <id>https://www.githubstatus.com/incidents/ctr28sphxc4c</id>
        <link href="https://www.githubstatus.com/incidents/ctr28sphxc4c"/>
        <updated>2023-09-20T09:33:57.000Z</updated>
        <summary type="html"><![CDATA[Sep 20, 09:33 UTC
Resolved - This incident has been resolved.
Sep 20, 09:31 UTC
Update - We have mitigated the Actions notifications and the service is recovering.
Sep 20, 09:21 UTC
Update - Actions notifications are experiencing degraded performance. We are currently investigating.
Sep 20, 09:20 UTC
Investigating - We are investigating reports of degraded performance for Actions]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Issues, API Requests and Git Operations]]></title>
        <id>https://www.githubstatus.com/incidents/zjchv3zvfg50</id>
        <link href="https://www.githubstatus.com/incidents/zjchv3zvfg50"/>
        <updated>2023-09-20T04:28:09.000Z</updated>
        <summary type="html"><![CDATA[Sep 20, 04:28 UTC
Resolved - This incident has been resolved.
Sep 20, 04:02 UTC
Update - Issues is operating normally.
Sep 20, 04:01 UTC
Update - We experienced an incident causing missing Project item data. We have restored all data from before the incident, up to 19 Sep 20:36 UTC. Project data modified between 20:36 UTC and 20 Sep 00:06 UTC was partially restored.
We will publish a root cause analysis for this issue by Sep 29.
Sep 20, 03:17 UTC
Update - Projects data has been restored to the state prior to the incident (19 Sep 20:57 UTC). We are continuing to restore the last of Project metadata updated since 20:57 UTC.
Sep 20, 02:35 UTC
Update - Projects data has been restored to the state prior to the incident (19 Sep 20:57 UTC). We are continuing to restore the last of Project metadat…]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Pull Requests]]></title>
        <id>https://www.githubstatus.com/incidents/00lscqwb6ht5</id>
        <link href="https://www.githubstatus.com/incidents/00lscqwb6ht5"/>
        <updated>2023-09-19T14:04:05.000Z</updated>
        <summary type="html"><![CDATA[Sep 19, 14:04 UTC
Resolved - This incident has been resolved.
Sep 19, 13:53 UTC
Update - Pull Requests is operating normally.
Sep 19, 13:52 UTC
Update - Push event processing has caught up and there should be no further delays experienced for pull request updates. There will be a tail of delayed notifications being delivered as part of the recovery, and we expect this to be fully caught up in the near future.
Sep 19, 13:29 UTC
Update - We are experiencing a delay in processing for repository push events, which may result in delayed updates to pull requests. We have identified the issue and are seeing recovery, and will provide another update shortly.
Sep 19, 13:21 UTC
Investigating - We are investigating reports of degraded performance for Pull Requests]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[We are investigating reports of degraded performance.]]></title>
        <id>https://www.githubstatus.com/incidents/ndjt4zhsr7q9</id>
        <link href="https://www.githubstatus.com/incidents/ndjt4zhsr7q9"/>
        <updated>2023-09-18T21:33:29.000Z</updated>
        <summary type="html"><![CDATA[Sep 18, 21:33 UTC
Resolved - This incident has been resolved.
Sep 18, 21:28 UTC
Update - There was a regional issue with Codespaces. Instance creation was failing for some customers in West US. The issue has since been mitigated.
Sep 18, 21:28 UTC
Investigating - We are currently investigating this issue.]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Codespaces]]></title>
        <id>https://www.githubstatus.com/incidents/frp2gyhj1mjc</id>
        <link href="https://www.githubstatus.com/incidents/frp2gyhj1mjc"/>
        <updated>2023-09-18T21:26:58.000Z</updated>
        <summary type="html"><![CDATA[Sep 18, 21:26 UTC
Resolved - This incident has been resolved.
Sep 18, 21:16 UTC
Investigating - We are investigating reports of degraded performance for Codespaces]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Checkbox creation and updates down]]></title>
        <id>https://status.notion.so/incidents/5xq6jc04sf0b</id>
        <link href="https://status.notion.so/incidents/5xq6jc04sf0b"/>
        <updated>2023-09-14T18:31:05.000Z</updated>
        <summary type="html"><![CDATA[Sep 14, 11:31 PDT
Resolved - This incident has been resolved. Formulas and checkboxes should now work for all public API users.
Sep 14, 11:24 PDT
Monitoring - At 11:00 AM PT on September 13th, 2023, some API calls for formulas and checkboxes were failing. 
A server rollback has been sent. We are currently monitoring the results.]]></summary>
        <author>
            <name>Notion Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Codespaces]]></title>
        <id>https://www.githubstatus.com/incidents/8rwpr0c6hvbc</id>
        <link href="https://www.githubstatus.com/incidents/8rwpr0c6hvbc"/>
        <updated>2023-09-14T10:21:49.000Z</updated>
        <summary type="html"><![CDATA[Sep 14, 10:21 UTC
Resolved - This incident has been resolved.
Sep 14, 10:01 UTC
Update - We have applied a mitigation to handle elevated errors in a provider. Customers will see increased latency creating and resuming Codespaces instead of failures.
Sep 14, 09:35 UTC
Investigating - We are investigating reports of degraded performance for Codespaces]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[App Platform in NYC1 Region]]></title>
        <id>https://status.digitalocean.com/incidents/5w2hdj0bnc08</id>
        <link href="https://status.digitalocean.com/incidents/5w2hdj0bnc08"/>
        <updated>2023-09-14T09:00:37.000Z</updated>
        <summary type="html"><![CDATA[Sep 14, 09:00 UTC
Resolved - Our Engineering team has confirmed that the problem affecting the App Platform in the NYC1 region has been completely resolved. Users should now be able to access their apps as usual.
If you continue to experience problems, please open a ticket with our support team.
Thank you for your patience and we apologize for any inconvenience.
Sep 14, 07:18 UTC
Monitoring - Our Engineering team has deployed a fix to resolve the issue with App Platform in the NYC1 region. Users should now have access to their apps. We are monitoring the situation closely and will share an update once the issue is resolved completely.
Sep 14, 05:47 UTC
Identified - As of 05:06 UTC, our Engineering team has observed a reoccurrence of the issues that were impacting the App Platform in the NYC1 region. As a result, a subset of our customers may still intermittently experience problems with reaching their apps. Our team is actively investigating the issue and is in the process of implementing a solution. We apologize for any inconvenience caused and will provide updates as the situation progresses.
Sep 14, 04:42 UTC
Monitoring - Our Engineering team has implemented a fix to resolve the issue with App Platform in the NYC1 region. Users should now have the capability to reach their apps. We are monitoring the situation closely and will share an update once the issue is resolved completely.
Sep 14, 04:22 UTC
Investigating - As of 2:30 UTC, our Engineering team is actively investigating issues with App Platform in the NYC1 region. During this time a subset of our customers may intermittently experience problems with reaching apps. We apologize for the inconvenience and will share an update once we have more information]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Networking - Multiple Regions]]></title>
        <id>https://status.digitalocean.com/incidents/tymj4w28h54w</id>
        <link href="https://status.digitalocean.com/incidents/tymj4w28h54w"/>
        <updated>2023-09-14T03:18:13.000Z</updated>
        <summary type="html"><![CDATA[Sep 14, 03:18 UTC
Resolved - Our Engineering team has confirmed full resolution of the issue impacting network connectivity in multiple regions. The impact has been completely subsided and the network connectivity is back to normal for all the impacted services. 
If you continue to experience problems, please open a ticket with our support team from your Cloud Control Panel.
Thank you for your patience and we apologize for any inconvenience.
Sep 14, 00:53 UTC
Monitoring - At this time, all services and regions impacted by this incident are recovered. 
We're now monitoring to ensure stability. 
If you are still experiencing any issues, please let our Support team know.
Sep 13, 21:56 UTC
Update - Our Engineering team has confirmed that additional network routes are impacted, alongside the im…]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Codespaces]]></title>
        <id>https://www.githubstatus.com/incidents/ty1p9pd6pncl</id>
        <link href="https://www.githubstatus.com/incidents/ty1p9pd6pncl"/>
        <updated>2023-09-13T07:16:13.000Z</updated>
        <summary type="html"><![CDATA[Sep 13, 07:16 UTC
Resolved - This incident has been resolved.
Sep 13, 05:02 UTC
Update - We are continuing to work with a third party provider to restore the ability to resume for some Codespaces in the West US region. When we have more detail we will provide another update.
Sep 13, 04:02 UTC
Update - Customers in the West US region may not be able to resume some Codespaces. We have failed over creation for new code spaces and are investigating the issue.
Sep 13, 03:45 UTC
Investigating - We are investigating reports of degraded performance for Codespaces]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Issues creating reservations on test listings]]></title>
        <id>https://airbnbapi.statuspage.io/incidents/43dzv9cm8bpk</id>
        <link href="https://airbnbapi.statuspage.io/incidents/43dzv9cm8bpk"/>
        <updated>2023-09-13T06:17:55.000Z</updated>
        <summary type="html"><![CDATA[Sep 12, 23:17 PDT
Resolved - This incident has been resolved.
Sep 12, 15:38 PDT
Monitoring - We have deployed a fix for this issue, and you can now create reservations on test listings. We will monitor the results for the next couple of hours. Apologies for the inconvenience.
Sep 11, 20:03 PDT
Update - The teams are actively working on the resolution and will require more time than initially expected.
We apologise for the inconvenience caused due to this issue and hope to provide a positive update as soon as we can.
Thank you for your patience and understanding.
Sep  7, 16:31 PDT
Identified - We have identified the issue causing the errors, however, the resolution is not trivial. The ETA for resolution is Monday, Sep 11, 2023 the latest. Apologies for the inconvenience.
Sep  7, 12:12 PDT
Investigating - We are investigating an issue where you can't create reservations on test listings. When you select dates to book a test listing, the following message appears "Those dates are not available", although the dates are available. We are actively looking into this issue and will provide updates as soon as possible,]]></summary>
        <author>
            <name>Airbnb API Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Subsea Fiber Faults]]></title>
        <id>https://status.digitalocean.com/incidents/0yj0wwt12hfc</id>
        <link href="https://status.digitalocean.com/incidents/0yj0wwt12hfc"/>
        <updated>2023-09-12T15:41:22.000Z</updated>
        <summary type="html"><![CDATA[Sep 12, 15:41 UTC
Resolved - Our Engineering team has observed stability for network routes and App Platform builds and deployments over the last week. Given this, we will proceed with closing out this incident. 
If the situation changes or we receive any important updates regarding the repair of the fiber faults, we will communicate as needed. 
If you are still experiencing any issues or have any questions, please feel free to open a support ticket from within your account. Thank you for your patience.
Sep  2, 04:32 UTC
Monitoring - Our Engineering team has observed some improvement in the networking routes between NYC and the Western EU, including FRA, AMS, and LON.
Due to the general nature of internet outages, DigitalOcean users may still experience degraded network performance in the …]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Billing system improvements]]></title>
        <id>273866</id>
        <link href="https://changelog.bookingsync.com/billing-system-improvements-273866"/>
        <updated>2023-09-11T07:16:47.000Z</updated>
        <summary type="html"><![CDATA[New!
 
Improvement
  
Tired of billing problems taking up a lot of your time? We understand!
Not long ago, we introduced some changes to our pricing model, which now takes into account your Gross Booking Value (GBV) and adjusts your monthly fee accordingly. Since this change, we understand that you’ve experienced some issues with your monthly payments to Smily and that this has been incredibly frustrating for you.
We are working hard to improve your payments experience, so that you no longer have to spend your time and energy solving payment issues.
We’re very happy to announce the first in a series of changes to the way in which you pay for Smily.
We are moving towards a billing system where:
For every payment that is due on your account, we will immediately issue an invoice.


The invoic…]]></summary>
        <author>
            <name>Megan, Product Manager</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Issues with Loading Insights Graphs]]></title>
        <id>https://status.digitalocean.com/incidents/l2szqpvkw4s1</id>
        <link href="https://status.digitalocean.com/incidents/l2szqpvkw4s1"/>
        <updated>2023-09-09T06:41:14.000Z</updated>
        <summary type="html"><![CDATA[Sep  9, 06:41 UTC
Resolved - Our Engineering team has confirmed full resolution of the issue with loading the Insights graphs. As of 06.23 UTC, users should be able to access the Insights graphs, and these graphs will display the expected data. 
If you continue to experience problems, please open a ticket with our support team. 
Thank you for your patience and we apologize for any inconvenience.
Sep  9, 06:23 UTC
Monitoring - Our Engineering team has implemented a fix to resolve the issue with loading the Insights graphs. Users should now be able to access the Insights graphs, and these graphs will display the expected data. We are monitoring the situation closely and will share an update once the issue is resolved completely.
Sep  9, 06:10 UTC
Identified - Our Engineering team has identified the cause of the issue with loading the Insights graphs and is actively working on a fix. During this time, you might encounter errors when trying to access Insights graphs, and the graphs may not display any data. We will post an update as soon as additional information is available.
Sep  9, 05:52 UTC
Investigating - As of 05.15 UTC, our Engineering team is investigating issues with viewing Insights graphs. During this time, you might encounter errors when trying to access Insights graphs, and the graphs may not display any data. We regret any inconvenience this may cause and will provide further information as soon as we have more details.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Some Admins are missing DMs in Single User Exports]]></title>
        <id>https://status.slack.com//2023-09/5b5bbd0b1b68e294</id>
        <link href="https://status.slack.com//2023-09/5b5bbd0b1b68e294"/>
        <updated>2023-09-08T19:42:47.000Z</updated>
        <summary type="html"><![CDATA[We've determined this issue impacts a small subset of admins on Enterprise Grid. We'll work to fix this internally, and provide further updates through customer support tickets. We apologize for any disruptions to your day.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Some users are receiving an error while attempting to load app configurations]]></title>
        <id>https://status.slack.com//2023-09/d0d43b69112068ec</id>
        <link href="https://status.slack.com//2023-09/d0d43b69112068ec"/>
        <updated>2023-09-08T01:38:58.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:

From September 6, 2023 at 9:50 PM PDT until September 7, 2023 at 3:18 AM PDT, some users may have encountered a 500 error when attempting to access their app configuration pages. 


We determined that a code change inadvertently omitted some recently updated parameters, causing these pages to return errors and preventing customers from accessing or modifying their app configurations.


We implemented an initial fix to rectify the 500 errors for most pages, and then a second fix to address any outstanding issues. With both fixes in place, we restored full access to all app configuration pages.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Git Operations]]></title>
        <id>https://www.githubstatus.com/incidents/2gy2gddtv23d</id>
        <link href="https://www.githubstatus.com/incidents/2gy2gddtv23d"/>
        <updated>2023-09-07T10:38:12.000Z</updated>
        <summary type="html"><![CDATA[Sep  7, 10:38 UTC
Resolved - This incident has been resolved.
Sep  7, 10:02 UTC
Investigating - We are investigating reports of degraded performance for Git Operations]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Webhooks]]></title>
        <id>https://www.githubstatus.com/incidents/n8wpsvv7wt6x</id>
        <link href="https://www.githubstatus.com/incidents/n8wpsvv7wt6x"/>
        <updated>2023-09-06T21:58:38.000Z</updated>
        <summary type="html"><![CDATA[Sep  6, 21:58 UTC
Resolved - This incident has been resolved.
Sep  6, 21:51 UTC
Update - We have mitigated the issue with webhooks and are working to confirm that customers are no longer seeing issues verifying payload signatures.
Sep  6, 20:36 UTC
Update - We are investigating reports of issues with verifying webhook payload signatures. We will provide updates as we have them.
Sep  6, 20:32 UTC
Investigating - We are investigating reports of degraded performance for Webhooks]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Git Operations]]></title>
        <id>https://www.githubstatus.com/incidents/njb4tgwrkv34</id>
        <link href="https://www.githubstatus.com/incidents/njb4tgwrkv34"/>
        <updated>2023-09-06T11:41:38.000Z</updated>
        <summary type="html"><![CDATA[Sep  6, 11:41 UTC
Resolved - This incident has been resolved.
Sep  6, 10:07 UTC
Update - We identified the issue affecting Git Operations and applied the mitigation. We expect service to fully recover in 30 min.
Sep  6, 09:03 UTC
Update - Operations that download Git archives and raw files are seeing highly elevated response times (up to 4+ seconds) for users. Other Git operations are not impacted. We are working on mitigation.
Sep  6, 08:53 UTC
Update - We are investigating reports of issues with service(s): Git Operations. We will continue to keep users updated on progress towards mitigation.
Sep  6, 08:21 UTC
Investigating - We are investigating reports of degraded performance for Git Operations]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Temporary Outage]]></title>
        <id>https://status.notion.so/incidents/d091c2f258j9</id>
        <link href="https://status.notion.so/incidents/d091c2f258j9"/>
        <updated>2023-09-06T01:54:44.000Z</updated>
        <summary type="html"><![CDATA[Sep  5, 18:54 PDT
Resolved - From 6:25pm PDT - 6:46pm PDT, we experienced an issue that prevented users from accessing Notion. The issue has been resolved, so users should be able to access Notion again. We'll continue to monitor performance and provide updates if we experience other issues.
Root cause: 
One of our memcache clusters crashed and caused our API cluster to get stuck. Engineering resolved the issue by restarting them. We’ll continue to investigate on what caused the cluster to crash.]]></summary>
        <author>
            <name>Notion Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: A small number of users are experiencing issues loading Slack.]]></title>
        <id>https://status.slack.com//2023-09/a6b0cdff3fbe130e</id>
        <link href="https://status.slack.com//2023-09/a6b0cdff3fbe130e"/>
        <updated>2023-09-05T22:50:42.000Z</updated>
        <summary type="html"><![CDATA[Issue Summary:

From 6:00 PM PST on September 3, 2023 to 12:40 PM PST on September 5, 2023, some users could not launch their Slack desktop apps.


We determined that a code change caused the app to call deleted workspaces for users, resulting in an error and an app loading loop.


Once the root cause was identified, we immediately made an adjustment to the code so that it did not call deleted teams for users, which resulted in the app loading properly once more.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Some customers are unable to switch channels in the web browser.]]></title>
        <id>https://status.slack.com//2023-09/6bb97b903beac5b6</id>
        <link href="https://status.slack.com//2023-09/6bb97b903beac5b6"/>
        <updated>2023-09-05T21:53:09.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:

From 12:24 PM PDT on August 30, 2023 to 12:44 PM PDT on September 5, 2023, some users were unable to switch channels using Slack in the browser.


We determined that the clicking on a channel in the sidebar ended up in a codepath which was requesting focus of the main Slack window. So in any case where the Slack app was opened from another page, the users encountered an issue.


The code change was reverted and a fix was deployed which resolved the issue for all affected users.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Actions, Pages, Pull Requests, Codespaces, API Requests, Issues, Webhooks and Packages]]></title>
        <id>https://www.githubstatus.com/incidents/smdz34v7j8q0</id>
        <link href="https://www.githubstatus.com/incidents/smdz34v7j8q0"/>
        <updated>2023-09-05T17:01:49.000Z</updated>
        <summary type="html"><![CDATA[Sep  5, 17:01 UTC
Resolved - From 16:24-16:43 UTC, multiple GitHub services were down or degraded due to an outage in one of our primary databases. 
The primary host for a shared datastore for GitHub experienced an underlying file system write error which affected availability for the majority of public-facing GitHub services. SAML login was affected, as was access to Actions, Issues, Pull Requests, Pages, API, Webhooks, Codespaces, and Packages. In this case, our automatic failover was unable to handle the partial file system failure mode. We mitigated by manually performing a forced failover, initiated 17 minutes after our first alert and completed 2 minutes later.
With the incident mitigated, we are working to assess more detailed impact and resilience improvements to each impacted serv…]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Git Operations and Actions]]></title>
        <id>https://www.githubstatus.com/incidents/frdfpnnt85s8</id>
        <link href="https://www.githubstatus.com/incidents/frdfpnnt85s8"/>
        <updated>2023-09-05T14:19:40.000Z</updated>
        <summary type="html"><![CDATA[Sep  5, 14:19 UTC
Resolved - Between 06:59 UTC to 13:18 UTC GitHub customers experienced intermittent increased latency when using our git archive and raw file downloading capability. This capability is typically used for larger CI/CD systems and bulk download of repository data.  This also caused intermittent periods of Actions workflow failures.
During this incident we saw bursts of increased unique traffic on specific endpoints that overloaded our caching capability for this system. In addition, the traffic caused saturation of the service that exposed a bug in downloading archived files at high load which caused some archives to be downloaded with incomplete data. This caused intermittent failure of workflows for GitHub Actions, which primarily downloads actions data via these endpoint…]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with API Requests, Pull Requests and Actions]]></title>
        <id>https://www.githubstatus.com/incidents/c8zjb9351hlc</id>
        <link href="https://www.githubstatus.com/incidents/c8zjb9351hlc"/>
        <updated>2023-09-05T05:10:01.000Z</updated>
        <summary type="html"><![CDATA[Sep  5, 05:10 UTC
Resolved - This incident has been resolved.
Sep  5, 05:09 UTC
Update - API Requests is operating normally.
Sep  5, 05:09 UTC
Update - Actions is operating normally.
Sep  5, 04:52 UTC
Update - We are investigating reports of issues with service(s): Actions, API Requests, Pull Requests. We will continue to keep users updated on progress towards mitigation.
Sep  5, 04:51 UTC
Update - Actions is experiencing degraded performance. We are continuing to investigate.
Sep  5, 04:17 UTC
Investigating - We are investigating reports of degraded performance for API Requests and Pull Requests]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Actions]]></title>
        <id>https://www.githubstatus.com/incidents/w01m57lwx8r3</id>
        <link href="https://www.githubstatus.com/incidents/w01m57lwx8r3"/>
        <updated>2023-09-05T03:27:28.000Z</updated>
        <summary type="html"><![CDATA[Sep  5, 03:27 UTC
Resolved - This incident has been resolved.
Sep  5, 03:18 UTC
Investigating - We are investigating reports of degraded performance for Actions]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Actions]]></title>
        <id>https://www.githubstatus.com/incidents/tqrmcdmghldw</id>
        <link href="https://www.githubstatus.com/incidents/tqrmcdmghldw"/>
        <updated>2023-09-04T21:56:49.000Z</updated>
        <summary type="html"><![CDATA[Sep  4, 21:56 UTC
Resolved - This incident has been resolved.
Sep  4, 21:28 UTC
Investigating - We are investigating reports of degraded performance for Actions]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Some users in India are having trouble sending DMs.]]></title>
        <id>https://status.slack.com//2023-09/64d234fca6bc1e06</id>
        <link href="https://status.slack.com//2023-09/64d234fca6bc1e06"/>
        <updated>2023-09-04T15:24:43.000Z</updated>
        <summary type="html"><![CDATA[Issue Summary:


From 11:00 PM PDT on September 1, 2023 to 01:00 AM PDT on September 2, 2023, some users in India may have had issues with the messaging functionality in Slack.


We determined that the issue was caused by too many requests causing our database to be overwhelmed.


To resolve the issue, we created additional hosts and redistributed the requests which fixed the issue for affected users. 


Thank you for your patience while we sorted this out.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Actions]]></title>
        <id>https://www.githubstatus.com/incidents/76xp2jd3px64</id>
        <link href="https://www.githubstatus.com/incidents/76xp2jd3px64"/>
        <updated>2023-09-04T14:48:44.000Z</updated>
        <summary type="html"><![CDATA[Sep  4, 14:48 UTC
Resolved - This incident has been resolved.
Sep  4, 14:21 UTC
Investigating - We are investigating reports of degraded performance for Actions]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Users are unable to post to the #general channel]]></title>
        <id>https://status.slack.com//2023-08/414e590c93cb5636</id>
        <link href="https://status.slack.com//2023-08/414e590c93cb5636"/>
        <updated>2023-09-01T18:36:44.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:

On August 23, 2023 from 4:30 PM PDT to August 31, 2023 11:26 PM PDT, some users experienced an issue posting messages in the designated #general channel of their workspace. 


Our team identified that recent changes in our code broke some conditional logic and deprecated the preference that allows users to post in the #general channel.


We pushed out a fix and asked affected users to reload their Slack apps. This combination of steps resolved the issue.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Codespaces]]></title>
        <id>https://www.githubstatus.com/incidents/wz41ffzj8937</id>
        <link href="https://www.githubstatus.com/incidents/wz41ffzj8937"/>
        <updated>2023-09-01T15:06:06.000Z</updated>
        <summary type="html"><![CDATA[Sep  1, 15:06 UTC
Resolved - This incident has been resolved.
Sep  1, 14:51 UTC
Update - A limited number of users in the UK and Western Europe are experiencing issues starting or reconnecting to GitHub Codespaces. We are investigating the issue.
Sep  1, 14:35 UTC
Investigating - We are investigating reports of degraded performance for Codespaces]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MongoDB Cluster Creation Failure]]></title>
        <id>https://status.digitalocean.com/incidents/t4hymf61fn71</id>
        <link href="https://status.digitalocean.com/incidents/t4hymf61fn71"/>
        <updated>2023-08-31T19:27:11.000Z</updated>
        <summary type="html"><![CDATA[Aug 31, 19:27 UTC
Resolved - The maintenance that was scheduled to prevent the recurrence of this issue has been completed as of 19:00 UTC and our Engineering team has confirmed that the issue affecting the creation of Mongo Managed Database clusters is fully resolved. 
We appreciate your patience throughout the process and if you continue to experience problems, please open a ticket with our support team for further review.
Aug 31, 17:03 UTC
Update - Our Engineering team has identified that urgent maintenance is needed in order to remediate this incident and prevent a recurrence. 
From 18:00 -19:00 UTC, we’ll be performing that maintenance. Further details and updates throughout the maintenance can be found here:  https://status.digitalocean.com/incidents/cq5jj3snkp64 
Once completed, we will update this incident after confirming the issue is fully resolved.
Aug 31, 11:44 UTC
Monitoring - Our engineering team has implemented a fix to resolve the issue that was preventing users from creating a MongoDB cluster in any region and is monitoring the situation. We will post an update as soon as the issue is fully resolved.
Aug 31, 10:53 UTC
Identified - Our engineering team has identified the cause of the issue that was preventing users from creating a MongoDB cluster in any region and is working on a fix. We will post an update as soon as additional information is available.
Aug 31, 09:56 UTC
Investigating - As of 09:30 UTC, our engineering team is investigating an issue that prevents creating a MongoDB cluster in any region. During this time, you may face issues when creating a MongoDB cluster. We apologize for the inconvenience and will share an update once we have more information.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Core Infrastructure Maintenance]]></title>
        <id>https://status.digitalocean.com/incidents/cq5jj3snkp64</id>
        <link href="https://status.digitalocean.com/incidents/cq5jj3snkp64"/>
        <updated>2023-08-31T19:00:04.000Z</updated>
        <summary type="html"><![CDATA[Aug 31, 19:00 UTC
Completed - The scheduled maintenance has been completed.
Aug 31, 18:25 UTC
Update - The failover process is complete and teams have verified services are running as expected. During the failover, we did observe a small amount of failed requests for the services indicated, but overall impact was very minimal. We aren't expecting any further customer impact. 
Our team is now performing the final actions in this maintenance and we're continuing to monitor.
Aug 31, 18:00 UTC
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
Aug 31, 16:51 UTC
Scheduled - Start Time: 18:00 UTC
End Time: 19:00 UTC
During this time, our Engineering Team will be performing maintenance to failover an internal service from one cluster to another. 
T…]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[We are investigating reports of degraded performance.]]></title>
        <id>https://www.githubstatus.com/incidents/cbhwcvtkfr34</id>
        <link href="https://www.githubstatus.com/incidents/cbhwcvtkfr34"/>
        <updated>2023-08-30T21:04:08.000Z</updated>
        <summary type="html"><![CDATA[Aug 30, 21:04 UTC
Resolved - This incident has been resolved.
Aug 30, 20:56 UTC
Investigating - We are currently investigating this issue.]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Webhooks]]></title>
        <id>https://www.githubstatus.com/incidents/f7lz4nc72bvp</id>
        <link href="https://www.githubstatus.com/incidents/f7lz4nc72bvp"/>
        <updated>2023-08-30T20:53:20.000Z</updated>
        <summary type="html"><![CDATA[Aug 30, 20:53 UTC
Resolved - This incident has been resolved.
Aug 30, 20:42 UTC
Update - Webhook delays have been reduced significantly. We anticipate returning to nominal service soon.
Aug 30, 19:13 UTC
Update - The remediation for Webhook delivery delays has been implemented. We will continue to keep users updated on Webhook latency improvements.
Aug 30, 18:10 UTC
Update - We are addressing the source of Webhook delays, and will continue to keep users updated on progress towards mitigation.
Aug 30, 17:37 UTC
Update - We have identified the source of delay in webhook deliveries and are in the process of implementing a fix.
Aug 30, 16:49 UTC
Update - We are investigating increased delivery time issues with Webhooks. We will continue to keep users updated on progress towards mitigation.
Aug 30, 16:45 UTC
Investigating - We are investigating reports of degraded performance for Webhooks]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Issues with workflows and app modals]]></title>
        <id>https://status.slack.com//2023-08/52eff24d7806f1cf</id>
        <link href="https://status.slack.com//2023-08/52eff24d7806f1cf"/>
        <updated>2023-08-30T14:22:50.000Z</updated>
        <summary type="html"><![CDATA[Issue Summary:


From 11:32 PM PDT on August 29, 2023 to 02:06 AM PDT on August 30, 2023, some users may have seen an internal server or connection error in workflow and app modals.


We determined that a code change inadvertently caused an issue where incorrect data was stored in our database. When a modal was opened it used this incorrect data and displayed a connection error to users.


The code change was reverted and a fix was deployed which resolved the issue for all affected users.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Webhooks]]></title>
        <id>https://www.githubstatus.com/incidents/wqv4yvlgtq62</id>
        <link href="https://www.githubstatus.com/incidents/wqv4yvlgtq62"/>
        <updated>2023-08-29T21:58:10.000Z</updated>
        <summary type="html"><![CDATA[Aug 29, 21:58 UTC
Resolved - This incident has been resolved.
Aug 29, 21:52 UTC
Update - GitHub webhooks are fully functional but can take up to 20 minutes to deliver. We are working on identifying the root cause of the increased latency.
Aug 29, 20:55 UTC
Update - The Webhooks backlog continues to process, and we anticipate continued latency while it clears.
Aug 29, 19:38 UTC
Update - The Webhooks backlog continues to process, and we anticipate continued latency while it clears.
Aug 29, 18:24 UTC
Update - We’ve mitigated the issue causing Webhooks latency and are monitoring processing of the backlog of queued requests.
Aug 29, 17:31 UTC
Update - We are investigating increased delivery time issues with Webhooks. We will continue to keep users updated on progress towards mitigation.
Aug 29, 17:29 UTC
Investigating - We are investigating reports of degraded performance for Webhooks]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Less than 1% of users may be experiencing slowness when loading Slack]]></title>
        <id>https://status.slack.com//2023-08/094f489e39b57d9f</id>
        <link href="https://status.slack.com//2023-08/094f489e39b57d9f"/>
        <updated>2023-08-29T16:54:59.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:

On August 28, 2023 from 4:30 AM PDT to 10:30 AM PDT, less than 1% of Slack users encountered slowness when loading channels, DMs, and threads. Some impacted users were also unable to load the sidebar.


We found that a host that caches workspace member, channel, and integration data was impacted by timeout errors. This prevented users on some workspaces from routing to the host and, in turn, reaching their cached data. 


We restarted the affected host, cleared the associated cache for impacted workspaces, and asked affected users to reload their Slack apps. This combination of steps resolved the issue for all users. 


We're continuing to investigate what caused the timeout errors to prevent future reoccurrence.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[We are investigating reports of degraded performance.]]></title>
        <id>https://www.githubstatus.com/incidents/99rhjnxq99tp</id>
        <link href="https://www.githubstatus.com/incidents/99rhjnxq99tp"/>
        <updated>2023-08-29T16:16:46.000Z</updated>
        <summary type="html"><![CDATA[Aug 29, 16:16 UTC
Resolved - This incident has been resolved.
Aug 29, 16:05 UTC
Update - Intermittent failures with our resource provider prevented around 200 Codespaces from launching or resuming in Europe West and Southeast Asia. We have mitigated impact and continue to monitor.
Aug 29, 16:05 UTC
Investigating - We are currently investigating this issue.]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Codespaces]]></title>
        <id>https://www.githubstatus.com/incidents/yyr2ghh113dj</id>
        <link href="https://www.githubstatus.com/incidents/yyr2ghh113dj"/>
        <updated>2023-08-29T15:35:49.000Z</updated>
        <summary type="html"><![CDATA[Aug 29, 15:35 UTC
Resolved - This incident has been resolved.
Aug 29, 15:25 UTC
Update - We are investigating issues with Codespaces in the Europe West and Southeast Asia geographic areas. Some users may not be able to connect to their Codespaces at this time. We will update on progress.
Aug 29, 15:13 UTC
Investigating - We are investigating reports of degraded performance for Codespaces]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Actions, Pull Requests and Webhooks]]></title>
        <id>https://www.githubstatus.com/incidents/spz29wshw9mh</id>
        <link href="https://www.githubstatus.com/incidents/spz29wshw9mh"/>
        <updated>2023-08-29T02:36:47.000Z</updated>
        <summary type="html"><![CDATA[Aug 29, 02:36 UTC
Resolved - This incident has been resolved.
Aug 29, 02:34 UTC
Update - Webhooks is operating normally.
Aug 29, 02:34 UTC
Update - Pull Requests is operating normally.
Aug 29, 02:34 UTC
Update - Actions is operating normally.
Aug 29, 02:15 UTC
Update - GitHub webhooks are delayed, and required pull-request checks and reviews are not triggered.
Aug 29, 02:14 UTC
Update - Webhooks is experiencing degraded performance. We are continuing to investigate.
Aug 29, 02:07 UTC
Update - Newly triggered Actions workflows are stalled. We identified the problem, and we are working on a mitigation.
Aug 29, 02:02 UTC
Update - Pull Requests is experiencing degraded performance. We are continuing to investigate.
Aug 29, 01:59 UTC
Investigating - We are investigating reports of degraded performance for Actions]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[App platform deployment and rollbacks in NYC region]]></title>
        <id>https://status.digitalocean.com/incidents/5zn0vljq3hnd</id>
        <link href="https://status.digitalocean.com/incidents/5zn0vljq3hnd"/>
        <updated>2023-08-27T12:22:38.000Z</updated>
        <summary type="html"><![CDATA[Aug 27, 12:22 UTC
Resolved - As of 12:22 UTC, our Engineering team has resolved the issue impacting the builds and rollbacks in our NYC region. Everything should be functioning normally and users should no longer experience issues with the builds and rollbacks being stuck.
We appreciate your patience throughout the process and if you continue to experience problems, please open a ticket with our support team for further review.
Aug 27, 11:29 UTC
Monitoring - As of 11:28 UTC, our Engineering team has implemented a fix to resolve the issue with the App platform impacting the builds and rollbacks in our NYC region and monitoring the situation. At this time, users should no longer experience issues with active deployment and rollbacks being stuck. 
We will share another update once the matter is fully resolved.
Aug 27, 09:32 UTC
Update - As of 09:32 UTC, our Engineering team has identified the cause of the issue with the App platform impacting the builds and rollbacks in our NYC region and has implemented a fix that has partially mitigated the issue. Currently, our Engineering team is working on investigating the issue further and implementing a permanent fix.
We will post an update as soon as additional information is available.
Aug 27, 06:32 UTC
Identified - As of 06:21 UTC, our Engineering team has identified the cause of the issue with the App platform impacting the builds and rollbacks in our NYC region and is actively working on a fix. We will post an update as soon as additional information is available.
Aug 27, 05:35 UTC
Investigating - Our Engineering team is investigating an issue with App Platform builds and rollbacks in our NYC region. At this time, users may experience issues with active deployment and rollbacks being stuck.
We will post an update as soon as additional information is available.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
</feed>