<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>urn:2023-12-10T00:24:17.464Z</id>
    <title>osmos::feed</title>
    <updated>2023-12-10T00:24:17.464Z</updated>
    <generator>osmosfeed 1.15.1</generator>
    <link rel="alternate" href="index.html"/>
    <entry>
        <title type="html"><![CDATA[SMS Delivery Delays to the Viaero Wireless Network in United States]]></title>
        <id>https://status.twilio.com/incidents/89n5ccfymjs2</id>
        <link href="https://status.twilio.com/incidents/89n5ccfymjs2"/>
        <updated>2023-12-09T23:28:40.000Z</updated>
        <summary type="html"><![CDATA[Dec  9, 15:28 PST
Update - We continue to experience SMS delivery delays when sending messages to the Viaero Wireless network in the United States. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 4 hours or as soon as more information becomes available.
Dec  9, 13:28 PST
Update - We are still experiencing SMS delivery delays when sending messages to the Viaero Wireless network in the United States. Our engineers continue to work with our carrier partner to resolve the issue. We will provide another update in 2 hours or as soon as more information becomes available.
Dec  9, 12:29 PST
Investigating - We are experiencing SMS delivery delays when sending messages to the Viaero Wireless network in the United States. Our engineers are working with our carrier partner to resolve the issue. We will provide another update in 1 hour or as soon as more information becomes available.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Error Listing Support Articles on help.twilio.com]]></title>
        <id>https://status.twilio.com/incidents/mpv0pl0cfk48</id>
        <link href="https://status.twilio.com/incidents/mpv0pl0cfk48"/>
        <updated>2023-12-09T21:25:41.000Z</updated>
        <summary type="html"><![CDATA[Dec  9, 13:25 PST
Resolved - The issue with synthetic test failures for help.twilio.com has been resolved and the Twilio Help Center is operating normally at this time.
Dec  9, 12:52 PST
Monitoring - We are no longer observing synthetic test failures for help.twilio.com and the platform is now operating normally. We will continue to monitor for system stability. We'll provide another update in 30 minutes or as soon as more information becomes available.
Dec  8, 21:42 PST
Update - We are continuing to investigate about the synthetic test failing for help.twilio.com. We expect to provide another update in 24 hours or as soon as more information becomes available
Dec  8, 20:44 PST
Investigating - Our monitoring systems have detected synthetic test failing for help.twilio.com, but customers can continue to find support articles via search engine. Our engineering team has been alerted and is actively investigating. We will update as soon as we have more information.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SMS Delivery Failures to Telenor Network in Sweden]]></title>
        <id>https://status.twilio.com/incidents/ry8n32dbdt7v</id>
        <link href="https://status.twilio.com/incidents/ry8n32dbdt7v"/>
        <updated>2023-12-09T20:37:20.000Z</updated>
        <summary type="html"><![CDATA[Dec  9, 12:37 PST
Resolved - We are no longer experiencing SMS delivery failures to the Telenor Network in Sweden. This incident has been resolved.
Dec  9, 10:37 PST
Monitoring - We are observing successful SMS delivery failures to Telenor Network in Sweden. We will continue to monitor to ensure full service recovery. We expect to provide another update in 2 hours or as soon as more information becomes available.
Dec  9, 09:14 PST
Investigating - We are experiencing SMS delivery failures to Telenor Network in Sweden. Our engineers are working with our carrier partner to resolve the issue. We expect to provide another update in 1 hour or as soon as more information becomes available.]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[United Kingdom Account Security Carrier Partner Maintenance - Three UK]]></title>
        <id>https://status.twilio.com/incidents/4316zf6ytgqn</id>
        <link href="https://status.twilio.com/incidents/4316zf6ytgqn"/>
        <updated>2023-12-09T18:00:51.000Z</updated>
        <summary type="html"><![CDATA[Dec  9, 10:00 PST
In progress - Scheduled maintenance is currently in progress. We will provide updates as necessary.
Dec  7, 16:23 PST
Scheduled - Our carrier partner Three UK is conducting an emergency maintenance from 09 December 2023 at 10:00 PST until 10 December 2023 at 01:30 PST. During the maintenance window, there could be intermittent API request failures for Three UK customers.


Impacted Products: Lookup SIM Swap, Lookup Identity Match, Legacy Identity MatchAndAttributes]]></summary>
        <author>
            <name>Twilio Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Network Connectivity in BLR1]]></title>
        <id>https://status.digitalocean.com/incidents/1hv33vh6sf2l</id>
        <link href="https://status.digitalocean.com/incidents/1hv33vh6sf2l"/>
        <updated>2023-12-08T18:00:00.000Z</updated>
        <summary type="html"><![CDATA[Dec  8, 18:00 UTC
Resolved - From 17:53 - 18:22 UTC, we experienced an issue impacting networking in our BLR1 region, with an impact to internal DigitalOcean services.
During that time, public networking for customer services like Droplets and Droplet-based products was not impacted. However, users experienced issues with CRUD (create, read, update, delete) operations for services in BLR1, such as creating Droplets, managing Spaces Buckets, etc. Additionally, Cloud Firewalls were unable to be applied to services in BLR1 during that timeframe.
Our Engineering team has resolved the issue and all services should be functioning normally.
We apologize for the inconvenience. If you have any questions or continue to experience issues, please reach out via a Support ticket on your account.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[UPDATE: We're investigating reports of an issue with Google Drive. We will provide more information shortly.]]></title>
        <id>https://www.google.com/appsstatus/dashboard/incidents/yBzNPqLpw1qh3YnJ69XL</id>
        <link href="https://www.google.com/appsstatus/dashboard/incidents/yBzNPqLpw1qh3YnJ69XL"/>
        <updated>2023-12-08T15:32:35.000Z</updated>
        <summary type="html"><![CDATA[<p> Incident began at <strong>2023-12-07 19:00</strong> and ended at <strong>2023-12-07 20:32</strong> <span>(times are in <strong>Coordinated Universal Time (UTC)</strong>).</span></p><div class="cBIRi14aVDP__status-update-text"><span>  We're investigating reports of an issue with Google Drive. We will provide more information shortly.  </span></div><hr><p>Affected products: Google Drive</p>]]></summary>
        <author>
            <name>Google Workspace Status Dashboard Updates</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spaces CDN in SGP1]]></title>
        <id>https://status.digitalocean.com/incidents/y557k86bkdts</id>
        <link href="https://status.digitalocean.com/incidents/y557k86bkdts"/>
        <updated>2023-12-08T14:33:52.000Z</updated>
        <summary type="html"><![CDATA[Dec  8, 14:33 UTC
Resolved - As of 09:18 UTC, our Engineering team has confirmed the resolution of the issue impacting Spaces CDN in our SGP1 region. Users should no longer experience issues when accessing their Spaces resources over the CDN endpoint in the SGP1 region. 
If you continue to experience problems, please open a ticket with our support team. We apologize for any inconvenience.
Dec  8, 09:47 UTC
Identified - As of 07:45 UTC, our Engineering team has been made aware of an issue with the Spaces CDN in the SGP1 region. During this time, users may experience errors for objects served over the CDN. 
We apologize for the inconvenience and will share an update once we have more information.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SSO Log-In Issues for Windows]]></title>
        <id>https://status.notion.so/incidents/9jymy8sknh0f</id>
        <link href="https://status.notion.so/incidents/9jymy8sknh0f"/>
        <updated>2023-12-05T21:22:51.000Z</updated>
        <summary type="html"><![CDATA[Dec  5, 13:22 PST
Resolved - The team will be investigating this incident as bug.
Dec  5, 12:16 PST
Monitoring - The incident has been identified as a bug and the team is actively monitoring reports and the issue
Dec  5, 11:08 PST
Investigating - We are currently investigating an issue where Notion users are unable to log-in via SSO on the Windows Desktop App]]></summary>
        <author>
            <name>Notion Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Trouble loading some parts of Slack]]></title>
        <id>https://status.slack.com//2023-12/b0072b040087e20b</id>
        <link href="https://status.slack.com//2023-12/b0072b040087e20b"/>
        <updated>2023-12-05T04:20:17.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:

On December 3, 2023 from 4:35 PM PST to around 5:29 PM PST, a small number of customers experienced trouble loading parts of Slack such as threads, channels, and direct messages. Affected customers may have also had trouble sending messages and running some workflows.


One of our databases experienced a minor hardware issue. This triggered an automatic intervention from our redundancy systems, and a new database was brought into service. However, the new database entered a state where it could not successfully respond to incoming queries.


As an immediate mitigation step, we performed a manual replacement and redirected the incoming queries to a third database. This resolved the issue for all impacted customers.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Support Contact Form]]></title>
        <id>https://status.digitalocean.com/incidents/8gycz6w7qj30</id>
        <link href="https://status.digitalocean.com/incidents/8gycz6w7qj30"/>
        <updated>2023-12-04T20:32:18.000Z</updated>
        <summary type="html"><![CDATA[Dec  4, 20:32 UTC
Resolved - Our Engineering team has confirmed full resolution of the issue with contact form submissions. From 14:59 - 19:27 UTC, submissions from https://www.digitalocean.com/company/contact were not being routed to our Support teams. All submissions have been routed to our teams and are being addressed.
If you continue to experience problems, please reach out to our support team. Thank you for your patience throughout this incident!
Dec  4, 20:21 UTC
Monitoring - Our Engineering team has completed the fix to resolve the issue with submissions from our Support Contact form and at this time, services should be functioning as expected. 
Our Support team is addressing all submissions as quickly as possible. We're monitoring the fix and will post an update as soon as we confâ€¦]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Issues with accessing Help Center]]></title>
        <id>https://status.rippling.com/incidents/53rn1yy678tz</id>
        <link href="https://status.rippling.com/incidents/53rn1yy678tz"/>
        <updated>2023-12-02T04:59:20.000Z</updated>
        <summary type="html"><![CDATA[Dec  2, 04:59 UTC
Resolved - This incident has been resolved.
Dec  2, 01:41 UTC
Monitoring - A fix has been implemented and we are monitoring the results.
Dec  2, 00:12 UTC
Identified - The issue has been identified and a fix is being implemented.
Dec  2, 00:12 UTC
Investigating - Customers are experiencing issues with accessing the Rippling Help Center. We are investigating this issue.]]></summary>
        <author>
            <name>Rippling Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Copilot]]></title>
        <id>https://www.githubstatus.com/incidents/fj7v3z6fy7ym</id>
        <link href="https://www.githubstatus.com/incidents/fj7v3z6fy7ym"/>
        <updated>2023-12-01T18:16:24.000Z</updated>
        <summary type="html"><![CDATA[Dec  1, 18:16 UTC
Resolved - This incident has been resolved.
Dec  1, 17:36 UTC
Update - A small percentage of Copilot Chat users are still experiencing long request times and errors. We are still investigating to determine the root cause.
Dec  1, 16:41 UTC
Update - Some customers are experiencing higher latency for Copilot Chat. We are continuing our investigation.
Dec  1, 15:55 UTC
Update - Copilot is experiencing degraded performance. We are continuing to investigate.
Dec  1, 15:53 UTC
Update - We are investigating reports that that some customers are experiencing increased latency and failed requests for Copilot Chat.
Dec  1, 15:49 UTC
Investigating - We are currently investigating this issue.]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Login code delay]]></title>
        <id>https://status.notion.so/incidents/4htm8cyzfh5w</id>
        <link href="https://status.notion.so/incidents/4htm8cyzfh5w"/>
        <updated>2023-12-01T11:30:54.000Z</updated>
        <summary type="html"><![CDATA[Dec  1, 03:30 PST
Resolved - Between 3:30 AM - 5:50 AM PST, some users experienced delays with their sign up and login code emails sending.
This issue was resolved at 5:50 AM PST. All sign up and login code emails should be delivered as expected.]]></summary>
        <author>
            <name>Notion Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Networking in BLR1 for a Subset of Droplets]]></title>
        <id>https://status.digitalocean.com/incidents/1n8mgx97nfb0</id>
        <link href="https://status.digitalocean.com/incidents/1n8mgx97nfb0"/>
        <updated>2023-11-30T18:12:21.000Z</updated>
        <summary type="html"><![CDATA[Nov 30, 18:12 UTC
Resolved - Beginning around 16:48 UTC, our Engineering team identified an issue impacting a subset of Droplets in our BLR1 region. From 16:48 UTC to 17:45 UTC, impacted Droplets did not have correctly functioning networking capabilities. Additionally, users were unable to perform any events (such as power off, recycle, resize, etc) and any changes to the Cloud Firewalls for impacted Droplets were not being applied.
Our Engineering team has resolved the issue and networking and the Cloud Firewalls on all Droplets should be functioning normally.  
We apologize for the inconvenience. If you have any questions or continue to experience issues, please reach out via a Support ticket on your account.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Issues with some users who are attempting to enroll their Windows computers with Rippling's MDM server]]></title>
        <id>https://status.rippling.com/incidents/3vm3nr1kcc68</id>
        <link href="https://status.rippling.com/incidents/3vm3nr1kcc68"/>
        <updated>2023-11-29T22:16:11.000Z</updated>
        <summary type="html"><![CDATA[Nov 29, 22:16 UTC
Resolved - This incident has been resolved.
Nov 29, 19:38 UTC
Monitoring - A fix has been implemented and we are monitoring the results.
Nov 29, 17:22 UTC
Identified - The issue has been identified and a fix is being implemented.]]></summary>
        <author>
            <name>Rippling Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Slack not loading for some users]]></title>
        <id>https://status.slack.com//2023-11/edc9f768095e939b</id>
        <link href="https://status.slack.com//2023-11/edc9f768095e939b"/>
        <updated>2023-11-29T14:41:20.000Z</updated>
        <summary type="html"><![CDATA[Issue Summary:


From 9:30 AM PST on November 28, 2023 to 12:30 AM PST on November 29, 2023, some users in Asia were experiencing issues with Slack loading. Most of the impacted users were in Japan and India.


We traced this back to an unexpected spike in a database load for which we quickly saw recovery.


We monitored the situation closely and as the load reduced without intervention, we did not take any mitigating actions.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[We are investigating reports of degraded performance.]]></title>
        <id>https://www.githubstatus.com/incidents/dq9m4n5tfyr6</id>
        <link href="https://www.githubstatus.com/incidents/dq9m4n5tfyr6"/>
        <updated>2023-11-28T19:40:12.000Z</updated>
        <summary type="html"><![CDATA[Nov 28, 19:40 UTC
Resolved - This incident has been resolved.
Nov 28, 19:36 UTC
Update - We were not able to publish webhooks in response to push events triggered between 16:23 and 17:12 UTC. To avoid further disruption to customer workflows, weâ€™ve decided not to continue our attempts to re-process those events. 
Workflows that trigger on pull_request or git push events may not have been run during this time period. 
You can run impacted workflows manually or by pushing a new commit to the same branch.
Nov 28, 18:09 UTC
Update - Customers saw push event deliveries for Actions and Webhooks fail between 16:23 and 17:12 (UTC). We fixed the issue, and we are working to re-process push events for the affected time period.
Nov 28, 18:09 UTC
Investigating - We are currently investigating this issue.]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Actions and Webhooks]]></title>
        <id>https://www.githubstatus.com/incidents/dsb3kn1zfdl7</id>
        <link href="https://www.githubstatus.com/incidents/dsb3kn1zfdl7"/>
        <updated>2023-11-28T17:59:15.000Z</updated>
        <summary type="html"><![CDATA[Nov 28, 17:59 UTC
Resolved - This incident has been resolved. An interaction between two feature flag rollouts caused us to suppress delivery of push webhooks between 16:23 and 17:11 UTC in a manner that evaded our existing observability. This affected 71,000 repositories whose users will have noted missing webhook deliveries and/or experienced Actions jobs with push triggers failing to start. During this period, around 25% of new Actions jobs were impacted. The issues were resolved by disabling one of the feature flags in question.
After weighing various options for retroactively dispatching old push webhooks, we concluded that the risk of delivering stale data to customers with these redeliveries outweighed the possible benefit.
As follow up to this incident, we are working to improve monitoring of webhook throughput and to document a policy around webhook redelivery timelines.
Nov 28, 17:59 UTC
Update - Actions is operating normally.
Nov 28, 17:36 UTC
Update - Customers saw pull requests push event deliveries for Actions and Webhooks fail between 16:23 and 17:12 (UTC). We fixed the issue, and we are working to re-process push events for the affected time period.
Nov 28, 17:24 UTC
Investigating - We are investigating reports of degraded performance for Actions and Webhooks]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Datastore App timing out]]></title>
        <id>https://status.make.com/incidents/3yz9s3tkz2xh</id>
        <link href="https://status.make.com/incidents/3yz9s3tkz2xh"/>
        <updated>2023-11-28T08:55:30.000Z</updated>
        <summary type="html"><![CDATA[Nov 28, 09:55 CET
Resolved - The implemented workaround has been effective and eu1.make.celonis.com remains stable. The incident has been resolved.
Nov 27, 17:18 CET
Update - The situation stays stable. We are still investigating the root cause of the problem. We will maintain ongoing monitoring and notify once we fully resolve the incident.
Nov 27, 16:31 CET
Monitoring - The tuning of our Data Store infrastructure did relieve the situation and Scenarios using the Data Store App are stable again. We are continuously monitoring the state of our platform. We will come up with an update in the next 30 minutes. Thank you for your understanding and patience.
Nov 27, 15:59 CET
Update - We are still investigating the root cause of this incident. Meanwhile, we are tuning our Data Store infrastructure to relieve the situation and put the platform in a more stable state. We will come up with an update in the next 30 minutes. Thank you for your understanding and patience.
Nov 27, 15:21 CET
Investigating - We have detected multiple instances of the Datastore App timing out and failing on eu1.make.celonis.com. We are currently investigating the root cause and will come back to you once we find more information. Thank you for your understanding and patience.]]></summary>
        <author>
            <name>Make Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Pull Requests, Issues, Webhooks and Actions]]></title>
        <id>https://www.githubstatus.com/incidents/66vhjmd266r9</id>
        <link href="https://www.githubstatus.com/incidents/66vhjmd266r9"/>
        <updated>2023-11-27T21:11:04.000Z</updated>
        <summary type="html"><![CDATA[Nov 27, 21:11 UTC
Resolved - This incident has been resolved.
On November 27, 2023 at 18:46 UTC, we attempted to rotate our OpenID Connect (OIDC) authentication flow certificates. Due to an error in the certificate formatting, we uploaded an invalid certificate configuration that was not observed in our pre-production testing. Our background job servers were unable to start because a valid configuration is required at worker start up. As a result, users experienced delays in Pull Requests, Webhooks, Issues, Actions and Projects. Rollback of the change was slowed by the invalid certificate as our deployment system relied on the same certificate. Rollback was completed at 20:35 UTC. Most services recovered by 20:44 UTC. 

Delayed updates to Issues and Pull Requests were applied normally onceâ€¦]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Introducing our enhanced Stripe integration ðŸš€]]></title>
        <id>279856</id>
        <link href="https://changelog.bookingsync.com/introducing-our-enhanced-stripe-integration-279856"/>
        <updated>2023-11-24T13:25:46.000Z</updated>
        <summary type="html"><![CDATA[New!
Â 
Improvement
Â 
Action required
Â Â 
We're thrilled to share some fantastic updates on our Stripe integration, aiming to improve your Smily experience. ðŸŽ‰
What's New?
Effortless Stripe Account Addition: managing multiple payment gateways just got easier! We've streamlined the process of adding new Stripe accounts for flexibility and convenience. 


Improved Customer Support Access: your satisfaction is our top priority. Now, our customer support is better equipped to assist you with any questions or issues related to your Stripe integration.


Why Does This Matter?
This upgrade is designed with your convenience in mind, offering the following benefits:
Time Saving: adding new Stripe accounts is now a few clicks away, eliminating lengthy back-and-forth communications.


Reduced Frustration: improved support ensures prompt resolution of queries or issues.


Maintained Control: you retain complete control over your Stripe accounts, payouts, and settings, experiencing no change in usage or payment reception.


What's Next?
Ready to unlock the enhanced Stripe Integration? Go to Settings > Payments in your Smily account, click connect on any unconnected Stripe payment gateways, and enjoy seamless transactions. 
Rest assured, these improvements maintain the highest security standards for your financial transactions.
For detailed information on connecting your Stripe account, check our FAQ.
We're here to support you every step of the way. If you have questions or need assistance, reach out to us. 
Let's embark on this journey together to make your vacation rental dreams a reality ðŸš€]]></summary>
        <author>
            <name>Megan, Product Manager</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Issues with the Adobe integration]]></title>
        <id>https://status.rippling.com/incidents/sj7thsw4jlzl</id>
        <link href="https://status.rippling.com/incidents/sj7thsw4jlzl"/>
        <updated>2023-11-23T22:41:38.000Z</updated>
        <summary type="html"><![CDATA[Nov 23, 22:41 UTC
Resolved - This incident has been resolved.
Nov 23, 16:29 UTC
Monitoring - A fix has been implemented and we are monitoring the results.
Nov 22, 18:03 UTC
Identified - The issue has been identified and a fix is being implemented.
Nov 22, 17:37 UTC
Investigating - Customers are experiencing issues with the assignment of Adobe licenses to users. We are investigating this issue.]]></summary>
        <author>
            <name>Rippling Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Notion AI is down]]></title>
        <id>https://status.notion.so/incidents/69628qhdf41j</id>
        <link href="https://status.notion.so/incidents/69628qhdf41j"/>
        <updated>2023-11-22T02:00:20.000Z</updated>
        <summary type="html"><![CDATA[Nov 21, 18:00 PST
Resolved - This is resolved.
Nov 21, 16:50 PST
Update - Provider calls are more stable. We are monitoring our provider.
Nov 21, 16:43 PST
Monitoring - A fix has been implemented and we are monitoring the results.
Nov 21, 16:42 PST
Identified - Notion AI is partially not working as one of our service providers is down]]></summary>
        <author>
            <name>Notion Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Actions]]></title>
        <id>https://www.githubstatus.com/incidents/x39xrr5m11b3</id>
        <link href="https://www.githubstatus.com/incidents/x39xrr5m11b3"/>
        <updated>2023-11-21T11:27:43.000Z</updated>
        <summary type="html"><![CDATA[Nov 21, 11:27 UTC
Resolved - On November 21, 2023, at 09:50 UTC GitHub Actions jobs encountered delays due to an incident in our background job service caused by excessive rebalancing in a Kafka consumer group. After a quick mitigation, we began to see recovery on the job queues by 10:02 UTC. During this time window 100% of Actions jobs were delayed in starting for up to 11 minutes.
Unfortunately, the rapid queue recovery sent a thundering herd of jobs to Actions hosted runner pools, causing a database deadlock that resulted in some hosted runner pools having increased latency when accepting new jobs. This affected only a small percentage of overall jobs, around 2%. Configuration changes led to a resolution and the system was fully recovered by 11:27 UTC and all in progress jobs were processed.
The incident is now resolved.
Nov 21, 11:12 UTC
Update - We've applied a mitigation to fix the issues with queuing and running Actions jobs. We are seeing improvements in telemetry and are monitoring for full recovery.
Nov 21, 10:24 UTC
Update - We have recovery for the underlying issue but are waiting for Actions queues to catch up. We expect this to be completed in less than 1 hour(s).
Nov 21, 10:11 UTC
Investigating - We are investigating reports of degraded performance for Actions]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Issue affecting template duplication]]></title>
        <id>https://status.notion.so/incidents/tk0hmlbd3lg9</id>
        <link href="https://status.notion.so/incidents/tk0hmlbd3lg9"/>
        <updated>2023-11-18T00:04:17.000Z</updated>
        <summary type="html"><![CDATA[Nov 17, 16:04 PST
Resolved - Our team has now resolved the issue preventing template duplication, and this is working as normal again. We appreciate your patience while we worked through this issue.
Nov 17, 14:05 PST
Identified - We are experiencing an issue with duplicating published templates and our team is actively working on a fix.]]></summary>
        <author>
            <name>Notion Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: Some users may be experiencing issues with huddles]]></title>
        <id>https://status.slack.com//2023-11/2b97ec921a81988a</id>
        <link href="https://status.slack.com//2023-11/2b97ec921a81988a"/>
        <updated>2023-11-17T21:42:44.000Z</updated>
        <summary type="html"><![CDATA[Issue Summary:

On November 8, 2023 from 7:55 AM PT until 8:27 PM PT, a small number of users experienced errors when attempting to join or start huddles.


We traced this back to an unexpected spike in a database load for which we quickly saw recovery.


We monitored the situation closely and in an effort to prevent further unexpected error spikes, we implemented a strategic configuration adjustment to optimize the load on our database.


Affected users should no longer experience issues with huddles.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Notion AI is down]]></title>
        <id>https://status.notion.so/incidents/vvx0wz4pgd9k</id>
        <link href="https://status.notion.so/incidents/vvx0wz4pgd9k"/>
        <updated>2023-11-17T03:11:59.000Z</updated>
        <summary type="html"><![CDATA[Nov 16, 19:11 PST
Resolved - The incident has been resolved. Time of resolution Nov 16 2023 6:46PM PST
Nov 16, 19:09 PST
Identified - Notion AI is down. We are working with them on a fix. Time - Nov 16 2023 6:11PM PST]]></summary>
        <author>
            <name>Notion Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Intermittent scenario execution errors in eu1, eu2 and us1 zones]]></title>
        <id>https://status.make.com/incidents/d82gd0vnvgz1</id>
        <link href="https://status.make.com/incidents/d82gd0vnvgz1"/>
        <updated>2023-11-16T08:45:00.000Z</updated>
        <summary type="html"><![CDATA[Nov 16, 09:45 CET
Resolved - Due to a configuration error, some scenarios in the eu1.make.com, eu2.make.com and us1.make.com zones may have intermittently failed to execute and in case of multiple consecutive errors get disabled by the system. According to our telemetry, the number of impacted scenarios was very small. Customers may have experienced this behavior between 9:45am and 8:00pm CET. We have addressed the configuration problem and all executions are now stable. We will continue monitoring the situation.]]></summary>
        <author>
            <name>Make Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Inquiry and Pre-Approval Issues]]></title>
        <id>https://airbnbapi.statuspage.io/incidents/l9cxvbj0pq59</id>
        <link href="https://airbnbapi.statuspage.io/incidents/l9cxvbj0pq59"/>
        <updated>2023-11-16T08:00:00.000Z</updated>
        <summary type="html"><![CDATA[Nov 16, 00:00 PST
Resolved - On Nov 16 and 17, some inquiries and pre-approvals expired prematurely, causing guests to be unable to accept them because Airbnb incorrectly showed these listings as unavailable, even though they were actually available. Additionally, Hosts were experiencing difficulties in creating new pre-approvals during this period. We apologize for the inconvenience that this issue has caused.
This issue started on Nov 16 around 12:00 AM PST and was resolved on Nov 17 at 9:10 AM PST, and we expect this to be fully resolved. Please contact us if you are still seeing this issue.]]></summary>
        <author>
            <name>Airbnb API Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[We are investigating reports of degraded performance.]]></title>
        <id>https://www.githubstatus.com/incidents/mnv0g944fncw</id>
        <link href="https://www.githubstatus.com/incidents/mnv0g944fncw"/>
        <updated>2023-11-15T11:34:14.000Z</updated>
        <summary type="html"><![CDATA[Nov 15, 11:34 UTC
Resolved - On 2023-11-15, from 09:44 to 10:42 UTC, some GitHub customers experienced increased latency or errors accessing repo data.
High concurrent access to a specific git object exposed a bug that forced a backend service to perform excessive calculations, overloading the service. Access to this repo was paused while load was re-rerouted, mitigating the problem.
The conditions that triggered the expensive operations have been identified and refactored.
Nov 15, 11:33 UTC
Update - Error rates and performance have returned to normal.
Nov 15, 11:21 UTC
Update - We have identified the source of the issue and have removed the additional load from the service. Sporadic delays in pull request experiences and intermittent 500s are still occurring and impacting a very small percentage of traffic. Next update is expected within 30 minutes.
Nov 15, 11:04 UTC
Update - We are seeing connectivity issues between some of our systems and git backend services. This is causing intermittent error responses and delays in pull request experiences for a very small percentage of traffic. We are investigating mitigations and expect to provide another update within 30 minutes.
Nov 15, 09:50 UTC
Investigating - We are currently investigating this issue.]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Outage: Slack not loading for some users]]></title>
        <id>https://status.slack.com//2023-11/0e7bc0e7a7e7cd87</id>
        <link href="https://status.slack.com//2023-11/0e7bc0e7a7e7cd87"/>
        <updated>2023-11-15T03:01:39.000Z</updated>
        <summary type="html"><![CDATA[Issue summary:

From 3:15 PM PST on November 14, 2023 to around 4:13 PM PST, a small number of customers using the Slack desktop app were unable to connect to Slack. This may have manifested as a "Something's gone awry" error page.


A recent code change inadvertently introduced a logic error that prevented the desktop app from connecting as expected. We reverted this code change as an immediate mitigation step, then rolled out a fix to correct the logic error. 


The fix resolved the issue for all affected customers, restoring full access to Slack.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DOKS in Multiple Regions]]></title>
        <id>https://status.digitalocean.com/incidents/wpz7gdly2p32</id>
        <link href="https://status.digitalocean.com/incidents/wpz7gdly2p32"/>
        <updated>2023-11-15T01:59:25.000Z</updated>
        <summary type="html"><![CDATA[Nov 15, 01:59 UTC
Resolved - Our Engineering team has confirmed the full resolution of the issue impacting DOKS across all regions. 
After the rollout, we are no longer reliant on that affected upstream provider for our DOKS product.
If you continue to experience problems, please open a ticket with our support team. We apologize for any inconvenience.
Nov 15, 00:42 UTC
Monitoring - Our Engineering team has completed the rollout to pivot away from the affected upstream provider and we are no longer reliant on that provider for our DOKS product. 
At this time, Users should no longer see any issues with nodes going into not ready states, creating new clusters, or scaling up additional nodes. 
We're monitoring the fix and will post another update once we confirm this issue is fully resolved.
Nov 14, 23:24 UTC
Update - Our Engineering team is currently working to pivot away from the affected upstream provider to mitigate impact from this incident. That fix is rolling out across our fleet and users should start to see conditions on affected clusters improve. 
As soon as the fix is rolled out completely, we'll post another update.
Nov 14, 22:20 UTC
Update - Our Engineering team has confirmed an issue on our upstream provider's end impacting DOKS across all regions which was initially reported for a few regions. 
During this time, Users will not be able to create new clusters, scale up additional nodes or may see nodes in an unready state across all regions.
We will share an update as soon as we have any information from our upstream provider.
Nov 14, 21:59 UTC
Identified - Beginning around 20:00 UTC, our Engineering team has confirmed an issue on our upstream provider's end impacting DOKS in our multiple regions. 
During this time, Users will not be able to create new clusters, scale up additional nodes or may see nodes in an unready state. 
We will share an update as soon as we have any information from our upstream provider.]]></summary>
        <author>
            <name>DigitalOcean Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[EU2 hooks delayed processing]]></title>
        <id>https://status.make.com/incidents/dzjb57y129qn</id>
        <link href="https://status.make.com/incidents/dzjb57y129qn"/>
        <updated>2023-11-14T17:04:00.000Z</updated>
        <summary type="html"><![CDATA[Nov 14, 18:04 CET
Resolved - This incident has been resolved.
Nov 14, 13:53 CET
Update - The current situation is stable, and after performing a series of checks, no issues were observed. We will maintain ongoing monitoring for the next 4 hours, and if everything remains stable during this period, we will proceed to resolve the incident.
Nov 13, 21:16 CET
Monitoring - The issue is currently stable. We will continue careful monitoring of the situation and provide updates regularly.
Nov 13, 16:58 CET
Update - Our team is continuing to investigate the technical difficulties affecting webhooks and mailhooks on eu2.make.com. At this time, we have not yet identified the root cause, and users may still experience sporadic delays in the processing of these services.
Nov 13, 14:54 CET
Investigating - We are currently experiencing technical difficulties with webhooks and mailhooks on eu2.make.com. Users may encounter delays in the processing of webhooks and mailhooks.
We will provide another update on this Statuspage within the next 2 hours or as soon as more information becomes available.]]></summary>
        <author>
            <name>Make Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[We are investigating reports of degraded performance.]]></title>
        <id>https://www.githubstatus.com/incidents/knl5pxnx0byt</id>
        <link href="https://www.githubstatus.com/incidents/knl5pxnx0byt"/>
        <updated>2023-11-13T21:38:40.000Z</updated>
        <summary type="html"><![CDATA[Nov 13, 21:38 UTC
Resolved - Between 20:35 and 21:38 we experienced up to a 20 minute delay delivering around 30,000 notifications due to side effects of some planned maintenance on supporting systems. We have noted the unexpected user impact of this type of maintenance and will address it in future maintenance planning.
Nov 13, 21:38 UTC
Update - An issue related to notifications has been resolved. Users should again be seeing their notifications.
Nov 13, 21:15 UTC
Update - We're seeing issues related to notifications.
Nov 13, 21:13 UTC
Investigating - We are currently investigating this issue.]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident: User presence is unexpectedly changing]]></title>
        <id>https://status.slack.com//2023-11/16fed44d7948cf49</id>
        <link href="https://status.slack.com//2023-11/16fed44d7948cf49"/>
        <updated>2023-11-13T15:57:36.000Z</updated>
        <summary type="html"><![CDATA[Issue Summary:


From 4:00 PM PDT on October 31, 2023 to 2:00 PM PDT on November 9, 2023, user presence would unexpectedly change to away or inactive.


We determined that an error during a routine system optimization on connectivity state caused this issue. 


We reverted the change which fixed the issue for all affected customers.


Thank you for your patience while we resolved this.]]></summary>
        <author>
            <name>Slack System Status</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incident with Pages, Webhooks and Actions]]></title>
        <id>https://www.githubstatus.com/incidents/wyk0ns67krlz</id>
        <link href="https://www.githubstatus.com/incidents/wyk0ns67krlz"/>
        <updated>2023-11-11T02:14:08.000Z</updated>
        <summary type="html"><![CDATA[Nov 11, 02:14 UTC
Resolved - On November 11, 2023, at 1:00 UTC, GitHub background jobs encountered delays lasting up to 50 minutes. This delay affected various services utilizing background jobs, including Actions, Webhooks, Pull Requests, and Pages. The impact persisted for approximately one hour until 2:10 UTC.
During the incident, some customers experienced delays in starting Github Actions workflow runs and Pages builds. We estimate that about 10% of Actions workflow runs were delayed during the impact window and 99% of Pages builds failed from 1:00 UTC to 1:20 UTC. Users may have experienced a delay in seeing recent pushes reflected in pull request views. This delay averaged between 5 and 10 minutes and affected up to 30% of pull request page views during the incident. 1% of pull requâ€¦]]></summary>
        <author>
            <name>GitHub Status - Incident History</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Issues loading Rippling]]></title>
        <id>https://status.rippling.com/incidents/54s1f3rs3n56</id>
        <link href="https://status.rippling.com/incidents/54s1f3rs3n56"/>
        <updated>2023-11-10T23:59:07.000Z</updated>
        <summary type="html"><![CDATA[Nov 10, 23:59 UTC
Resolved - This incident has been resolved.
Nov  9, 19:56 UTC
Monitoring - A fix has been implemented and we are monitoring the results.
Nov  9, 18:41 UTC
Update - We are continuing to investigate this issue.
Nov  9, 18:39 UTC
Update - We are continuing to investigate this issue.
Nov  9, 18:34 UTC
Investigating - We are currently investigating this issue.]]></summary>
        <author>
            <name>Rippling Status - Incident History</name>
        </author>
    </entry>
</feed>